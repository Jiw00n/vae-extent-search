{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "03afca96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "\n",
    "project_root = \"/root/work/tenset\"\n",
    "os.environ[\"TVM_HOME\"] = f\"{project_root}\"\n",
    "os.environ[\"TVM_LIBRARY_PATH\"] = f\"{project_root}/build\"\n",
    "if f\"{project_root}/python\" not in sys.path:\n",
    "    sys.path.insert(0, f\"{project_root}/python\")\n",
    "\n",
    "sys.path = [p for p in sys.path if not p.startswith(f\"{project_root}/build\")]\n",
    "sys.path.append(f\"{project_root}/build\")\n",
    "os.environ[\"LD_LIBRARY_PATH\"] = f\"{project_root}/build:\" + os.environ.get(\"LD_LIBRARY_PATH\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3fe2201b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "class FeatureRegressionDataset(Dataset):\n",
    "    def __init__(self, X, y, feature):\n",
    "        if isinstance(X, np.ndarray):\n",
    "            self.X = torch.from_numpy(X).float()\n",
    "        else:\n",
    "            self.X = X\n",
    "        if isinstance(feature, np.ndarray):\n",
    "            self.feature = torch.from_numpy(feature).float()\n",
    "        else:\n",
    "            self.feature = feature\n",
    "        self.y = torch.from_numpy(y).float()\n",
    "        # y shape이 (N,)이면 (N,1)로 바꿔주는 게 편할 때가 많음\n",
    "        if self.y.ndim == 1:\n",
    "            self.y = self.y.unsqueeze(1)\n",
    "        if self.feature.ndim == 1:\n",
    "            self.feature = self.feature.unsqueeze(1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx], self.feature[idx]\n",
    "\n",
    "\n",
    "class FeatureDataset(Dataset):\n",
    "    def __init__(self, X, feature):\n",
    "        if isinstance(X, np.ndarray):\n",
    "            self.X = torch.from_numpy(X).float()\n",
    "        else:\n",
    "            self.X = X\n",
    "        self.feature = torch.from_numpy(feature).float()\n",
    "        # feature shape이 (N,)이면 (N,1)로 바꿔주는 게 편할 때가 많음\n",
    "        if self.feature.ndim == 1:\n",
    "            self.feature = self.feature.unsqueeze(1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.feature[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a8b86d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# record_index\n",
    "# vector_index\n",
    "# diff_indices\n",
    "# diff_values\n",
    "# cost\n",
    "\n",
    "json_diffs = np.load(\"../i_vectors_diffs.npz\")\n",
    "raw_input = json_diffs[\"diff_values\"]\n",
    "\n",
    "# input_data = json_diffs[\"diff_values\"]\n",
    "cost = -np.log(json_diffs[\"cost\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "92928ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def transform_schedule(x_int, mean=None, std=None, eps=1e-6):\n",
    "    \"\"\"\n",
    "    스케줄 파라미터 int 텐서를 log-scale + zero-flag로 변환\n",
    "\n",
    "    Args:\n",
    "        x_int: (B, D) int 텐서. 예: 0, 1, 2, 4, 8, ..., 1024\n",
    "        mean, std: (1, D) 형태의 텐서. None이면 입력에서 계산해서 반환.\n",
    "        eps: 분산 0 방지용 작은 값.\n",
    "\n",
    "    Returns:\n",
    "        x_cont: (B, 2*D) float 텐서. [v_norm, is_zero] concat\n",
    "        mean, std: (1, D) float 텐서. 나중에 validation/test에도 reuse\n",
    "    \"\"\"\n",
    "    # int → float\n",
    "    x_int = torch.tensor(x_int)\n",
    "    x = x_int.to(torch.float32)\n",
    "\n",
    "    # zero flag\n",
    "    is_zero = (x_int == 0).to(torch.float32)  # (B, D)\n",
    "\n",
    "    # log2 변환 (0은 일단 0으로 두고 mask)\n",
    "    v = torch.zeros_like(x, dtype=torch.float32)  # (B, D)\n",
    "    mask = (x_int > 0)\n",
    "    v[mask] = torch.log2(x[mask])\n",
    "\n",
    "    # mean / std 없으면 전체 batch 기준으로 계산 (보통은 train 전체로 미리 계산)\n",
    "    if mean is None or std is None:\n",
    "        mean = v.mean(dim=0, keepdim=True)           # (1, D)\n",
    "        std = v.std(dim=0, keepdim=True) + eps       # (1, D)\n",
    "\n",
    "    # 정규화\n",
    "    v_norm = (v - mean) / std   # (B, D)\n",
    "\n",
    "    # v_norm과 is_zero concat → (B, 2D)\n",
    "    x_cont = torch.cat([v_norm, is_zero], dim=-1)\n",
    "\n",
    "    return x_cont, mean, std\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "00c9eae3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[116], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m json_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/root/work/tenset/dataset/measure_records_tenset/k80/([0bcb8746286db050cd088f375c85372d,1,64,64,128,6,6,32,128,1,64,64,32],cuda).json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     12\u001b[0m tasks \u001b[38;5;241m=\u001b[39m load_and_register_tasks()\n\u001b[0;32m---> 13\u001b[0m inputs, results \u001b[38;5;241m=\u001b[39m \u001b[43mauto_scheduler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRecordReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_file\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_lines\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m raw_features, raw_normalized_throughputs, task_ids, min_latency \u001b[38;5;241m=\u001b[39m get_per_store_features_from_file(json_file, \u001b[38;5;241m10000\u001b[39m)\n",
      "File \u001b[0;32m~/work/tenset/python/tvm/auto_scheduler/measure_record.py:118\u001b[0m, in \u001b[0;36mRecordReader.read_lines\u001b[0;34m(self, max_lines, skip_lines)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mread_lines\u001b[39m(\u001b[38;5;28mself\u001b[39m, max_lines\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, skip_lines\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m     95\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Read multiple lines from the log file.\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \n\u001b[1;32m     97\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;124;03m    to rebuild these fields.\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m     inputs, results \u001b[38;5;241m=\u001b[39m \u001b[43m_ffi_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRecordReaderReadLines\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_lines\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmax_lines\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_lines\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_workload_key(inputs)\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inputs, results\n",
      "File \u001b[0;32m~/work/tenset/python/tvm/_ffi/_ctypes/packed_func.py:227\u001b[0m, in \u001b[0;36mPackedFuncBase.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    224\u001b[0m ret_val \u001b[38;5;241m=\u001b[39m TVMValue()\n\u001b[1;32m    225\u001b[0m ret_tcode \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mc_int()\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m--> 227\u001b[0m     \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTVMFuncCall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtcodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_args\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mret_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mret_tcode\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    236\u001b[0m ):\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m get_last_ffi_error()\n\u001b[1;32m    238\u001b[0m _ \u001b[38;5;241m=\u001b[39m temp_args\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/root/work/tenset/scripts\")\n",
    "\n",
    "from tvm import auto_scheduler\n",
    "from print_programs import return_program\n",
    "from tvm.auto_scheduler.feature import get_per_store_features_from_file\n",
    "from make_dataset import load_and_register_tasks\n",
    "import numpy as np\n",
    "\n",
    "json_file = \"/root/work/tenset/dataset/measure_records_tenset/k80/([0bcb8746286db050cd088f375c85372d,1,64,64,128,6,6,32,128,1,64,64,32],cuda).json\"\n",
    "\n",
    "tasks = load_and_register_tasks()\n",
    "inputs, results = auto_scheduler.RecordReader(json_file).read_lines()\n",
    "raw_features, raw_normalized_throughputs, task_ids, min_latency = get_per_store_features_from_file(json_file, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc41699",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "for feature, throughput in zip(raw_features, raw_normalized_throughputs):\n",
    "    if throughput > 1.0e-10:\n",
    "        features.append(feature)\n",
    "\n",
    "\n",
    "features = np.array(features, dtype=np.float32)\n",
    "features_mean = np.mean(features, axis=1)\n",
    "features_mean = torch.tensor(features_mean, dtype=torch.float32)\n",
    "# (3464, 8, features_dim) -> (3464, features_dim)\n",
    "\n",
    "features_mean = features_mean.view(features_mean.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57939556",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class VAE_feature_head(nn.Module):\n",
    "    def __init__(self, input_dim, feature_dim, latent_dim=16, hidden_dim=128):\n",
    "        \"\"\"\n",
    "        input_dim: 2 * D (v_norm + is_zero concat한 차원)\n",
    "        latent_dim: latent space 차원\n",
    "        hidden_dim: MLP hidden 크기\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.fc_mu = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(hidden_dim, latent_dim)\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, input_dim),\n",
    "            \n",
    "            # 출력은 연속값이니까 activation 없이 그대로\n",
    "        )\n",
    "\n",
    "        self.feature_predictor = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, feature_dim),  # features.shape[1]는 feature 차원\n",
    "        )\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = self.encoder(x)\n",
    "        mu = self.fc_mu(h)\n",
    "        logvar = self.fc_logvar(h)\n",
    "        return mu, logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        return self.decoder(z)\n",
    "\n",
    "    def predict_feature(self, z):\n",
    "        return self.feature_predictor(z)\n",
    "\n",
    "    def forward(self, x, use_mean=True):\n",
    "        mu, logvar = self.encode(x)\n",
    "        if use_mean:\n",
    "            z = mu\n",
    "        else:\n",
    "            z = self.reparameterize(mu, logvar)\n",
    "        x_recon = self.decode(z)\n",
    "        feature_pred = self.predict_feature(z)\n",
    "        return x_recon, mu, logvar, z, feature_pred\n",
    "\n",
    "def vae_feature_loss(x_recon, x, mu, logvar, feature_pred, feature, alpha_recon=0, alpha_feature=0, beta=1.0):\n",
    "    \"\"\"\n",
    "    x, x_recon: (B, input_dim)\n",
    "    mu, logvar: (B, latent_dim)\n",
    "\n",
    "    beta: KL 가중치 (β-VAE 스타일로 조절)\n",
    "    \"\"\"\n",
    "    # reconstruction loss: MSE\n",
    "    recon_loss = F.mse_loss(x_recon, x, reduction=\"mean\")\n",
    "\n",
    "    feature_loss = F.mse_loss(feature_pred, feature, reduction=\"mean\")\n",
    "\n",
    "    # KL divergence: D_KL(q(z|x) || N(0, I))\n",
    "    kl = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "    loss = alpha_recon * recon_loss + beta * kl + alpha_feature * feature_loss\n",
    "    return loss, recon_loss, kl, feature_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "99f53909",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "input_data = np.log(json_diffs[\"diff_values\"]+1e-8)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "input_data_scaled = scaler.fit_transform(input_data)\n",
    "feature_scaled = scaler.fit_transform(features_mean)\n",
    "\n",
    "X_train, X_val, y_train, y_val, feature_train, feature_val = train_test_split(\n",
    "    input_data_scaled, cost, feature_scaled,  test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# input_data, mean, std = transform_schedule(json_diffs[\"diff_values\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "051ab10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d14b1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================\n",
      "Experiment 1/432\n",
      "beta=0.001, noise_std=0.001, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.0051, recon=0.0105, feature=0.0142, kl=2.6542\n",
      "epoch 300: val loss=0.0102, val recon=0.0288, val feature=0.0465, val kl=2.6444\n",
      "Recon R2 : 0.971184121504381, Feature R2 : 0.4291942431317978\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 2/432\n",
      "beta=0.001, noise_std=0.001, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.0050, recon=0.0100, feature=0.0138, kl=2.6531\n",
      "epoch 300: val loss=0.0103, val recon=0.0300, val feature=0.0463, val kl=2.6714\n",
      "Recon R2 : 0.9699798979759202, Feature R2 : 0.4295778662486734\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 3/432\n",
      "beta=0.001, noise_std=0.001, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.0050, recon=0.0089, feature=0.0143, kl=2.6619\n",
      "epoch 300: val loss=0.0101, val recon=0.0294, val feature=0.0449, val kl=2.6467\n",
      "Recon R2 : 0.970475037566648, Feature R2 : 0.4306141143972563\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 4/432\n",
      "beta=0.001, noise_std=0.001, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.0134, recon=0.0408, feature=0.0610, kl=3.2298\n",
      "epoch 300: val loss=0.0177, val recon=0.0585, val feature=0.0866, val kl=3.1702\n",
      "Recon R2 : 0.9411154580851013, Feature R2 : 0.3892521887202418\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 5/432\n",
      "beta=0.001, noise_std=0.001, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.0130, recon=0.0409, feature=0.0570, kl=3.2130\n",
      "epoch 300: val loss=0.0178, val recon=0.0596, val feature=0.0859, val kl=3.2149\n",
      "Recon R2 : 0.9403209355360113, Feature R2 : 0.39039294115841344\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 6/432\n",
      "beta=0.001, noise_std=0.001, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.0135, recon=0.0408, feature=0.0618, kl=3.2565\n",
      "epoch 300: val loss=0.0172, val recon=0.0569, val feature=0.0832, val kl=3.2018\n",
      "Recon R2 : 0.9427618300606964, Feature R2 : 0.39286393814690146\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 7/432\n",
      "beta=0.001, noise_std=0.001, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.0045, recon=0.0082, feature=0.0135, kl=2.3319\n",
      "epoch 300: val loss=0.0095, val recon=0.0259, val feature=0.0455, val kl=2.3161\n",
      "Recon R2 : 0.9742077177935964, Feature R2 : 0.43037358275003273\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 8/432\n",
      "beta=0.001, noise_std=0.001, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.0045, recon=0.0081, feature=0.0140, kl=2.3096\n",
      "epoch 300: val loss=0.0087, val recon=0.0209, val feature=0.0420, val kl=2.3675\n",
      "Recon R2 : 0.9789481848287149, Feature R2 : 0.4338201540840763\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 9/432\n",
      "beta=0.001, noise_std=0.001, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.0047, recon=0.0095, feature=0.0138, kl=2.3310\n",
      "epoch 300: val loss=0.0100, val recon=0.0274, val feature=0.0495, val kl=2.3377\n",
      "Recon R2 : 0.9725807270796407, Feature R2 : 0.4261695770769856\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 10/432\n",
      "beta=0.001, noise_std=0.001, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.0112, recon=0.0308, feature=0.0533, kl=2.8339\n",
      "epoch 300: val loss=0.0155, val recon=0.0462, val feature=0.0805, val kl=2.8153\n",
      "Recon R2 : 0.9536277968920412, Feature R2 : 0.39553510150515325\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 11/432\n",
      "beta=0.001, noise_std=0.001, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.0110, recon=0.0291, feature=0.0533, kl=2.7197\n",
      "epoch 300: val loss=0.0147, val recon=0.0393, val feature=0.0798, val kl=2.8125\n",
      "Recon R2 : 0.9606611468912973, Feature R2 : 0.39638413026489744\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 12/432\n",
      "beta=0.001, noise_std=0.001, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.0110, recon=0.0316, feature=0.0504, kl=2.7582\n",
      "epoch 300: val loss=0.0150, val recon=0.0441, val feature=0.0774, val kl=2.8044\n",
      "Recon R2 : 0.9558149686481979, Feature R2 : 0.3984559434271242\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 13/432\n",
      "beta=0.001, noise_std=0.001, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.0165, recon=0.0192, feature=0.0107, kl=3.8488\n",
      "epoch 300: val loss=0.0489, val recon=0.0607, val feature=0.0390, val kl=3.8206\n",
      "Recon R2 : 0.9391663305552924, Feature R2 : 0.43688419133929035\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 14/432\n",
      "beta=0.001, noise_std=0.001, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.0159, recon=0.0161, feature=0.0105, kl=3.8075\n",
      "epoch 300: val loss=0.0502, val recon=0.0600, val feature=0.0404, val kl=3.8348\n",
      "Recon R2 : 0.9399283802372214, Feature R2 : 0.4353347435923139\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 15/432\n",
      "beta=0.001, noise_std=0.001, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.0169, recon=0.0159, feature=0.0114, kl=3.9120\n",
      "epoch 300: val loss=0.0526, val recon=0.0550, val feature=0.0433, val kl=3.8095\n",
      "Recon R2 : 0.9448411156709655, Feature R2 : 0.4327390030059787\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 16/432\n",
      "beta=0.001, noise_std=0.001, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.0661, recon=0.1115, feature=0.0500, kl=4.8941\n",
      "epoch 300: val loss=0.0936, val recon=0.1423, val feature=0.0745, val kl=4.8008\n",
      "Recon R2 : 0.8575558296045156, Feature R2 : 0.40193759723306915\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 17/432\n",
      "beta=0.001, noise_std=0.001, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.0630, recon=0.1038, feature=0.0477, kl=4.9161\n",
      "epoch 300: val loss=0.0929, val recon=0.1338, val feature=0.0747, val kl=4.8815\n",
      "Recon R2 : 0.8662438424268215, Feature R2 : 0.40186865344809625\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 18/432\n",
      "beta=0.001, noise_std=0.001, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.0674, recon=0.1028, feature=0.0521, kl=4.9957\n",
      "epoch 300: val loss=0.0879, val recon=0.1291, val feature=0.0702, val kl=4.8481\n",
      "Recon R2 : 0.8702072174921196, Feature R2 : 0.40631391618633655\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 19/432\n",
      "beta=0.001, noise_std=0.001, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.0157, recon=0.0157, feature=0.0107, kl=3.4777\n",
      "epoch 300: val loss=0.0520, val recon=0.0578, val feature=0.0428, val kl=3.4433\n",
      "Recon R2 : 0.9421747479930759, Feature R2 : 0.4331646095661837\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 20/432\n",
      "beta=0.001, noise_std=0.001, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.0149, recon=0.0146, feature=0.0101, kl=3.4014\n",
      "epoch 300: val loss=0.0511, val recon=0.0490, val feature=0.0427, val kl=3.4731\n",
      "Recon R2 : 0.9505617533503954, Feature R2 : 0.433385293565584\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 21/432\n",
      "beta=0.001, noise_std=0.001, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.0162, recon=0.0179, feature=0.0109, kl=3.4215\n",
      "epoch 300: val loss=0.0490, val recon=0.0538, val feature=0.0402, val kl=3.4370\n",
      "Recon R2 : 0.9462049825024317, Feature R2 : 0.43541169549260367\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 22/432\n",
      "beta=0.001, noise_std=0.001, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.0596, recon=0.0985, feature=0.0454, kl=4.3541\n",
      "epoch 300: val loss=0.0933, val recon=0.1293, val feature=0.0761, val kl=4.2864\n",
      "Recon R2 : 0.8708982798274921, Feature R2 : 0.40049851054859104\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 23/432\n",
      "beta=0.001, noise_std=0.001, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.0623, recon=0.0949, feature=0.0487, kl=4.1562\n",
      "epoch 300: val loss=0.0949, val recon=0.1250, val feature=0.0781, val kl=4.2857\n",
      "Recon R2 : 0.875181053466748, Feature R2 : 0.3987181996175759\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 24/432\n",
      "beta=0.001, noise_std=0.001, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.0622, recon=0.1006, feature=0.0480, kl=4.2092\n",
      "epoch 300: val loss=0.0896, val recon=0.1262, val feature=0.0727, val kl=4.2717\n",
      "Recon R2 : 0.8739297804586899, Feature R2 : 0.40387501876052234\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 25/432\n",
      "beta=0.001, noise_std=0.001, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.0130, recon=0.0064, feature=0.0223, kl=4.3905\n",
      "epoch 300: val loss=0.0402, val recon=0.0282, val feature=0.0768, val kl=4.3452\n",
      "Recon R2 : 0.9718200560350428, Feature R2 : 0.398840630696661\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 26/432\n",
      "beta=0.001, noise_std=0.001, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.0131, recon=0.0068, feature=0.0193, kl=4.3468\n",
      "epoch 300: val loss=0.0402, val recon=0.0283, val feature=0.0755, val kl=4.4018\n",
      "Recon R2 : 0.971743210151067, Feature R2 : 0.4000060006391804\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 27/432\n",
      "beta=0.001, noise_std=0.001, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.0132, recon=0.0065, feature=0.0237, kl=4.3199\n",
      "epoch 300: val loss=0.0364, val recon=0.0253, val feature=0.0676, val kl=4.2710\n",
      "Recon R2 : 0.9745256450753257, Feature R2 : 0.4078557051537577\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 28/432\n",
      "beta=0.001, noise_std=0.001, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.0506, recon=0.0347, feature=0.0888, kl=6.9907\n",
      "epoch 300: val loss=0.0734, val recon=0.0539, val feature=0.1259, val kl=6.8946\n",
      "Recon R2 : 0.946347097754316, Feature R2 : 0.3501541867181555\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 29/432\n",
      "beta=0.001, noise_std=0.001, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.0479, recon=0.0323, feature=0.0866, kl=6.9287\n",
      "epoch 300: val loss=0.0705, val recon=0.0520, val feature=0.1161, val kl=6.8844\n",
      "Recon R2 : 0.9483322017382174, Feature R2 : 0.35972412851752045\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 30/432\n",
      "beta=0.001, noise_std=0.001, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.0495, recon=0.0336, feature=0.0897, kl=6.9066\n",
      "epoch 300: val loss=0.0676, val recon=0.0494, val feature=0.1150, val kl=6.7463\n",
      "Recon R2 : 0.9506391358724827, Feature R2 : 0.3611985683484261\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 31/432\n",
      "beta=0.001, noise_std=0.001, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.0108, recon=0.0049, feature=0.0219, kl=3.7896\n",
      "epoch 300: val loss=0.0331, val recon=0.0226, val feature=0.0674, val kl=3.7922\n",
      "Recon R2 : 0.9772355010826582, Feature R2 : 0.4082315629055072\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 32/432\n",
      "beta=0.001, noise_std=0.001, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.0114, recon=0.0054, feature=0.0236, kl=3.6318\n",
      "epoch 300: val loss=0.0269, val recon=0.0166, val feature=0.0655, val kl=3.7583\n",
      "Recon R2 : 0.9834399317112089, Feature R2 : 0.4099598911547232\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 33/432\n",
      "beta=0.001, noise_std=0.001, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.0118, recon=0.0058, feature=0.0225, kl=3.7704\n",
      "epoch 300: val loss=0.0311, val recon=0.0205, val feature=0.0676, val kl=3.8197\n",
      "Recon R2 : 0.9793465461531033, Feature R2 : 0.4081036636652525\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 34/432\n",
      "beta=0.001, noise_std=0.001, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.0365, recon=0.0225, feature=0.0843, kl=5.5093\n",
      "epoch 300: val loss=0.0524, val recon=0.0351, val feature=0.1175, val kl=5.5227\n",
      "Recon R2 : 0.9650604605759474, Feature R2 : 0.3589901154016935\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 35/432\n",
      "beta=0.001, noise_std=0.001, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.0371, recon=0.0234, feature=0.0829, kl=5.3958\n",
      "epoch 300: val loss=0.0508, val recon=0.0344, val feature=0.1091, val kl=5.5390\n",
      "Recon R2 : 0.9654808257793153, Feature R2 : 0.3669954393316174\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 36/432\n",
      "beta=0.001, noise_std=0.001, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.0358, recon=0.0223, feature=0.0804, kl=5.4548\n",
      "epoch 300: val loss=0.0492, val recon=0.0324, val feature=0.1113, val kl=5.6039\n",
      "Recon R2 : 0.9676267449997352, Feature R2 : 0.36449843619970235\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 37/432\n",
      "beta=0.001, noise_std=0.001, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.0284, recon=0.0083, feature=0.0146, kl=5.4384\n",
      "epoch 300: val loss=0.0971, val recon=0.0337, val feature=0.0580, val kl=5.3880\n",
      "Recon R2 : 0.9662948560984752, Feature R2 : 0.41770203531849043\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 38/432\n",
      "beta=0.001, noise_std=0.001, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.0247, recon=0.0072, feature=0.0120, kl=5.3586\n",
      "epoch 300: val loss=0.0919, val recon=0.0358, val feature=0.0508, val kl=5.3674\n",
      "Recon R2 : 0.9641280620628448, Feature R2 : 0.4250838622045056\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 39/432\n",
      "beta=0.001, noise_std=0.001, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.0276, recon=0.0076, feature=0.0147, kl=5.3453\n",
      "epoch 300: val loss=0.0919, val recon=0.0350, val feature=0.0516, val kl=5.2839\n",
      "Recon R2 : 0.9651829428489889, Feature R2 : 0.42382020525336683\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 40/432\n",
      "beta=0.001, noise_std=0.001, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.1147, recon=0.0440, feature=0.0617, kl=9.0388\n",
      "epoch 300: val loss=0.1681, val recon=0.0665, val feature=0.0927, val kl=8.9714\n",
      "Recon R2 : 0.9332615454317328, Feature R2 : 0.38343646579719476\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 41/432\n",
      "beta=0.001, noise_std=0.001, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.1134, recon=0.0431, feature=0.0611, kl=9.1290\n",
      "epoch 300: val loss=0.1685, val recon=0.0660, val feature=0.0937, val kl=8.8479\n",
      "Recon R2 : 0.9342094601579762, Feature R2 : 0.3829418743252385\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 42/432\n",
      "beta=0.001, noise_std=0.001, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.1129, recon=0.0407, feature=0.0629, kl=9.3144\n",
      "epoch 300: val loss=0.1565, val recon=0.0611, val feature=0.0863, val kl=9.0777\n",
      "Recon R2 : 0.9385050494563313, Feature R2 : 0.3903481616260536\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 43/432\n",
      "beta=0.001, noise_std=0.001, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.0252, recon=0.0062, feature=0.0143, kl=4.6700\n",
      "epoch 300: val loss=0.0860, val recon=0.0275, val feature=0.0539, val kl=4.6301\n",
      "Recon R2 : 0.972352826260699, Feature R2 : 0.42191417950781274\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 44/432\n",
      "beta=0.001, noise_std=0.001, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.0253, recon=0.0058, feature=0.0151, kl=4.3836\n",
      "epoch 300: val loss=0.0690, val recon=0.0176, val feature=0.0468, val kl=4.5056\n",
      "Recon R2 : 0.9821650617319524, Feature R2 : 0.42896622549052665\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 45/432\n",
      "beta=0.001, noise_std=0.001, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.0268, recon=0.0081, feature=0.0141, kl=4.6074\n",
      "epoch 300: val loss=0.0893, val recon=0.0321, val feature=0.0525, val kl=4.6880\n",
      "Recon R2 : 0.9677197331444052, Feature R2 : 0.4232092638028895\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 46/432\n",
      "beta=0.001, noise_std=0.001, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.0956, recon=0.0312, feature=0.0573, kl=7.1472\n",
      "epoch 300: val loss=0.1405, val recon=0.0486, val feature=0.0848, val kl=7.1132\n",
      "Recon R2 : 0.9514675952993148, Feature R2 : 0.39149742610932753\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 47/432\n",
      "beta=0.001, noise_std=0.001, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.0966, recon=0.0304, feature=0.0594, kl=6.7873\n",
      "epoch 300: val loss=0.1356, val recon=0.0429, val feature=0.0857, val kl=6.9782\n",
      "Recon R2 : 0.9570794406536984, Feature R2 : 0.39051924663625265\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 48/432\n",
      "beta=0.001, noise_std=0.001, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.0955, recon=0.0337, feature=0.0548, kl=7.0446\n",
      "epoch 300: val loss=0.1397, val recon=0.0510, val feature=0.0816, val kl=7.2305\n",
      "Recon R2 : 0.9488964925175339, Feature R2 : 0.39475293548273144\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 49/432\n",
      "beta=0.001, noise_std=0.01, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.0051, recon=0.0105, feature=0.0142, kl=2.6542\n",
      "epoch 300: val loss=0.0102, val recon=0.0288, val feature=0.0465, val kl=2.6444\n",
      "Recon R2 : 0.971184121504381, Feature R2 : 0.4291942431317978\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 50/432\n",
      "beta=0.001, noise_std=0.01, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.0050, recon=0.0100, feature=0.0138, kl=2.6531\n",
      "epoch 300: val loss=0.0103, val recon=0.0300, val feature=0.0463, val kl=2.6714\n",
      "Recon R2 : 0.9699798979759202, Feature R2 : 0.4295778662486734\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 51/432\n",
      "beta=0.001, noise_std=0.01, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.0050, recon=0.0089, feature=0.0143, kl=2.6619\n",
      "epoch 300: val loss=0.0101, val recon=0.0294, val feature=0.0449, val kl=2.6467\n",
      "Recon R2 : 0.970475037566648, Feature R2 : 0.4306141143972563\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 52/432\n",
      "beta=0.001, noise_std=0.01, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.0134, recon=0.0408, feature=0.0610, kl=3.2298\n",
      "epoch 300: val loss=0.0177, val recon=0.0585, val feature=0.0866, val kl=3.1702\n",
      "Recon R2 : 0.9411154580851013, Feature R2 : 0.3892521887202418\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 53/432\n",
      "beta=0.001, noise_std=0.01, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.0130, recon=0.0409, feature=0.0570, kl=3.2130\n",
      "epoch 300: val loss=0.0178, val recon=0.0596, val feature=0.0859, val kl=3.2149\n",
      "Recon R2 : 0.9403209355360113, Feature R2 : 0.39039294115841344\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 54/432\n",
      "beta=0.001, noise_std=0.01, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.0135, recon=0.0408, feature=0.0618, kl=3.2565\n",
      "epoch 300: val loss=0.0172, val recon=0.0569, val feature=0.0832, val kl=3.2018\n",
      "Recon R2 : 0.9427618300606964, Feature R2 : 0.39286393814690146\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 55/432\n",
      "beta=0.001, noise_std=0.01, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.0045, recon=0.0082, feature=0.0135, kl=2.3319\n",
      "epoch 300: val loss=0.0095, val recon=0.0259, val feature=0.0455, val kl=2.3161\n",
      "Recon R2 : 0.9742077177935964, Feature R2 : 0.43037358275003273\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 56/432\n",
      "beta=0.001, noise_std=0.01, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.0045, recon=0.0081, feature=0.0140, kl=2.3096\n",
      "epoch 300: val loss=0.0087, val recon=0.0209, val feature=0.0420, val kl=2.3675\n",
      "Recon R2 : 0.9789481848287149, Feature R2 : 0.4338201540840763\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 57/432\n",
      "beta=0.001, noise_std=0.01, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.0047, recon=0.0095, feature=0.0138, kl=2.3310\n",
      "epoch 300: val loss=0.0100, val recon=0.0274, val feature=0.0495, val kl=2.3377\n",
      "Recon R2 : 0.9725807270796407, Feature R2 : 0.4261695770769856\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 58/432\n",
      "beta=0.001, noise_std=0.01, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.0112, recon=0.0308, feature=0.0533, kl=2.8339\n",
      "epoch 300: val loss=0.0155, val recon=0.0462, val feature=0.0805, val kl=2.8153\n",
      "Recon R2 : 0.9536277968920412, Feature R2 : 0.39553510150515325\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 59/432\n",
      "beta=0.001, noise_std=0.01, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.0110, recon=0.0291, feature=0.0533, kl=2.7197\n",
      "epoch 300: val loss=0.0147, val recon=0.0393, val feature=0.0798, val kl=2.8125\n",
      "Recon R2 : 0.9606611468912973, Feature R2 : 0.39638413026489744\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 60/432\n",
      "beta=0.001, noise_std=0.01, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.0110, recon=0.0316, feature=0.0504, kl=2.7582\n",
      "epoch 300: val loss=0.0150, val recon=0.0441, val feature=0.0774, val kl=2.8044\n",
      "Recon R2 : 0.9558149686481979, Feature R2 : 0.3984559434271242\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 61/432\n",
      "beta=0.001, noise_std=0.01, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.0165, recon=0.0192, feature=0.0107, kl=3.8488\n",
      "epoch 300: val loss=0.0489, val recon=0.0607, val feature=0.0390, val kl=3.8206\n",
      "Recon R2 : 0.9391663305552924, Feature R2 : 0.43688419133929035\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 62/432\n",
      "beta=0.001, noise_std=0.01, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.0159, recon=0.0161, feature=0.0105, kl=3.8075\n",
      "epoch 300: val loss=0.0502, val recon=0.0600, val feature=0.0404, val kl=3.8348\n",
      "Recon R2 : 0.9399283802372214, Feature R2 : 0.4353347435923139\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 63/432\n",
      "beta=0.001, noise_std=0.01, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.0169, recon=0.0159, feature=0.0114, kl=3.9120\n",
      "epoch 300: val loss=0.0526, val recon=0.0550, val feature=0.0433, val kl=3.8095\n",
      "Recon R2 : 0.9448411156709655, Feature R2 : 0.4327390030059787\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 64/432\n",
      "beta=0.001, noise_std=0.01, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.0661, recon=0.1115, feature=0.0500, kl=4.8941\n",
      "epoch 300: val loss=0.0936, val recon=0.1423, val feature=0.0745, val kl=4.8008\n",
      "Recon R2 : 0.8575558296045156, Feature R2 : 0.40193759723306915\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 65/432\n",
      "beta=0.001, noise_std=0.01, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.0630, recon=0.1038, feature=0.0477, kl=4.9161\n",
      "epoch 300: val loss=0.0929, val recon=0.1338, val feature=0.0747, val kl=4.8815\n",
      "Recon R2 : 0.8662438424268215, Feature R2 : 0.40186865344809625\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 66/432\n",
      "beta=0.001, noise_std=0.01, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.0674, recon=0.1028, feature=0.0521, kl=4.9957\n",
      "epoch 300: val loss=0.0879, val recon=0.1291, val feature=0.0702, val kl=4.8481\n",
      "Recon R2 : 0.8702072174921196, Feature R2 : 0.40631391618633655\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 67/432\n",
      "beta=0.001, noise_std=0.01, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.0157, recon=0.0157, feature=0.0107, kl=3.4777\n",
      "epoch 300: val loss=0.0520, val recon=0.0578, val feature=0.0428, val kl=3.4433\n",
      "Recon R2 : 0.9421747479930759, Feature R2 : 0.4331646095661837\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 68/432\n",
      "beta=0.001, noise_std=0.01, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.0149, recon=0.0146, feature=0.0101, kl=3.4014\n",
      "epoch 300: val loss=0.0511, val recon=0.0490, val feature=0.0427, val kl=3.4731\n",
      "Recon R2 : 0.9505617533503954, Feature R2 : 0.433385293565584\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 69/432\n",
      "beta=0.001, noise_std=0.01, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.0162, recon=0.0179, feature=0.0109, kl=3.4215\n",
      "epoch 300: val loss=0.0490, val recon=0.0538, val feature=0.0402, val kl=3.4370\n",
      "Recon R2 : 0.9462049825024317, Feature R2 : 0.43541169549260367\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 70/432\n",
      "beta=0.001, noise_std=0.01, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.0596, recon=0.0985, feature=0.0454, kl=4.3541\n",
      "epoch 300: val loss=0.0933, val recon=0.1293, val feature=0.0761, val kl=4.2864\n",
      "Recon R2 : 0.8708982798274921, Feature R2 : 0.40049851054859104\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 71/432\n",
      "beta=0.001, noise_std=0.01, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.0623, recon=0.0949, feature=0.0487, kl=4.1562\n",
      "epoch 300: val loss=0.0949, val recon=0.1250, val feature=0.0781, val kl=4.2857\n",
      "Recon R2 : 0.875181053466748, Feature R2 : 0.3987181996175759\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 72/432\n",
      "beta=0.001, noise_std=0.01, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.0622, recon=0.1006, feature=0.0480, kl=4.2092\n",
      "epoch 300: val loss=0.0896, val recon=0.1262, val feature=0.0727, val kl=4.2717\n",
      "Recon R2 : 0.8739297804586899, Feature R2 : 0.40387501876052234\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 73/432\n",
      "beta=0.001, noise_std=0.01, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.0130, recon=0.0064, feature=0.0223, kl=4.3905\n",
      "epoch 300: val loss=0.0402, val recon=0.0282, val feature=0.0768, val kl=4.3452\n",
      "Recon R2 : 0.9718200560350428, Feature R2 : 0.398840630696661\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 74/432\n",
      "beta=0.001, noise_std=0.01, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.0131, recon=0.0068, feature=0.0193, kl=4.3468\n",
      "epoch 300: val loss=0.0402, val recon=0.0283, val feature=0.0755, val kl=4.4018\n",
      "Recon R2 : 0.971743210151067, Feature R2 : 0.4000060006391804\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 75/432\n",
      "beta=0.001, noise_std=0.01, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.0132, recon=0.0065, feature=0.0237, kl=4.3199\n",
      "epoch 300: val loss=0.0364, val recon=0.0253, val feature=0.0676, val kl=4.2710\n",
      "Recon R2 : 0.9745256450753257, Feature R2 : 0.4078557051537577\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 76/432\n",
      "beta=0.001, noise_std=0.01, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.0506, recon=0.0347, feature=0.0888, kl=6.9907\n",
      "epoch 300: val loss=0.0734, val recon=0.0539, val feature=0.1259, val kl=6.8946\n",
      "Recon R2 : 0.946347097754316, Feature R2 : 0.3501541867181555\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 77/432\n",
      "beta=0.001, noise_std=0.01, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.0479, recon=0.0323, feature=0.0866, kl=6.9287\n",
      "epoch 300: val loss=0.0705, val recon=0.0520, val feature=0.1161, val kl=6.8844\n",
      "Recon R2 : 0.9483322017382174, Feature R2 : 0.35972412851752045\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 78/432\n",
      "beta=0.001, noise_std=0.01, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.0495, recon=0.0336, feature=0.0897, kl=6.9066\n",
      "epoch 300: val loss=0.0676, val recon=0.0494, val feature=0.1150, val kl=6.7463\n",
      "Recon R2 : 0.9506391358724827, Feature R2 : 0.3611985683484261\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 79/432\n",
      "beta=0.001, noise_std=0.01, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.0108, recon=0.0049, feature=0.0219, kl=3.7896\n",
      "epoch 300: val loss=0.0331, val recon=0.0226, val feature=0.0674, val kl=3.7922\n",
      "Recon R2 : 0.9772355010826582, Feature R2 : 0.4082315629055072\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 80/432\n",
      "beta=0.001, noise_std=0.01, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.0114, recon=0.0054, feature=0.0236, kl=3.6318\n",
      "epoch 300: val loss=0.0269, val recon=0.0166, val feature=0.0655, val kl=3.7583\n",
      "Recon R2 : 0.9834399317112089, Feature R2 : 0.4099598911547232\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 81/432\n",
      "beta=0.001, noise_std=0.01, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.0118, recon=0.0058, feature=0.0225, kl=3.7704\n",
      "epoch 300: val loss=0.0311, val recon=0.0205, val feature=0.0676, val kl=3.8197\n",
      "Recon R2 : 0.9793465461531033, Feature R2 : 0.4081036636652525\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 82/432\n",
      "beta=0.001, noise_std=0.01, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.0365, recon=0.0225, feature=0.0843, kl=5.5093\n",
      "epoch 300: val loss=0.0524, val recon=0.0351, val feature=0.1175, val kl=5.5227\n",
      "Recon R2 : 0.9650604605759474, Feature R2 : 0.3589901154016935\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 83/432\n",
      "beta=0.001, noise_std=0.01, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.0371, recon=0.0234, feature=0.0829, kl=5.3958\n",
      "epoch 300: val loss=0.0508, val recon=0.0344, val feature=0.1091, val kl=5.5390\n",
      "Recon R2 : 0.9654808257793153, Feature R2 : 0.3669954393316174\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 84/432\n",
      "beta=0.001, noise_std=0.01, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.0358, recon=0.0223, feature=0.0804, kl=5.4548\n",
      "epoch 300: val loss=0.0492, val recon=0.0324, val feature=0.1113, val kl=5.6039\n",
      "Recon R2 : 0.9676267449997352, Feature R2 : 0.36449843619970235\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 85/432\n",
      "beta=0.001, noise_std=0.01, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.0284, recon=0.0083, feature=0.0146, kl=5.4384\n",
      "epoch 300: val loss=0.0971, val recon=0.0337, val feature=0.0580, val kl=5.3880\n",
      "Recon R2 : 0.9662948560984752, Feature R2 : 0.41770203531849043\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 86/432\n",
      "beta=0.001, noise_std=0.01, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.0247, recon=0.0072, feature=0.0120, kl=5.3586\n",
      "epoch 300: val loss=0.0919, val recon=0.0358, val feature=0.0508, val kl=5.3674\n",
      "Recon R2 : 0.9641280620628448, Feature R2 : 0.4250838622045056\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 87/432\n",
      "beta=0.001, noise_std=0.01, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.0276, recon=0.0076, feature=0.0147, kl=5.3453\n",
      "epoch 300: val loss=0.0919, val recon=0.0350, val feature=0.0516, val kl=5.2839\n",
      "Recon R2 : 0.9651829428489889, Feature R2 : 0.42382020525336683\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 88/432\n",
      "beta=0.001, noise_std=0.01, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.1147, recon=0.0440, feature=0.0617, kl=9.0388\n",
      "epoch 300: val loss=0.1681, val recon=0.0665, val feature=0.0927, val kl=8.9714\n",
      "Recon R2 : 0.9332615454317328, Feature R2 : 0.38343646579719476\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 89/432\n",
      "beta=0.001, noise_std=0.01, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.1134, recon=0.0431, feature=0.0611, kl=9.1290\n",
      "epoch 300: val loss=0.1685, val recon=0.0660, val feature=0.0937, val kl=8.8479\n",
      "Recon R2 : 0.9342094601579762, Feature R2 : 0.3829418743252385\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 90/432\n",
      "beta=0.001, noise_std=0.01, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.1129, recon=0.0407, feature=0.0629, kl=9.3144\n",
      "epoch 300: val loss=0.1565, val recon=0.0611, val feature=0.0863, val kl=9.0777\n",
      "Recon R2 : 0.9385050494563313, Feature R2 : 0.3903481616260536\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 91/432\n",
      "beta=0.001, noise_std=0.01, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.0252, recon=0.0062, feature=0.0143, kl=4.6700\n",
      "epoch 300: val loss=0.0860, val recon=0.0275, val feature=0.0539, val kl=4.6301\n",
      "Recon R2 : 0.972352826260699, Feature R2 : 0.42191417950781274\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 92/432\n",
      "beta=0.001, noise_std=0.01, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.0253, recon=0.0058, feature=0.0151, kl=4.3836\n",
      "epoch 300: val loss=0.0690, val recon=0.0176, val feature=0.0468, val kl=4.5056\n",
      "Recon R2 : 0.9821650617319524, Feature R2 : 0.42896622549052665\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 93/432\n",
      "beta=0.001, noise_std=0.01, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.0268, recon=0.0081, feature=0.0141, kl=4.6074\n",
      "epoch 300: val loss=0.0893, val recon=0.0321, val feature=0.0525, val kl=4.6880\n",
      "Recon R2 : 0.9677197331444052, Feature R2 : 0.4232092638028895\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 94/432\n",
      "beta=0.001, noise_std=0.01, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.0956, recon=0.0312, feature=0.0573, kl=7.1472\n",
      "epoch 300: val loss=0.1405, val recon=0.0486, val feature=0.0848, val kl=7.1132\n",
      "Recon R2 : 0.9514675952993148, Feature R2 : 0.39149742610932753\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 95/432\n",
      "beta=0.001, noise_std=0.01, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.0966, recon=0.0304, feature=0.0594, kl=6.7873\n",
      "epoch 300: val loss=0.1356, val recon=0.0429, val feature=0.0857, val kl=6.9782\n",
      "Recon R2 : 0.9570794406536984, Feature R2 : 0.39051924663625265\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 96/432\n",
      "beta=0.001, noise_std=0.01, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.0955, recon=0.0337, feature=0.0548, kl=7.0446\n",
      "epoch 300: val loss=0.1397, val recon=0.0510, val feature=0.0816, val kl=7.2305\n",
      "Recon R2 : 0.9488964925175339, Feature R2 : 0.39475293548273144\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 97/432\n",
      "beta=0.001, noise_std=0.1, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.0051, recon=0.0105, feature=0.0142, kl=2.6542\n",
      "epoch 300: val loss=0.0102, val recon=0.0288, val feature=0.0465, val kl=2.6444\n",
      "Recon R2 : 0.971184121504381, Feature R2 : 0.4291942431317978\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 98/432\n",
      "beta=0.001, noise_std=0.1, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.0050, recon=0.0100, feature=0.0138, kl=2.6531\n",
      "epoch 300: val loss=0.0103, val recon=0.0300, val feature=0.0463, val kl=2.6714\n",
      "Recon R2 : 0.9699798979759202, Feature R2 : 0.4295778662486734\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 99/432\n",
      "beta=0.001, noise_std=0.1, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.0050, recon=0.0089, feature=0.0143, kl=2.6619\n",
      "epoch 300: val loss=0.0101, val recon=0.0294, val feature=0.0449, val kl=2.6467\n",
      "Recon R2 : 0.970475037566648, Feature R2 : 0.4306141143972563\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 100/432\n",
      "beta=0.001, noise_std=0.1, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.0134, recon=0.0408, feature=0.0610, kl=3.2298\n",
      "epoch 300: val loss=0.0177, val recon=0.0585, val feature=0.0866, val kl=3.1702\n",
      "Recon R2 : 0.9411154580851013, Feature R2 : 0.3892521887202418\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 101/432\n",
      "beta=0.001, noise_std=0.1, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.0130, recon=0.0409, feature=0.0570, kl=3.2130\n",
      "epoch 300: val loss=0.0178, val recon=0.0596, val feature=0.0859, val kl=3.2149\n",
      "Recon R2 : 0.9403209355360113, Feature R2 : 0.39039294115841344\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 102/432\n",
      "beta=0.001, noise_std=0.1, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.0135, recon=0.0408, feature=0.0618, kl=3.2565\n",
      "epoch 300: val loss=0.0172, val recon=0.0569, val feature=0.0832, val kl=3.2018\n",
      "Recon R2 : 0.9427618300606964, Feature R2 : 0.39286393814690146\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 103/432\n",
      "beta=0.001, noise_std=0.1, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.0045, recon=0.0082, feature=0.0135, kl=2.3319\n",
      "epoch 300: val loss=0.0095, val recon=0.0259, val feature=0.0455, val kl=2.3161\n",
      "Recon R2 : 0.9742077177935964, Feature R2 : 0.43037358275003273\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 104/432\n",
      "beta=0.001, noise_std=0.1, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.0045, recon=0.0081, feature=0.0140, kl=2.3096\n",
      "epoch 300: val loss=0.0087, val recon=0.0209, val feature=0.0420, val kl=2.3675\n",
      "Recon R2 : 0.9789481848287149, Feature R2 : 0.4338201540840763\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 105/432\n",
      "beta=0.001, noise_std=0.1, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.0047, recon=0.0095, feature=0.0138, kl=2.3310\n",
      "epoch 300: val loss=0.0100, val recon=0.0274, val feature=0.0495, val kl=2.3377\n",
      "Recon R2 : 0.9725807270796407, Feature R2 : 0.4261695770769856\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 106/432\n",
      "beta=0.001, noise_std=0.1, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.0112, recon=0.0308, feature=0.0533, kl=2.8339\n",
      "epoch 300: val loss=0.0155, val recon=0.0462, val feature=0.0805, val kl=2.8153\n",
      "Recon R2 : 0.9536277968920412, Feature R2 : 0.39553510150515325\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 107/432\n",
      "beta=0.001, noise_std=0.1, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.0110, recon=0.0291, feature=0.0533, kl=2.7197\n",
      "epoch 300: val loss=0.0147, val recon=0.0393, val feature=0.0798, val kl=2.8125\n",
      "Recon R2 : 0.9606611468912973, Feature R2 : 0.39638413026489744\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 108/432\n",
      "beta=0.001, noise_std=0.1, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.0110, recon=0.0316, feature=0.0504, kl=2.7582\n",
      "epoch 300: val loss=0.0150, val recon=0.0441, val feature=0.0774, val kl=2.8044\n",
      "Recon R2 : 0.9558149686481979, Feature R2 : 0.3984559434271242\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 109/432\n",
      "beta=0.001, noise_std=0.1, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.0165, recon=0.0192, feature=0.0107, kl=3.8488\n",
      "epoch 300: val loss=0.0489, val recon=0.0607, val feature=0.0390, val kl=3.8206\n",
      "Recon R2 : 0.9391663305552924, Feature R2 : 0.43688419133929035\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 110/432\n",
      "beta=0.001, noise_std=0.1, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.0159, recon=0.0161, feature=0.0105, kl=3.8075\n",
      "epoch 300: val loss=0.0502, val recon=0.0600, val feature=0.0404, val kl=3.8348\n",
      "Recon R2 : 0.9399283802372214, Feature R2 : 0.4353347435923139\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 111/432\n",
      "beta=0.001, noise_std=0.1, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.0169, recon=0.0159, feature=0.0114, kl=3.9120\n",
      "epoch 300: val loss=0.0526, val recon=0.0550, val feature=0.0433, val kl=3.8095\n",
      "Recon R2 : 0.9448411156709655, Feature R2 : 0.4327390030059787\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 112/432\n",
      "beta=0.001, noise_std=0.1, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.0661, recon=0.1115, feature=0.0500, kl=4.8941\n",
      "epoch 300: val loss=0.0936, val recon=0.1423, val feature=0.0745, val kl=4.8008\n",
      "Recon R2 : 0.8575558296045156, Feature R2 : 0.40193759723306915\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 113/432\n",
      "beta=0.001, noise_std=0.1, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.0630, recon=0.1038, feature=0.0477, kl=4.9161\n",
      "epoch 300: val loss=0.0929, val recon=0.1338, val feature=0.0747, val kl=4.8815\n",
      "Recon R2 : 0.8662438424268215, Feature R2 : 0.40186865344809625\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 114/432\n",
      "beta=0.001, noise_std=0.1, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.0674, recon=0.1028, feature=0.0521, kl=4.9957\n",
      "epoch 300: val loss=0.0879, val recon=0.1291, val feature=0.0702, val kl=4.8481\n",
      "Recon R2 : 0.8702072174921196, Feature R2 : 0.40631391618633655\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 115/432\n",
      "beta=0.001, noise_std=0.1, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.0157, recon=0.0157, feature=0.0107, kl=3.4777\n",
      "epoch 300: val loss=0.0520, val recon=0.0578, val feature=0.0428, val kl=3.4433\n",
      "Recon R2 : 0.9421747479930759, Feature R2 : 0.4331646095661837\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 116/432\n",
      "beta=0.001, noise_std=0.1, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.0149, recon=0.0146, feature=0.0101, kl=3.4014\n",
      "epoch 300: val loss=0.0511, val recon=0.0490, val feature=0.0427, val kl=3.4731\n",
      "Recon R2 : 0.9505617533503954, Feature R2 : 0.433385293565584\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 117/432\n",
      "beta=0.001, noise_std=0.1, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.0162, recon=0.0179, feature=0.0109, kl=3.4215\n",
      "epoch 300: val loss=0.0490, val recon=0.0538, val feature=0.0402, val kl=3.4370\n",
      "Recon R2 : 0.9462049825024317, Feature R2 : 0.43541169549260367\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 118/432\n",
      "beta=0.001, noise_std=0.1, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.0596, recon=0.0985, feature=0.0454, kl=4.3541\n",
      "epoch 300: val loss=0.0933, val recon=0.1293, val feature=0.0761, val kl=4.2864\n",
      "Recon R2 : 0.8708982798274921, Feature R2 : 0.40049851054859104\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 119/432\n",
      "beta=0.001, noise_std=0.1, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.0623, recon=0.0949, feature=0.0487, kl=4.1562\n",
      "epoch 300: val loss=0.0949, val recon=0.1250, val feature=0.0781, val kl=4.2857\n",
      "Recon R2 : 0.875181053466748, Feature R2 : 0.3987181996175759\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 120/432\n",
      "beta=0.001, noise_std=0.1, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.0622, recon=0.1006, feature=0.0480, kl=4.2092\n",
      "epoch 300: val loss=0.0896, val recon=0.1262, val feature=0.0727, val kl=4.2717\n",
      "Recon R2 : 0.8739297804586899, Feature R2 : 0.40387501876052234\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 121/432\n",
      "beta=0.001, noise_std=0.1, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.0130, recon=0.0064, feature=0.0223, kl=4.3905\n",
      "epoch 300: val loss=0.0402, val recon=0.0282, val feature=0.0768, val kl=4.3452\n",
      "Recon R2 : 0.9718200560350428, Feature R2 : 0.398840630696661\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 122/432\n",
      "beta=0.001, noise_std=0.1, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.0131, recon=0.0068, feature=0.0193, kl=4.3468\n",
      "epoch 300: val loss=0.0402, val recon=0.0283, val feature=0.0755, val kl=4.4018\n",
      "Recon R2 : 0.971743210151067, Feature R2 : 0.4000060006391804\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 123/432\n",
      "beta=0.001, noise_std=0.1, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.0132, recon=0.0065, feature=0.0237, kl=4.3199\n",
      "epoch 300: val loss=0.0364, val recon=0.0253, val feature=0.0676, val kl=4.2710\n",
      "Recon R2 : 0.9745256450753257, Feature R2 : 0.4078557051537577\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 124/432\n",
      "beta=0.001, noise_std=0.1, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.0506, recon=0.0347, feature=0.0888, kl=6.9907\n",
      "epoch 300: val loss=0.0734, val recon=0.0539, val feature=0.1259, val kl=6.8946\n",
      "Recon R2 : 0.946347097754316, Feature R2 : 0.3501541867181555\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 125/432\n",
      "beta=0.001, noise_std=0.1, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.0479, recon=0.0323, feature=0.0866, kl=6.9287\n",
      "epoch 300: val loss=0.0705, val recon=0.0520, val feature=0.1161, val kl=6.8844\n",
      "Recon R2 : 0.9483322017382174, Feature R2 : 0.35972412851752045\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 126/432\n",
      "beta=0.001, noise_std=0.1, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.0495, recon=0.0336, feature=0.0897, kl=6.9066\n",
      "epoch 300: val loss=0.0676, val recon=0.0494, val feature=0.1150, val kl=6.7463\n",
      "Recon R2 : 0.9506391358724827, Feature R2 : 0.3611985683484261\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 127/432\n",
      "beta=0.001, noise_std=0.1, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.0108, recon=0.0049, feature=0.0219, kl=3.7896\n",
      "epoch 300: val loss=0.0331, val recon=0.0226, val feature=0.0674, val kl=3.7922\n",
      "Recon R2 : 0.9772355010826582, Feature R2 : 0.4082315629055072\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 128/432\n",
      "beta=0.001, noise_std=0.1, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.0114, recon=0.0054, feature=0.0236, kl=3.6318\n",
      "epoch 300: val loss=0.0269, val recon=0.0166, val feature=0.0655, val kl=3.7583\n",
      "Recon R2 : 0.9834399317112089, Feature R2 : 0.4099598911547232\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 129/432\n",
      "beta=0.001, noise_std=0.1, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.0118, recon=0.0058, feature=0.0225, kl=3.7704\n",
      "epoch 300: val loss=0.0311, val recon=0.0205, val feature=0.0676, val kl=3.8197\n",
      "Recon R2 : 0.9793465461531033, Feature R2 : 0.4081036636652525\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 130/432\n",
      "beta=0.001, noise_std=0.1, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.0365, recon=0.0225, feature=0.0843, kl=5.5093\n",
      "epoch 300: val loss=0.0524, val recon=0.0351, val feature=0.1175, val kl=5.5227\n",
      "Recon R2 : 0.9650604605759474, Feature R2 : 0.3589901154016935\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 131/432\n",
      "beta=0.001, noise_std=0.1, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.0371, recon=0.0234, feature=0.0829, kl=5.3958\n",
      "epoch 300: val loss=0.0508, val recon=0.0344, val feature=0.1091, val kl=5.5390\n",
      "Recon R2 : 0.9654808257793153, Feature R2 : 0.3669954393316174\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 132/432\n",
      "beta=0.001, noise_std=0.1, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.0358, recon=0.0223, feature=0.0804, kl=5.4548\n",
      "epoch 300: val loss=0.0492, val recon=0.0324, val feature=0.1113, val kl=5.6039\n",
      "Recon R2 : 0.9676267449997352, Feature R2 : 0.36449843619970235\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 133/432\n",
      "beta=0.001, noise_std=0.1, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.0284, recon=0.0083, feature=0.0146, kl=5.4384\n",
      "epoch 300: val loss=0.0971, val recon=0.0337, val feature=0.0580, val kl=5.3880\n",
      "Recon R2 : 0.9662948560984752, Feature R2 : 0.41770203531849043\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 134/432\n",
      "beta=0.001, noise_std=0.1, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.0247, recon=0.0072, feature=0.0120, kl=5.3586\n",
      "epoch 300: val loss=0.0919, val recon=0.0358, val feature=0.0508, val kl=5.3674\n",
      "Recon R2 : 0.9641280620628448, Feature R2 : 0.4250838622045056\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 135/432\n",
      "beta=0.001, noise_std=0.1, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.0276, recon=0.0076, feature=0.0147, kl=5.3453\n",
      "epoch 300: val loss=0.0919, val recon=0.0350, val feature=0.0516, val kl=5.2839\n",
      "Recon R2 : 0.9651829428489889, Feature R2 : 0.42382020525336683\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 136/432\n",
      "beta=0.001, noise_std=0.1, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.1147, recon=0.0440, feature=0.0617, kl=9.0388\n",
      "epoch 300: val loss=0.1681, val recon=0.0665, val feature=0.0927, val kl=8.9714\n",
      "Recon R2 : 0.9332615454317328, Feature R2 : 0.38343646579719476\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 137/432\n",
      "beta=0.001, noise_std=0.1, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.1134, recon=0.0431, feature=0.0611, kl=9.1290\n",
      "epoch 300: val loss=0.1685, val recon=0.0660, val feature=0.0937, val kl=8.8479\n",
      "Recon R2 : 0.9342094601579762, Feature R2 : 0.3829418743252385\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 138/432\n",
      "beta=0.001, noise_std=0.1, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.1129, recon=0.0407, feature=0.0629, kl=9.3144\n",
      "epoch 300: val loss=0.1565, val recon=0.0611, val feature=0.0863, val kl=9.0777\n",
      "Recon R2 : 0.9385050494563313, Feature R2 : 0.3903481616260536\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 139/432\n",
      "beta=0.001, noise_std=0.1, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.0252, recon=0.0062, feature=0.0143, kl=4.6700\n",
      "epoch 300: val loss=0.0860, val recon=0.0275, val feature=0.0539, val kl=4.6301\n",
      "Recon R2 : 0.972352826260699, Feature R2 : 0.42191417950781274\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 140/432\n",
      "beta=0.001, noise_std=0.1, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.0253, recon=0.0058, feature=0.0151, kl=4.3836\n",
      "epoch 300: val loss=0.0690, val recon=0.0176, val feature=0.0468, val kl=4.5056\n",
      "Recon R2 : 0.9821650617319524, Feature R2 : 0.42896622549052665\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 141/432\n",
      "beta=0.001, noise_std=0.1, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.0268, recon=0.0081, feature=0.0141, kl=4.6074\n",
      "epoch 300: val loss=0.0893, val recon=0.0321, val feature=0.0525, val kl=4.6880\n",
      "Recon R2 : 0.9677197331444052, Feature R2 : 0.4232092638028895\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 142/432\n",
      "beta=0.001, noise_std=0.1, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.0956, recon=0.0312, feature=0.0573, kl=7.1472\n",
      "epoch 300: val loss=0.1405, val recon=0.0486, val feature=0.0848, val kl=7.1132\n",
      "Recon R2 : 0.9514675952993148, Feature R2 : 0.39149742610932753\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 143/432\n",
      "beta=0.001, noise_std=0.1, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.0966, recon=0.0304, feature=0.0594, kl=6.7873\n",
      "epoch 300: val loss=0.1356, val recon=0.0429, val feature=0.0857, val kl=6.9782\n",
      "Recon R2 : 0.9570794406536984, Feature R2 : 0.39051924663625265\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 144/432\n",
      "beta=0.001, noise_std=0.1, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.0955, recon=0.0337, feature=0.0548, kl=7.0446\n",
      "epoch 300: val loss=0.1397, val recon=0.0510, val feature=0.0816, val kl=7.2305\n",
      "Recon R2 : 0.9488964925175339, Feature R2 : 0.39475293548273144\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 145/432\n",
      "beta=0.01, noise_std=0.001, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.0161, recon=0.0324, feature=0.0268, kl=1.0227\n",
      "epoch 300: val loss=0.0187, val recon=0.0386, val feature=0.0471, val kl=1.0173\n",
      "Recon R2 : 0.9614616517356505, Feature R2 : 0.42845457993303093\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 146/432\n",
      "beta=0.01, noise_std=0.001, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.0157, recon=0.0324, feature=0.0256, kl=0.9911\n",
      "epoch 300: val loss=0.0187, val recon=0.0414, val feature=0.0464, val kl=0.9967\n",
      "Recon R2 : 0.958638098642858, Feature R2 : 0.42910951962317323\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 147/432\n",
      "beta=0.01, noise_std=0.001, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.0164, recon=0.0328, feature=0.0292, kl=1.0197\n",
      "epoch 300: val loss=0.0185, val recon=0.0381, val feature=0.0458, val kl=1.0067\n",
      "Recon R2 : 0.9617383160773743, Feature R2 : 0.42963790363691107\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 148/432\n",
      "beta=0.01, noise_std=0.001, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.0290, recon=0.0803, feature=0.0794, kl=1.2998\n",
      "epoch 300: val loss=0.0292, val recon=0.0722, val feature=0.0914, val kl=1.2826\n",
      "Recon R2 : 0.9276542024722503, Feature R2 : 0.38429011652240774\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 149/432\n",
      "beta=0.01, noise_std=0.001, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.0289, recon=0.0788, feature=0.0795, kl=1.3033\n",
      "epoch 300: val loss=0.0292, val recon=0.0701, val feature=0.0919, val kl=1.3024\n",
      "Recon R2 : 0.9298965505627633, Feature R2 : 0.3839980792303761\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 150/432\n",
      "beta=0.01, noise_std=0.001, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.0294, recon=0.0784, feature=0.0830, kl=1.3297\n",
      "epoch 300: val loss=0.0285, val recon=0.0660, val feature=0.0888, val kl=1.3011\n",
      "Recon R2 : 0.9338014539805932, Feature R2 : 0.3871724548765588\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 151/432\n",
      "beta=0.01, noise_std=0.001, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.0111, recon=0.0214, feature=0.0209, kl=0.6917\n",
      "epoch 300: val loss=0.0142, val recon=0.0328, val feature=0.0410, val kl=0.6828\n",
      "Recon R2 : 0.9672433530312687, Feature R2 : 0.43463052881458586\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 152/432\n",
      "beta=0.01, noise_std=0.001, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.0111, recon=0.0221, feature=0.0212, kl=0.6747\n",
      "epoch 300: val loss=0.0141, val recon=0.0310, val feature=0.0408, val kl=0.6892\n",
      "Recon R2 : 0.9690569836419711, Feature R2 : 0.43475492697990137\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 153/432\n",
      "beta=0.01, noise_std=0.001, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.0116, recon=0.0239, feature=0.0224, kl=0.6964\n",
      "epoch 300: val loss=0.0149, val recon=0.0349, val feature=0.0443, val kl=0.7001\n",
      "Recon R2 : 0.9651156844897499, Feature R2 : 0.4309758742699988\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 154/432\n",
      "beta=0.01, noise_std=0.001, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.0245, recon=0.0679, feature=0.0716, kl=1.0578\n",
      "epoch 300: val loss=0.0254, val recon=0.0643, val feature=0.0859, val kl=1.0430\n",
      "Recon R2 : 0.9360351148946038, Feature R2 : 0.3899623284714603\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 155/432\n",
      "beta=0.01, noise_std=0.001, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.0239, recon=0.0652, feature=0.0721, kl=1.0171\n",
      "epoch 300: val loss=0.0247, val recon=0.0571, val feature=0.0848, val kl=1.0507\n",
      "Recon R2 : 0.9429952646023843, Feature R2 : 0.39119935960985514\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 156/432\n",
      "beta=0.01, noise_std=0.001, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.0242, recon=0.0682, feature=0.0692, kl=1.0467\n",
      "epoch 300: val loss=0.0247, val recon=0.0576, val feature=0.0834, val kl=1.0573\n",
      "Recon R2 : 0.9424044426235639, Feature R2 : 0.3922512838815451\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 157/432\n",
      "beta=0.01, noise_std=0.001, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.0350, recon=0.0307, feature=0.0137, kl=1.8229\n",
      "epoch 300: val loss=0.0583, val recon=0.0669, val feature=0.0336, val kl=1.8051\n",
      "Recon R2 : 0.9330167368251313, Feature R2 : 0.44211340946395605\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 158/432\n",
      "beta=0.01, noise_std=0.001, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.0346, recon=0.0293, feature=0.0135, kl=1.8202\n",
      "epoch 300: val loss=0.0623, val recon=0.0635, val feature=0.0378, val kl=1.8146\n",
      "Recon R2 : 0.9364553442121852, Feature R2 : 0.43777329376275553\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 159/432\n",
      "beta=0.01, noise_std=0.001, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.0366, recon=0.0289, feature=0.0150, kl=1.8762\n",
      "epoch 300: val loss=0.0627, val recon=0.0576, val feature=0.0387, val kl=1.8280\n",
      "Recon R2 : 0.9420328117460091, Feature R2 : 0.4368279138626338\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 160/432\n",
      "beta=0.01, noise_std=0.001, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.0849, recon=0.1250, feature=0.0514, kl=2.0909\n",
      "epoch 300: val loss=0.1090, val recon=0.1408, val feature=0.0743, val kl=2.0575\n",
      "Recon R2 : 0.85891983492165, Feature R2 : 0.40207622088157013\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 161/432\n",
      "beta=0.01, noise_std=0.001, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.0836, recon=0.1211, feature=0.0504, kl=2.1126\n",
      "epoch 300: val loss=0.1110, val recon=0.1377, val feature=0.0762, val kl=2.1106\n",
      "Recon R2 : 0.861933799138886, Feature R2 : 0.40032330654929327\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 162/432\n",
      "beta=0.01, noise_std=0.001, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.0867, recon=0.1077, feature=0.0544, kl=2.1533\n",
      "epoch 300: val loss=0.1042, val recon=0.1219, val feature=0.0710, val kl=2.1015\n",
      "Recon R2 : 0.8769225268289389, Feature R2 : 0.4052795136954722\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 163/432\n",
      "beta=0.01, noise_std=0.001, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.0302, recon=0.0253, feature=0.0129, kl=1.4818\n",
      "epoch 300: val loss=0.0610, val recon=0.0647, val feature=0.0398, val kl=1.4767\n",
      "Recon R2 : 0.9351854104809281, Feature R2 : 0.43598099018585607\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 164/432\n",
      "beta=0.01, noise_std=0.001, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.0296, recon=0.0262, feature=0.0123, kl=1.4645\n",
      "epoch 300: val loss=0.0601, val recon=0.0553, val feature=0.0396, val kl=1.4988\n",
      "Recon R2 : 0.9442282061886603, Feature R2 : 0.4362853769080156\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 165/432\n",
      "beta=0.01, noise_std=0.001, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.0295, recon=0.0280, feature=0.0126, kl=1.4072\n",
      "epoch 300: val loss=0.0581, val recon=0.0636, val feature=0.0376, val kl=1.4166\n",
      "Recon R2 : 0.936301778108365, Feature R2 : 0.4379510622837249\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 166/432\n",
      "beta=0.01, noise_std=0.001, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.0744, recon=0.1082, feature=0.0452, kl=1.8289\n",
      "epoch 300: val loss=0.1032, val recon=0.1347, val feature=0.0717, val kl=1.8036\n",
      "Recon R2 : 0.8652560760793422, Feature R2 : 0.4047274978743948\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 167/432\n",
      "beta=0.01, noise_std=0.001, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.0773, recon=0.0997, feature=0.0494, kl=1.7848\n",
      "epoch 300: val loss=0.1034, val recon=0.1194, val feature=0.0731, val kl=1.8317\n",
      "Recon R2 : 0.8804169777178767, Feature R2 : 0.40350411369212924\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 168/432\n",
      "beta=0.01, noise_std=0.001, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.0780, recon=0.1120, feature=0.0488, kl=1.8021\n",
      "epoch 300: val loss=0.1018, val recon=0.1273, val feature=0.0709, val kl=1.8197\n",
      "Recon R2 : 0.8725952064239957, Feature R2 : 0.405540410323286\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 169/432\n",
      "beta=0.01, noise_std=0.001, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.0362, recon=0.0103, feature=0.0257, kl=2.3282\n",
      "epoch 300: val loss=0.0535, val recon=0.0239, val feature=0.0636, val kl=2.3295\n",
      "Recon R2 : 0.9760446734869779, Feature R2 : 0.4122340275737026\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 170/432\n",
      "beta=0.01, noise_std=0.001, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.0356, recon=0.0101, feature=0.0239, kl=2.3152\n",
      "epoch 300: val loss=0.0544, val recon=0.0250, val feature=0.0627, val kl=2.3151\n",
      "Recon R2 : 0.975142898195726, Feature R2 : 0.41294447955609\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 171/432\n",
      "beta=0.01, noise_std=0.001, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.0357, recon=0.0101, feature=0.0246, kl=2.3199\n",
      "epoch 300: val loss=0.0503, val recon=0.0212, val feature=0.0608, val kl=2.2968\n",
      "Recon R2 : 0.9786208690864083, Feature R2 : 0.414456186340007\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 172/432\n",
      "beta=0.01, noise_std=0.001, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.0710, recon=0.0352, feature=0.0877, kl=2.7049\n",
      "epoch 300: val loss=0.0905, val recon=0.0514, val feature=0.1229, val kl=2.6816\n",
      "Recon R2 : 0.9490056482307407, Feature R2 : 0.3533062150347134\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 173/432\n",
      "beta=0.01, noise_std=0.001, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.0682, recon=0.0329, feature=0.0838, kl=2.6892\n",
      "epoch 300: val loss=0.0846, val recon=0.0463, val feature=0.1123, val kl=2.7072\n",
      "Recon R2 : 0.9539723039816579, Feature R2 : 0.3635761676727664\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 174/432\n",
      "beta=0.01, noise_std=0.001, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.0714, recon=0.0351, feature=0.0912, kl=2.7196\n",
      "epoch 300: val loss=0.0839, val recon=0.0457, val feature=0.1132, val kl=2.6881\n",
      "Recon R2 : 0.9543478693670331, Feature R2 : 0.3629109431103774\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 175/432\n",
      "beta=0.01, noise_std=0.001, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.0309, recon=0.0093, feature=0.0235, kl=1.9185\n",
      "epoch 300: val loss=0.0451, val recon=0.0197, val feature=0.0614, val kl=1.9216\n",
      "Recon R2 : 0.9802503020269342, Feature R2 : 0.41402489128746295\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 176/432\n",
      "beta=0.01, noise_std=0.001, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.0305, recon=0.0093, feature=0.0226, kl=1.8990\n",
      "epoch 300: val loss=0.0406, val recon=0.0156, val feature=0.0541, val kl=1.9583\n",
      "Recon R2 : 0.9843935041027596, Feature R2 : 0.4211632791573414\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 177/432\n",
      "beta=0.01, noise_std=0.001, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.0311, recon=0.0094, feature=0.0234, kl=1.9409\n",
      "epoch 300: val loss=0.0464, val recon=0.0205, val feature=0.0638, val kl=1.9445\n",
      "Recon R2 : 0.9793571669783492, Feature R2 : 0.4118219665072368\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 178/432\n",
      "beta=0.01, noise_std=0.001, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.0551, recon=0.0239, feature=0.0774, kl=2.3510\n",
      "epoch 300: val loss=0.0676, val recon=0.0335, val feature=0.1059, val kl=2.3543\n",
      "Recon R2 : 0.9666240374822258, Feature R2 : 0.3700300367739614\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 179/432\n",
      "beta=0.01, noise_std=0.001, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.0544, recon=0.0239, feature=0.0782, kl=2.2710\n",
      "epoch 300: val loss=0.0641, val recon=0.0299, val feature=0.1052, val kl=2.3615\n",
      "Recon R2 : 0.9699852957679834, Feature R2 : 0.370776561878524\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 180/432\n",
      "beta=0.01, noise_std=0.001, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.0558, recon=0.0249, feature=0.0773, kl=2.3182\n",
      "epoch 300: val loss=0.0637, val recon=0.0299, val feature=0.1028, val kl=2.3542\n",
      "Recon R2 : 0.9702057845608518, Feature R2 : 0.3729164351561455\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 181/432\n",
      "beta=0.01, noise_std=0.001, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.0509, recon=0.0095, feature=0.0146, kl=2.6764\n",
      "epoch 300: val loss=0.1067, val recon=0.0312, val feature=0.0489, val kl=2.6637\n",
      "Recon R2 : 0.9687609133925039, Feature R2 : 0.4269909114820794\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 182/432\n",
      "beta=0.01, noise_std=0.001, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.0507, recon=0.0100, feature=0.0143, kl=2.6409\n",
      "epoch 300: val loss=0.1059, val recon=0.0302, val feature=0.0491, val kl=2.6520\n",
      "Recon R2 : 0.9697345033885831, Feature R2 : 0.426708007965318\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 183/432\n",
      "beta=0.01, noise_std=0.001, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.0495, recon=0.0091, feature=0.0137, kl=2.6612\n",
      "epoch 300: val loss=0.1002, val recon=0.0280, val feature=0.0459, val kl=2.6397\n",
      "Recon R2 : 0.9718682180342338, Feature R2 : 0.42952124983306017\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 184/432\n",
      "beta=0.01, noise_std=0.001, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.1329, recon=0.0397, feature=0.0609, kl=3.2274\n",
      "epoch 300: val loss=0.1759, val recon=0.0577, val feature=0.0865, val kl=3.1698\n",
      "Recon R2 : 0.9419300824820056, Feature R2 : 0.38937647594797725\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 185/432\n",
      "beta=0.01, noise_std=0.001, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.1307, recon=0.0413, feature=0.0571, kl=3.2215\n",
      "epoch 300: val loss=0.1776, val recon=0.0593, val feature=0.0862, val kl=3.2201\n",
      "Recon R2 : 0.9406694472433538, Feature R2 : 0.39009294146978085\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 186/432\n",
      "beta=0.01, noise_std=0.001, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.1342, recon=0.0399, feature=0.0617, kl=3.2575\n",
      "epoch 300: val loss=0.1714, val recon=0.0562, val feature=0.0831, val kl=3.2028\n",
      "Recon R2 : 0.9434590379002816, Feature R2 : 0.3929664638128839\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 187/432\n",
      "beta=0.01, noise_std=0.001, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.0466, recon=0.0082, feature=0.0152, kl=2.3218\n",
      "epoch 300: val loss=0.0961, val recon=0.0264, val feature=0.0465, val kl=2.3160\n",
      "Recon R2 : 0.9735287628373521, Feature R2 : 0.42924592004024015\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 188/432\n",
      "beta=0.01, noise_std=0.001, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.0439, recon=0.0083, feature=0.0128, kl=2.2830\n",
      "epoch 300: val loss=0.0849, val recon=0.0189, val feature=0.0426, val kl=2.3370\n",
      "Recon R2 : 0.9809714846214616, Feature R2 : 0.4330642417180857\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 189/432\n",
      "beta=0.01, noise_std=0.001, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.0487, recon=0.0107, feature=0.0149, kl=2.3053\n",
      "epoch 300: val loss=0.1007, val recon=0.0299, val feature=0.0476, val kl=2.3111\n",
      "Recon R2 : 0.9700841622815661, Feature R2 : 0.4282406702795833\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 190/432\n",
      "beta=0.01, noise_std=0.001, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.1106, recon=0.0300, feature=0.0523, kl=2.8292\n",
      "epoch 300: val loss=0.1525, val recon=0.0447, val feature=0.0797, val kl=2.8129\n",
      "Recon R2 : 0.9551782183990358, Feature R2 : 0.39640878076978764\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 191/432\n",
      "beta=0.01, noise_std=0.001, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.1094, recon=0.0289, feature=0.0533, kl=2.7205\n",
      "epoch 300: val loss=0.1475, val recon=0.0397, val feature=0.0797, val kl=2.8152\n",
      "Recon R2 : 0.9602677124728248, Feature R2 : 0.3965963181144025\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 192/432\n",
      "beta=0.01, noise_std=0.001, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.1077, recon=0.0306, feature=0.0495, kl=2.7657\n",
      "epoch 300: val loss=0.1492, val recon=0.0441, val feature=0.0769, val kl=2.8134\n",
      "Recon R2 : 0.9557484877817978, Feature R2 : 0.3989926832330496\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 193/432\n",
      "beta=0.01, noise_std=0.01, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.0161, recon=0.0324, feature=0.0268, kl=1.0227\n",
      "epoch 300: val loss=0.0187, val recon=0.0386, val feature=0.0471, val kl=1.0173\n",
      "Recon R2 : 0.9614616517356505, Feature R2 : 0.42845457993303093\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 194/432\n",
      "beta=0.01, noise_std=0.01, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.0157, recon=0.0324, feature=0.0256, kl=0.9911\n",
      "epoch 300: val loss=0.0187, val recon=0.0414, val feature=0.0464, val kl=0.9967\n",
      "Recon R2 : 0.958638098642858, Feature R2 : 0.42910951962317323\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 195/432\n",
      "beta=0.01, noise_std=0.01, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.0164, recon=0.0328, feature=0.0292, kl=1.0197\n",
      "epoch 300: val loss=0.0185, val recon=0.0381, val feature=0.0458, val kl=1.0067\n",
      "Recon R2 : 0.9617383160773743, Feature R2 : 0.42963790363691107\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 196/432\n",
      "beta=0.01, noise_std=0.01, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.0290, recon=0.0803, feature=0.0794, kl=1.2998\n",
      "epoch 300: val loss=0.0292, val recon=0.0722, val feature=0.0914, val kl=1.2826\n",
      "Recon R2 : 0.9276542024722503, Feature R2 : 0.38429011652240774\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 197/432\n",
      "beta=0.01, noise_std=0.01, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.0289, recon=0.0788, feature=0.0795, kl=1.3033\n",
      "epoch 300: val loss=0.0292, val recon=0.0701, val feature=0.0919, val kl=1.3024\n",
      "Recon R2 : 0.9298965505627633, Feature R2 : 0.3839980792303761\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 198/432\n",
      "beta=0.01, noise_std=0.01, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.0294, recon=0.0784, feature=0.0830, kl=1.3297\n",
      "epoch 300: val loss=0.0285, val recon=0.0660, val feature=0.0888, val kl=1.3011\n",
      "Recon R2 : 0.9338014539805932, Feature R2 : 0.3871724548765588\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 199/432\n",
      "beta=0.01, noise_std=0.01, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.0111, recon=0.0214, feature=0.0209, kl=0.6917\n",
      "epoch 300: val loss=0.0142, val recon=0.0328, val feature=0.0410, val kl=0.6828\n",
      "Recon R2 : 0.9672433530312687, Feature R2 : 0.43463052881458586\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 200/432\n",
      "beta=0.01, noise_std=0.01, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.0111, recon=0.0221, feature=0.0212, kl=0.6747\n",
      "epoch 300: val loss=0.0141, val recon=0.0310, val feature=0.0408, val kl=0.6892\n",
      "Recon R2 : 0.9690569836419711, Feature R2 : 0.43475492697990137\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 201/432\n",
      "beta=0.01, noise_std=0.01, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.0116, recon=0.0239, feature=0.0224, kl=0.6964\n",
      "epoch 300: val loss=0.0149, val recon=0.0349, val feature=0.0443, val kl=0.7001\n",
      "Recon R2 : 0.9651156844897499, Feature R2 : 0.4309758742699988\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 202/432\n",
      "beta=0.01, noise_std=0.01, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.0245, recon=0.0679, feature=0.0716, kl=1.0578\n",
      "epoch 300: val loss=0.0254, val recon=0.0643, val feature=0.0859, val kl=1.0430\n",
      "Recon R2 : 0.9360351148946038, Feature R2 : 0.3899623284714603\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 203/432\n",
      "beta=0.01, noise_std=0.01, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.0239, recon=0.0652, feature=0.0721, kl=1.0171\n",
      "epoch 300: val loss=0.0247, val recon=0.0571, val feature=0.0848, val kl=1.0507\n",
      "Recon R2 : 0.9429952646023843, Feature R2 : 0.39119935960985514\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 204/432\n",
      "beta=0.01, noise_std=0.01, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.0242, recon=0.0682, feature=0.0692, kl=1.0467\n",
      "epoch 300: val loss=0.0247, val recon=0.0576, val feature=0.0834, val kl=1.0573\n",
      "Recon R2 : 0.9424044426235639, Feature R2 : 0.3922512838815451\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 205/432\n",
      "beta=0.01, noise_std=0.01, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.0350, recon=0.0307, feature=0.0137, kl=1.8229\n",
      "epoch 300: val loss=0.0583, val recon=0.0669, val feature=0.0336, val kl=1.8051\n",
      "Recon R2 : 0.9330167368251313, Feature R2 : 0.44211340946395605\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 206/432\n",
      "beta=0.01, noise_std=0.01, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.0346, recon=0.0293, feature=0.0135, kl=1.8202\n",
      "epoch 300: val loss=0.0623, val recon=0.0635, val feature=0.0378, val kl=1.8146\n",
      "Recon R2 : 0.9364553442121852, Feature R2 : 0.43777329376275553\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 207/432\n",
      "beta=0.01, noise_std=0.01, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.0366, recon=0.0289, feature=0.0150, kl=1.8762\n",
      "epoch 300: val loss=0.0627, val recon=0.0576, val feature=0.0387, val kl=1.8280\n",
      "Recon R2 : 0.9420328117460091, Feature R2 : 0.4368279138626338\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 208/432\n",
      "beta=0.01, noise_std=0.01, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.0849, recon=0.1250, feature=0.0514, kl=2.0909\n",
      "epoch 300: val loss=0.1090, val recon=0.1408, val feature=0.0743, val kl=2.0575\n",
      "Recon R2 : 0.85891983492165, Feature R2 : 0.40207622088157013\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 209/432\n",
      "beta=0.01, noise_std=0.01, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.0836, recon=0.1211, feature=0.0504, kl=2.1126\n",
      "epoch 300: val loss=0.1110, val recon=0.1377, val feature=0.0762, val kl=2.1106\n",
      "Recon R2 : 0.861933799138886, Feature R2 : 0.40032330654929327\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 210/432\n",
      "beta=0.01, noise_std=0.01, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.0867, recon=0.1077, feature=0.0544, kl=2.1533\n",
      "epoch 300: val loss=0.1042, val recon=0.1219, val feature=0.0710, val kl=2.1015\n",
      "Recon R2 : 0.8769225268289389, Feature R2 : 0.4052795136954722\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 211/432\n",
      "beta=0.01, noise_std=0.01, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.0302, recon=0.0253, feature=0.0129, kl=1.4818\n",
      "epoch 300: val loss=0.0610, val recon=0.0647, val feature=0.0398, val kl=1.4767\n",
      "Recon R2 : 0.9351854104809281, Feature R2 : 0.43598099018585607\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 212/432\n",
      "beta=0.01, noise_std=0.01, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.0296, recon=0.0262, feature=0.0123, kl=1.4645\n",
      "epoch 300: val loss=0.0601, val recon=0.0553, val feature=0.0396, val kl=1.4988\n",
      "Recon R2 : 0.9442282061886603, Feature R2 : 0.4362853769080156\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 213/432\n",
      "beta=0.01, noise_std=0.01, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.0295, recon=0.0280, feature=0.0126, kl=1.4072\n",
      "epoch 300: val loss=0.0581, val recon=0.0636, val feature=0.0376, val kl=1.4166\n",
      "Recon R2 : 0.936301778108365, Feature R2 : 0.4379510622837249\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 214/432\n",
      "beta=0.01, noise_std=0.01, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.0744, recon=0.1082, feature=0.0452, kl=1.8289\n",
      "epoch 300: val loss=0.1032, val recon=0.1347, val feature=0.0717, val kl=1.8036\n",
      "Recon R2 : 0.8652560760793422, Feature R2 : 0.4047274978743948\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 215/432\n",
      "beta=0.01, noise_std=0.01, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.0773, recon=0.0997, feature=0.0494, kl=1.7848\n",
      "epoch 300: val loss=0.1034, val recon=0.1194, val feature=0.0731, val kl=1.8317\n",
      "Recon R2 : 0.8804169777178767, Feature R2 : 0.40350411369212924\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 216/432\n",
      "beta=0.01, noise_std=0.01, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.0780, recon=0.1120, feature=0.0488, kl=1.8021\n",
      "epoch 300: val loss=0.1018, val recon=0.1273, val feature=0.0709, val kl=1.8197\n",
      "Recon R2 : 0.8725952064239957, Feature R2 : 0.405540410323286\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 217/432\n",
      "beta=0.01, noise_std=0.01, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.0362, recon=0.0103, feature=0.0257, kl=2.3282\n",
      "epoch 300: val loss=0.0535, val recon=0.0239, val feature=0.0636, val kl=2.3295\n",
      "Recon R2 : 0.9760446734869779, Feature R2 : 0.4122340275737026\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 218/432\n",
      "beta=0.01, noise_std=0.01, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.0356, recon=0.0101, feature=0.0239, kl=2.3152\n",
      "epoch 300: val loss=0.0544, val recon=0.0250, val feature=0.0627, val kl=2.3151\n",
      "Recon R2 : 0.975142898195726, Feature R2 : 0.41294447955609\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 219/432\n",
      "beta=0.01, noise_std=0.01, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.0357, recon=0.0101, feature=0.0246, kl=2.3199\n",
      "epoch 300: val loss=0.0503, val recon=0.0212, val feature=0.0608, val kl=2.2968\n",
      "Recon R2 : 0.9786208690864083, Feature R2 : 0.414456186340007\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 220/432\n",
      "beta=0.01, noise_std=0.01, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.0710, recon=0.0352, feature=0.0877, kl=2.7049\n",
      "epoch 300: val loss=0.0905, val recon=0.0514, val feature=0.1229, val kl=2.6816\n",
      "Recon R2 : 0.9490056482307407, Feature R2 : 0.3533062150347134\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 221/432\n",
      "beta=0.01, noise_std=0.01, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.0682, recon=0.0329, feature=0.0838, kl=2.6892\n",
      "epoch 300: val loss=0.0846, val recon=0.0463, val feature=0.1123, val kl=2.7072\n",
      "Recon R2 : 0.9539723039816579, Feature R2 : 0.3635761676727664\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 222/432\n",
      "beta=0.01, noise_std=0.01, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.0714, recon=0.0351, feature=0.0912, kl=2.7196\n",
      "epoch 300: val loss=0.0839, val recon=0.0457, val feature=0.1132, val kl=2.6881\n",
      "Recon R2 : 0.9543478693670331, Feature R2 : 0.3629109431103774\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 223/432\n",
      "beta=0.01, noise_std=0.01, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.0309, recon=0.0093, feature=0.0235, kl=1.9185\n",
      "epoch 300: val loss=0.0451, val recon=0.0197, val feature=0.0614, val kl=1.9216\n",
      "Recon R2 : 0.9802503020269342, Feature R2 : 0.41402489128746295\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 224/432\n",
      "beta=0.01, noise_std=0.01, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.0305, recon=0.0093, feature=0.0226, kl=1.8990\n",
      "epoch 300: val loss=0.0406, val recon=0.0156, val feature=0.0541, val kl=1.9583\n",
      "Recon R2 : 0.9843935041027596, Feature R2 : 0.4211632791573414\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 225/432\n",
      "beta=0.01, noise_std=0.01, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.0311, recon=0.0094, feature=0.0234, kl=1.9409\n",
      "epoch 300: val loss=0.0464, val recon=0.0205, val feature=0.0638, val kl=1.9445\n",
      "Recon R2 : 0.9793571669783492, Feature R2 : 0.4118219665072368\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 226/432\n",
      "beta=0.01, noise_std=0.01, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.0551, recon=0.0239, feature=0.0774, kl=2.3510\n",
      "epoch 300: val loss=0.0676, val recon=0.0335, val feature=0.1059, val kl=2.3543\n",
      "Recon R2 : 0.9666240374822258, Feature R2 : 0.3700300367739614\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 227/432\n",
      "beta=0.01, noise_std=0.01, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.0544, recon=0.0239, feature=0.0782, kl=2.2710\n",
      "epoch 300: val loss=0.0641, val recon=0.0299, val feature=0.1052, val kl=2.3615\n",
      "Recon R2 : 0.9699852957679834, Feature R2 : 0.370776561878524\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 228/432\n",
      "beta=0.01, noise_std=0.01, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.0558, recon=0.0249, feature=0.0773, kl=2.3182\n",
      "epoch 300: val loss=0.0637, val recon=0.0299, val feature=0.1028, val kl=2.3542\n",
      "Recon R2 : 0.9702057845608518, Feature R2 : 0.3729164351561455\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 229/432\n",
      "beta=0.01, noise_std=0.01, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.0509, recon=0.0095, feature=0.0146, kl=2.6764\n",
      "epoch 300: val loss=0.1067, val recon=0.0312, val feature=0.0489, val kl=2.6637\n",
      "Recon R2 : 0.9687609133925039, Feature R2 : 0.4269909114820794\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 230/432\n",
      "beta=0.01, noise_std=0.01, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.0507, recon=0.0100, feature=0.0143, kl=2.6409\n",
      "epoch 300: val loss=0.1059, val recon=0.0302, val feature=0.0491, val kl=2.6520\n",
      "Recon R2 : 0.9697345033885831, Feature R2 : 0.426708007965318\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 231/432\n",
      "beta=0.01, noise_std=0.01, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.0495, recon=0.0091, feature=0.0137, kl=2.6612\n",
      "epoch 300: val loss=0.1002, val recon=0.0280, val feature=0.0459, val kl=2.6397\n",
      "Recon R2 : 0.9718682180342338, Feature R2 : 0.42952124983306017\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 232/432\n",
      "beta=0.01, noise_std=0.01, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.1329, recon=0.0397, feature=0.0609, kl=3.2274\n",
      "epoch 300: val loss=0.1759, val recon=0.0577, val feature=0.0865, val kl=3.1698\n",
      "Recon R2 : 0.9419300824820056, Feature R2 : 0.38937647594797725\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 233/432\n",
      "beta=0.01, noise_std=0.01, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.1307, recon=0.0413, feature=0.0571, kl=3.2215\n",
      "epoch 300: val loss=0.1776, val recon=0.0593, val feature=0.0862, val kl=3.2201\n",
      "Recon R2 : 0.9406694472433538, Feature R2 : 0.39009294146978085\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 234/432\n",
      "beta=0.01, noise_std=0.01, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.1342, recon=0.0399, feature=0.0617, kl=3.2575\n",
      "epoch 300: val loss=0.1714, val recon=0.0562, val feature=0.0831, val kl=3.2028\n",
      "Recon R2 : 0.9434590379002816, Feature R2 : 0.3929664638128839\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 235/432\n",
      "beta=0.01, noise_std=0.01, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.0466, recon=0.0082, feature=0.0152, kl=2.3218\n",
      "epoch 300: val loss=0.0961, val recon=0.0264, val feature=0.0465, val kl=2.3160\n",
      "Recon R2 : 0.9735287628373521, Feature R2 : 0.42924592004024015\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 236/432\n",
      "beta=0.01, noise_std=0.01, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.0439, recon=0.0083, feature=0.0128, kl=2.2830\n",
      "epoch 300: val loss=0.0849, val recon=0.0189, val feature=0.0426, val kl=2.3370\n",
      "Recon R2 : 0.9809714846214616, Feature R2 : 0.4330642417180857\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 237/432\n",
      "beta=0.01, noise_std=0.01, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.0487, recon=0.0107, feature=0.0149, kl=2.3053\n",
      "epoch 300: val loss=0.1007, val recon=0.0299, val feature=0.0476, val kl=2.3111\n",
      "Recon R2 : 0.9700841622815661, Feature R2 : 0.4282406702795833\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 238/432\n",
      "beta=0.01, noise_std=0.01, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.1106, recon=0.0300, feature=0.0523, kl=2.8292\n",
      "epoch 300: val loss=0.1525, val recon=0.0447, val feature=0.0797, val kl=2.8129\n",
      "Recon R2 : 0.9551782183990358, Feature R2 : 0.39640878076978764\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 239/432\n",
      "beta=0.01, noise_std=0.01, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.1094, recon=0.0289, feature=0.0533, kl=2.7205\n",
      "epoch 300: val loss=0.1475, val recon=0.0397, val feature=0.0797, val kl=2.8152\n",
      "Recon R2 : 0.9602677124728248, Feature R2 : 0.3965963181144025\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 240/432\n",
      "beta=0.01, noise_std=0.01, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.1077, recon=0.0306, feature=0.0495, kl=2.7657\n",
      "epoch 300: val loss=0.1492, val recon=0.0441, val feature=0.0769, val kl=2.8134\n",
      "Recon R2 : 0.9557484877817978, Feature R2 : 0.3989926832330496\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 241/432\n",
      "beta=0.01, noise_std=0.1, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.0161, recon=0.0324, feature=0.0268, kl=1.0227\n",
      "epoch 300: val loss=0.0187, val recon=0.0386, val feature=0.0471, val kl=1.0173\n",
      "Recon R2 : 0.9614616517356505, Feature R2 : 0.42845457993303093\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 242/432\n",
      "beta=0.01, noise_std=0.1, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.0157, recon=0.0324, feature=0.0256, kl=0.9911\n",
      "epoch 300: val loss=0.0187, val recon=0.0414, val feature=0.0464, val kl=0.9967\n",
      "Recon R2 : 0.958638098642858, Feature R2 : 0.42910951962317323\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 243/432\n",
      "beta=0.01, noise_std=0.1, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.0164, recon=0.0328, feature=0.0292, kl=1.0197\n",
      "epoch 300: val loss=0.0185, val recon=0.0381, val feature=0.0458, val kl=1.0067\n",
      "Recon R2 : 0.9617383160773743, Feature R2 : 0.42963790363691107\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 244/432\n",
      "beta=0.01, noise_std=0.1, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.0290, recon=0.0803, feature=0.0794, kl=1.2998\n",
      "epoch 300: val loss=0.0292, val recon=0.0722, val feature=0.0914, val kl=1.2826\n",
      "Recon R2 : 0.9276542024722503, Feature R2 : 0.38429011652240774\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 245/432\n",
      "beta=0.01, noise_std=0.1, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.0289, recon=0.0788, feature=0.0795, kl=1.3033\n",
      "epoch 300: val loss=0.0292, val recon=0.0701, val feature=0.0919, val kl=1.3024\n",
      "Recon R2 : 0.9298965505627633, Feature R2 : 0.3839980792303761\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 246/432\n",
      "beta=0.01, noise_std=0.1, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.0294, recon=0.0784, feature=0.0830, kl=1.3297\n",
      "epoch 300: val loss=0.0285, val recon=0.0660, val feature=0.0888, val kl=1.3011\n",
      "Recon R2 : 0.9338014539805932, Feature R2 : 0.3871724548765588\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 247/432\n",
      "beta=0.01, noise_std=0.1, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.0111, recon=0.0214, feature=0.0209, kl=0.6917\n",
      "epoch 300: val loss=0.0142, val recon=0.0328, val feature=0.0410, val kl=0.6828\n",
      "Recon R2 : 0.9672433530312687, Feature R2 : 0.43463052881458586\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 248/432\n",
      "beta=0.01, noise_std=0.1, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.0111, recon=0.0221, feature=0.0212, kl=0.6747\n",
      "epoch 300: val loss=0.0141, val recon=0.0310, val feature=0.0408, val kl=0.6892\n",
      "Recon R2 : 0.9690569836419711, Feature R2 : 0.43475492697990137\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 249/432\n",
      "beta=0.01, noise_std=0.1, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.0116, recon=0.0239, feature=0.0224, kl=0.6964\n",
      "epoch 300: val loss=0.0149, val recon=0.0349, val feature=0.0443, val kl=0.7001\n",
      "Recon R2 : 0.9651156844897499, Feature R2 : 0.4309758742699988\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 250/432\n",
      "beta=0.01, noise_std=0.1, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.0245, recon=0.0679, feature=0.0716, kl=1.0578\n",
      "epoch 300: val loss=0.0254, val recon=0.0643, val feature=0.0859, val kl=1.0430\n",
      "Recon R2 : 0.9360351148946038, Feature R2 : 0.3899623284714603\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 251/432\n",
      "beta=0.01, noise_std=0.1, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.0239, recon=0.0652, feature=0.0721, kl=1.0171\n",
      "epoch 300: val loss=0.0247, val recon=0.0571, val feature=0.0848, val kl=1.0507\n",
      "Recon R2 : 0.9429952646023843, Feature R2 : 0.39119935960985514\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 252/432\n",
      "beta=0.01, noise_std=0.1, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.0242, recon=0.0682, feature=0.0692, kl=1.0467\n",
      "epoch 300: val loss=0.0247, val recon=0.0576, val feature=0.0834, val kl=1.0573\n",
      "Recon R2 : 0.9424044426235639, Feature R2 : 0.3922512838815451\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 253/432\n",
      "beta=0.01, noise_std=0.1, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.0350, recon=0.0307, feature=0.0137, kl=1.8229\n",
      "epoch 300: val loss=0.0583, val recon=0.0669, val feature=0.0336, val kl=1.8051\n",
      "Recon R2 : 0.9330167368251313, Feature R2 : 0.44211340946395605\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 254/432\n",
      "beta=0.01, noise_std=0.1, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.0346, recon=0.0293, feature=0.0135, kl=1.8202\n",
      "epoch 300: val loss=0.0623, val recon=0.0635, val feature=0.0378, val kl=1.8146\n",
      "Recon R2 : 0.9364553442121852, Feature R2 : 0.43777329376275553\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 255/432\n",
      "beta=0.01, noise_std=0.1, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.0366, recon=0.0289, feature=0.0150, kl=1.8762\n",
      "epoch 300: val loss=0.0627, val recon=0.0576, val feature=0.0387, val kl=1.8280\n",
      "Recon R2 : 0.9420328117460091, Feature R2 : 0.4368279138626338\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 256/432\n",
      "beta=0.01, noise_std=0.1, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.0849, recon=0.1250, feature=0.0514, kl=2.0909\n",
      "epoch 300: val loss=0.1090, val recon=0.1408, val feature=0.0743, val kl=2.0575\n",
      "Recon R2 : 0.85891983492165, Feature R2 : 0.40207622088157013\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 257/432\n",
      "beta=0.01, noise_std=0.1, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.0836, recon=0.1211, feature=0.0504, kl=2.1126\n",
      "epoch 300: val loss=0.1110, val recon=0.1377, val feature=0.0762, val kl=2.1106\n",
      "Recon R2 : 0.861933799138886, Feature R2 : 0.40032330654929327\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 258/432\n",
      "beta=0.01, noise_std=0.1, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.0867, recon=0.1077, feature=0.0544, kl=2.1533\n",
      "epoch 300: val loss=0.1042, val recon=0.1219, val feature=0.0710, val kl=2.1015\n",
      "Recon R2 : 0.8769225268289389, Feature R2 : 0.4052795136954722\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 259/432\n",
      "beta=0.01, noise_std=0.1, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.0302, recon=0.0253, feature=0.0129, kl=1.4818\n",
      "epoch 300: val loss=0.0610, val recon=0.0647, val feature=0.0398, val kl=1.4767\n",
      "Recon R2 : 0.9351854104809281, Feature R2 : 0.43598099018585607\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 260/432\n",
      "beta=0.01, noise_std=0.1, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.0296, recon=0.0262, feature=0.0123, kl=1.4645\n",
      "epoch 300: val loss=0.0601, val recon=0.0553, val feature=0.0396, val kl=1.4988\n",
      "Recon R2 : 0.9442282061886603, Feature R2 : 0.4362853769080156\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 261/432\n",
      "beta=0.01, noise_std=0.1, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.0295, recon=0.0280, feature=0.0126, kl=1.4072\n",
      "epoch 300: val loss=0.0581, val recon=0.0636, val feature=0.0376, val kl=1.4166\n",
      "Recon R2 : 0.936301778108365, Feature R2 : 0.4379510622837249\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 262/432\n",
      "beta=0.01, noise_std=0.1, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.0744, recon=0.1082, feature=0.0452, kl=1.8289\n",
      "epoch 300: val loss=0.1032, val recon=0.1347, val feature=0.0717, val kl=1.8036\n",
      "Recon R2 : 0.8652560760793422, Feature R2 : 0.4047274978743948\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 263/432\n",
      "beta=0.01, noise_std=0.1, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.0773, recon=0.0997, feature=0.0494, kl=1.7848\n",
      "epoch 300: val loss=0.1034, val recon=0.1194, val feature=0.0731, val kl=1.8317\n",
      "Recon R2 : 0.8804169777178767, Feature R2 : 0.40350411369212924\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 264/432\n",
      "beta=0.01, noise_std=0.1, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.0780, recon=0.1120, feature=0.0488, kl=1.8021\n",
      "epoch 300: val loss=0.1018, val recon=0.1273, val feature=0.0709, val kl=1.8197\n",
      "Recon R2 : 0.8725952064239957, Feature R2 : 0.405540410323286\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 265/432\n",
      "beta=0.01, noise_std=0.1, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.0362, recon=0.0103, feature=0.0257, kl=2.3282\n",
      "epoch 300: val loss=0.0535, val recon=0.0239, val feature=0.0636, val kl=2.3295\n",
      "Recon R2 : 0.9760446734869779, Feature R2 : 0.4122340275737026\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 266/432\n",
      "beta=0.01, noise_std=0.1, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.0356, recon=0.0101, feature=0.0239, kl=2.3152\n",
      "epoch 300: val loss=0.0544, val recon=0.0250, val feature=0.0627, val kl=2.3151\n",
      "Recon R2 : 0.975142898195726, Feature R2 : 0.41294447955609\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 267/432\n",
      "beta=0.01, noise_std=0.1, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.0357, recon=0.0101, feature=0.0246, kl=2.3199\n",
      "epoch 300: val loss=0.0503, val recon=0.0212, val feature=0.0608, val kl=2.2968\n",
      "Recon R2 : 0.9786208690864083, Feature R2 : 0.414456186340007\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 268/432\n",
      "beta=0.01, noise_std=0.1, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.0710, recon=0.0352, feature=0.0877, kl=2.7049\n",
      "epoch 300: val loss=0.0905, val recon=0.0514, val feature=0.1229, val kl=2.6816\n",
      "Recon R2 : 0.9490056482307407, Feature R2 : 0.3533062150347134\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 269/432\n",
      "beta=0.01, noise_std=0.1, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.0682, recon=0.0329, feature=0.0838, kl=2.6892\n",
      "epoch 300: val loss=0.0846, val recon=0.0463, val feature=0.1123, val kl=2.7072\n",
      "Recon R2 : 0.9539723039816579, Feature R2 : 0.3635761676727664\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 270/432\n",
      "beta=0.01, noise_std=0.1, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.0714, recon=0.0351, feature=0.0912, kl=2.7196\n",
      "epoch 300: val loss=0.0839, val recon=0.0457, val feature=0.1132, val kl=2.6881\n",
      "Recon R2 : 0.9543478693670331, Feature R2 : 0.3629109431103774\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 271/432\n",
      "beta=0.01, noise_std=0.1, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.0309, recon=0.0093, feature=0.0235, kl=1.9185\n",
      "epoch 300: val loss=0.0451, val recon=0.0197, val feature=0.0614, val kl=1.9216\n",
      "Recon R2 : 0.9802503020269342, Feature R2 : 0.41402489128746295\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 272/432\n",
      "beta=0.01, noise_std=0.1, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.0305, recon=0.0093, feature=0.0226, kl=1.8990\n",
      "epoch 300: val loss=0.0406, val recon=0.0156, val feature=0.0541, val kl=1.9583\n",
      "Recon R2 : 0.9843935041027596, Feature R2 : 0.4211632791573414\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 273/432\n",
      "beta=0.01, noise_std=0.1, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.0311, recon=0.0094, feature=0.0234, kl=1.9409\n",
      "epoch 300: val loss=0.0464, val recon=0.0205, val feature=0.0638, val kl=1.9445\n",
      "Recon R2 : 0.9793571669783492, Feature R2 : 0.4118219665072368\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 274/432\n",
      "beta=0.01, noise_std=0.1, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.0551, recon=0.0239, feature=0.0774, kl=2.3510\n",
      "epoch 300: val loss=0.0676, val recon=0.0335, val feature=0.1059, val kl=2.3543\n",
      "Recon R2 : 0.9666240374822258, Feature R2 : 0.3700300367739614\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 275/432\n",
      "beta=0.01, noise_std=0.1, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.0544, recon=0.0239, feature=0.0782, kl=2.2710\n",
      "epoch 300: val loss=0.0641, val recon=0.0299, val feature=0.1052, val kl=2.3615\n",
      "Recon R2 : 0.9699852957679834, Feature R2 : 0.370776561878524\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 276/432\n",
      "beta=0.01, noise_std=0.1, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.0558, recon=0.0249, feature=0.0773, kl=2.3182\n",
      "epoch 300: val loss=0.0637, val recon=0.0299, val feature=0.1028, val kl=2.3542\n",
      "Recon R2 : 0.9702057845608518, Feature R2 : 0.3729164351561455\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 277/432\n",
      "beta=0.01, noise_std=0.1, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.0509, recon=0.0095, feature=0.0146, kl=2.6764\n",
      "epoch 300: val loss=0.1067, val recon=0.0312, val feature=0.0489, val kl=2.6637\n",
      "Recon R2 : 0.9687609133925039, Feature R2 : 0.4269909114820794\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 278/432\n",
      "beta=0.01, noise_std=0.1, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.0507, recon=0.0100, feature=0.0143, kl=2.6409\n",
      "epoch 300: val loss=0.1059, val recon=0.0302, val feature=0.0491, val kl=2.6520\n",
      "Recon R2 : 0.9697345033885831, Feature R2 : 0.426708007965318\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 279/432\n",
      "beta=0.01, noise_std=0.1, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.0495, recon=0.0091, feature=0.0137, kl=2.6612\n",
      "epoch 300: val loss=0.1002, val recon=0.0280, val feature=0.0459, val kl=2.6397\n",
      "Recon R2 : 0.9718682180342338, Feature R2 : 0.42952124983306017\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 280/432\n",
      "beta=0.01, noise_std=0.1, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.1329, recon=0.0397, feature=0.0609, kl=3.2274\n",
      "epoch 300: val loss=0.1759, val recon=0.0577, val feature=0.0865, val kl=3.1698\n",
      "Recon R2 : 0.9419300824820056, Feature R2 : 0.38937647594797725\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 281/432\n",
      "beta=0.01, noise_std=0.1, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.1307, recon=0.0413, feature=0.0571, kl=3.2215\n",
      "epoch 300: val loss=0.1776, val recon=0.0593, val feature=0.0862, val kl=3.2201\n",
      "Recon R2 : 0.9406694472433538, Feature R2 : 0.39009294146978085\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 282/432\n",
      "beta=0.01, noise_std=0.1, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.1342, recon=0.0399, feature=0.0617, kl=3.2575\n",
      "epoch 300: val loss=0.1714, val recon=0.0562, val feature=0.0831, val kl=3.2028\n",
      "Recon R2 : 0.9434590379002816, Feature R2 : 0.3929664638128839\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 283/432\n",
      "beta=0.01, noise_std=0.1, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.0466, recon=0.0082, feature=0.0152, kl=2.3218\n",
      "epoch 300: val loss=0.0961, val recon=0.0264, val feature=0.0465, val kl=2.3160\n",
      "Recon R2 : 0.9735287628373521, Feature R2 : 0.42924592004024015\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 284/432\n",
      "beta=0.01, noise_std=0.1, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.0439, recon=0.0083, feature=0.0128, kl=2.2830\n",
      "epoch 300: val loss=0.0849, val recon=0.0189, val feature=0.0426, val kl=2.3370\n",
      "Recon R2 : 0.9809714846214616, Feature R2 : 0.4330642417180857\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 285/432\n",
      "beta=0.01, noise_std=0.1, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.0487, recon=0.0107, feature=0.0149, kl=2.3053\n",
      "epoch 300: val loss=0.1007, val recon=0.0299, val feature=0.0476, val kl=2.3111\n",
      "Recon R2 : 0.9700841622815661, Feature R2 : 0.4282406702795833\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 286/432\n",
      "beta=0.01, noise_std=0.1, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.1106, recon=0.0300, feature=0.0523, kl=2.8292\n",
      "epoch 300: val loss=0.1525, val recon=0.0447, val feature=0.0797, val kl=2.8129\n",
      "Recon R2 : 0.9551782183990358, Feature R2 : 0.39640878076978764\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 287/432\n",
      "beta=0.01, noise_std=0.1, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.1094, recon=0.0289, feature=0.0533, kl=2.7205\n",
      "epoch 300: val loss=0.1475, val recon=0.0397, val feature=0.0797, val kl=2.8152\n",
      "Recon R2 : 0.9602677124728248, Feature R2 : 0.3965963181144025\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 288/432\n",
      "beta=0.01, noise_std=0.1, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.1077, recon=0.0306, feature=0.0495, kl=2.7657\n",
      "epoch 300: val loss=0.1492, val recon=0.0441, val feature=0.0769, val kl=2.8134\n",
      "Recon R2 : 0.9557484877817978, Feature R2 : 0.3989926832330496\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 289/432\n",
      "beta=0.1, noise_std=0.001, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2023\n",
      "Early stopping at epoch 245\n",
      "epoch 245: loss=0.0560, recon=0.1672, feature=0.0986, kl=0.2943\n",
      "epoch 245: val loss=0.0579, val recon=0.1786, val feature=0.1122, val kl=0.2881\n",
      "Recon R2 : 0.8218107348062377, Feature R2 : 0.36210601988563385\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 290/432\n",
      "beta=0.1, noise_std=0.001, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.0559, recon=0.1668, feature=0.1075, kl=0.2851\n",
      "epoch 300: val loss=0.0573, val recon=0.1820, val feature=0.1148, val kl=0.2758\n",
      "Recon R2 : 0.8164933566257379, Feature R2 : 0.3592259544035833\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 291/432\n",
      "beta=0.1, noise_std=0.001, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.0575, recon=0.1666, feature=0.1032, kl=0.3052\n",
      "epoch 300: val loss=0.0552, val recon=0.1568, val feature=0.0980, val kl=0.2971\n",
      "Recon R2 : 0.8432581111258546, Feature R2 : 0.3765423830246078\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 292/432\n",
      "beta=0.1, noise_std=0.001, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.0831, recon=0.3587, feature=0.1860, kl=0.2860\n",
      "epoch 300: val loss=0.0722, val recon=0.2791, val feature=0.1606, val kl=0.2824\n",
      "Recon R2 : 0.7232477328866171, Feature R2 : 0.313601557523507\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 293/432\n",
      "beta=0.1, noise_std=0.001, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.0831, recon=0.3539, feature=0.1827, kl=0.2941\n",
      "epoch 300: val loss=0.0715, val recon=0.2653, val feature=0.1599, val kl=0.2894\n",
      "Recon R2 : 0.7369027529587374, Feature R2 : 0.31442796639950227\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 294/432\n",
      "beta=0.1, noise_std=0.001, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.0877, recon=0.3792, feature=0.2028, kl=0.2944\n",
      "epoch 300: val loss=0.0737, val recon=0.2884, val feature=0.1677, val kl=0.2813\n",
      "Recon R2 : 0.7149709954841237, Feature R2 : 0.3064081548994661\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 295/432\n",
      "beta=0.1, noise_std=0.001, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.0363, recon=0.0960, feature=0.0553, kl=0.2120\n",
      "epoch 300: val loss=0.0423, val recon=0.1371, val feature=0.0801, val kl=0.2057\n",
      "Recon R2 : 0.8630598569635394, Feature R2 : 0.39435446559400034\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 296/432\n",
      "beta=0.1, noise_std=0.001, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.0372, recon=0.1024, feature=0.0662, kl=0.2032\n",
      "epoch 300: val loss=0.0414, val recon=0.1256, val feature=0.0834, val kl=0.2047\n",
      "Recon R2 : 0.8746202740586031, Feature R2 : 0.3913033905765541\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 297/432\n",
      "beta=0.1, noise_std=0.001, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.0384, recon=0.1085, feature=0.0681, kl=0.2076\n",
      "epoch 300: val loss=0.0422, val recon=0.1298, val feature=0.0873, val kl=0.2050\n",
      "Recon R2 : 0.8702603815040428, Feature R2 : 0.3874548257955651\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 298/432\n",
      "beta=0.1, noise_std=0.001, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.0676, recon=0.2592, feature=0.1567, kl=0.2600\n",
      "epoch 300: val loss=0.0572, val recon=0.1796, val feature=0.1356, val kl=0.2571\n",
      "Recon R2 : 0.8218414150516646, Feature R2 : 0.33932189847952476\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 299/432\n",
      "beta=0.1, noise_std=0.001, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.0652, recon=0.2546, feature=0.1540, kl=0.2429\n",
      "epoch 300: val loss=0.0566, val recon=0.1784, val feature=0.1368, val kl=0.2507\n",
      "Recon R2 : 0.8228324918413031, Feature R2 : 0.3383093180766769\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 300/432\n",
      "beta=0.1, noise_std=0.001, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.0689, recon=0.2752, feature=0.1610, kl=0.2531\n",
      "epoch 300: val loss=0.0575, val recon=0.1843, val feature=0.1363, val kl=0.2540\n",
      "Recon R2 : 0.8166511148049187, Feature R2 : 0.3384686550006163\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 301/432\n",
      "beta=0.1, noise_std=0.001, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.0962, recon=0.1167, feature=0.0320, kl=0.5259\n",
      "epoch 300: val loss=0.1156, val recon=0.1629, val feature=0.0471, val kl=0.5216\n",
      "Recon R2 : 0.8365020612230814, Feature R2 : 0.42820203311312555\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 302/432\n",
      "beta=0.1, noise_std=0.001, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.0947, recon=0.1127, feature=0.0308, kl=0.5265\n",
      "epoch 300: val loss=0.1170, val recon=0.1678, val feature=0.0475, val kl=0.5278\n",
      "Recon R2 : 0.8315653897947726, Feature R2 : 0.4284242539437933\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 303/432\n",
      "beta=0.1, noise_std=0.001, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.0981, recon=0.1117, feature=0.0324, kl=0.5452\n",
      "epoch 300: val loss=0.1190, val recon=0.1553, val feature=0.0498, val kl=0.5363\n",
      "Recon R2 : 0.8448250589702988, Feature R2 : 0.42580831748132775\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 304/432\n",
      "beta=0.1, noise_std=0.001, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.1833, recon=0.3012, feature=0.0888, kl=0.6439\n",
      "epoch 300: val loss=0.1809, val recon=0.2595, val feature=0.0918, val kl=0.6318\n",
      "Recon R2 : 0.7401451598731205, Feature R2 : 0.3841386108193702\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 305/432\n",
      "beta=0.1, noise_std=0.001, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.1793, recon=0.2975, feature=0.0864, kl=0.6314\n",
      "epoch 300: val loss=0.1825, val recon=0.2605, val feature=0.0937, val kl=0.6275\n",
      "Recon R2 : 0.7392431360607669, Feature R2 : 0.38265894538500383\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 306/432\n",
      "beta=0.1, noise_std=0.001, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.1910, recon=0.3114, feature=0.0929, kl=0.6687\n",
      "epoch 300: val loss=0.1794, val recon=0.2661, val feature=0.0883, val kl=0.6442\n",
      "Recon R2 : 0.7334529690959506, Feature R2 : 0.38751769808476993\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 307/432\n",
      "beta=0.1, noise_std=0.001, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.0645, recon=0.0700, feature=0.0213, kl=0.3617\n",
      "epoch 300: val loss=0.0920, val recon=0.1268, val feature=0.0438, val kl=0.3547\n",
      "Recon R2 : 0.872337747601397, Feature R2 : 0.4316407801977031\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 308/432\n",
      "beta=0.1, noise_std=0.001, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.0652, recon=0.0726, feature=0.0228, kl=0.3515\n",
      "epoch 300: val loss=0.0906, val recon=0.1254, val feature=0.0425, val kl=0.3563\n",
      "Recon R2 : 0.8739058070932648, Feature R2 : 0.4331275754464186\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 309/432\n",
      "beta=0.1, noise_std=0.001, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.0681, recon=0.0780, feature=0.0232, kl=0.3713\n",
      "epoch 300: val loss=0.0909, val recon=0.1216, val feature=0.0418, val kl=0.3699\n",
      "Recon R2 : 0.878233046731978, Feature R2 : 0.43378225505319384\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 310/432\n",
      "beta=0.1, noise_std=0.001, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.1566, recon=0.2688, feature=0.0769, kl=0.5290\n",
      "epoch 300: val loss=0.1619, val recon=0.2413, val feature=0.0863, val kl=0.5148\n",
      "Recon R2 : 0.758781769732402, Feature R2 : 0.3897245195714665\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 311/432\n",
      "beta=0.1, noise_std=0.001, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.1579, recon=0.2497, feature=0.0822, kl=0.5074\n",
      "epoch 300: val loss=0.1640, val recon=0.2270, val feature=0.0891, val kl=0.5215\n",
      "Recon R2 : 0.7731994281103808, Feature R2 : 0.38717635311692633\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 312/432\n",
      "beta=0.1, noise_std=0.001, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.1563, recon=0.2701, feature=0.0786, kl=0.5070\n",
      "epoch 300: val loss=0.1599, val recon=0.2355, val feature=0.0851, val kl=0.5125\n",
      "Recon R2 : 0.764409266410085, Feature R2 : 0.39104810099833903\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 313/432\n",
      "beta=0.1, noise_std=0.001, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.1240, recon=0.0373, feature=0.0529, kl=0.8139\n",
      "epoch 300: val loss=0.1358, val recon=0.0481, val feature=0.0802, val kl=0.7971\n",
      "Recon R2 : 0.9521384134942582, Feature R2 : 0.3951076993438272\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 314/432\n",
      "beta=0.1, noise_std=0.001, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.1246, recon=0.0370, feature=0.0499, kl=0.8264\n",
      "epoch 300: val loss=0.1297, val recon=0.0394, val feature=0.0729, val kl=0.8308\n",
      "Recon R2 : 0.9608880850879036, Feature R2 : 0.4022738387285731\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 315/432\n",
      "beta=0.1, noise_std=0.001, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.1249, recon=0.0373, feature=0.0568, kl=0.8191\n",
      "epoch 300: val loss=0.1294, val recon=0.0408, val feature=0.0790, val kl=0.8073\n",
      "Recon R2 : 0.9594740444150027, Feature R2 : 0.39600959517428913\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 316/432\n",
      "beta=0.1, noise_std=0.001, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.2078, recon=0.0869, feature=0.1267, kl=1.0823\n",
      "epoch 300: val loss=0.1922, val recon=0.0715, val feature=0.1366, val kl=1.0710\n",
      "Recon R2 : 0.929282484228446, Feature R2 : 0.33934317592619534\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 317/432\n",
      "beta=0.1, noise_std=0.001, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.2021, recon=0.0824, feature=0.1231, kl=1.0747\n",
      "epoch 300: val loss=0.1864, val recon=0.0668, val feature=0.1233, val kl=1.0728\n",
      "Recon R2 : 0.9335551400761652, Feature R2 : 0.35232888366625315\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 318/432\n",
      "beta=0.1, noise_std=0.001, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.2116, recon=0.0887, feature=0.1275, kl=1.1013\n",
      "epoch 300: val loss=0.1868, val recon=0.0666, val feature=0.1271, val kl=1.0756\n",
      "Recon R2 : 0.9341743123610693, Feature R2 : 0.3488851068727786\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 319/432\n",
      "beta=0.1, noise_std=0.001, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.0839, recon=0.0250, feature=0.0375, kl=0.5522\n",
      "epoch 300: val loss=0.0905, val recon=0.0294, val feature=0.0609, val kl=0.5497\n",
      "Recon R2 : 0.9705252209996977, Feature R2 : 0.4144814804716999\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 320/432\n",
      "beta=0.1, noise_std=0.001, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.0830, recon=0.0249, feature=0.0395, kl=0.5421\n",
      "epoch 300: val loss=0.0904, val recon=0.0282, val feature=0.0607, val kl=0.5615\n",
      "Recon R2 : 0.9718210200590414, Feature R2 : 0.4147686089051541\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 321/432\n",
      "beta=0.1, noise_std=0.001, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.0852, recon=0.0256, feature=0.0375, kl=0.5581\n",
      "epoch 300: val loss=0.0995, val recon=0.0363, val feature=0.0690, val kl=0.5627\n",
      "Recon R2 : 0.9636121827344512, Feature R2 : 0.4063308526608228\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 322/432\n",
      "beta=0.1, noise_std=0.001, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.1698, recon=0.0734, feature=0.1152, kl=0.8490\n",
      "epoch 300: val loss=0.1563, val recon=0.0592, val feature=0.1231, val kl=0.8482\n",
      "Recon R2 : 0.9412871331992789, Feature R2 : 0.35268610673440925\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 323/432\n",
      "beta=0.1, noise_std=0.001, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.1659, recon=0.0730, feature=0.1084, kl=0.8207\n",
      "epoch 300: val loss=0.1473, val recon=0.0501, val feature=0.1169, val kl=0.8550\n",
      "Recon R2 : 0.9504149203202068, Feature R2 : 0.35874831162873716\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 324/432\n",
      "beta=0.1, noise_std=0.001, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.1703, recon=0.0741, feature=0.1123, kl=0.8503\n",
      "epoch 300: val loss=0.1513, val recon=0.0533, val feature=0.1187, val kl=0.8616\n",
      "Recon R2 : 0.9471425761631946, Feature R2 : 0.3567644099839108\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 325/432\n",
      "beta=0.1, noise_std=0.001, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.1609, recon=0.0330, feature=0.0261, kl=1.0192\n",
      "epoch 300: val loss=0.1880, val recon=0.0398, val feature=0.0471, val kl=1.0113\n",
      "Recon R2 : 0.9602650111052148, Feature R2 : 0.42854120337261425\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 326/432\n",
      "beta=0.1, noise_std=0.001, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.1596, recon=0.0331, feature=0.0267, kl=0.9981\n",
      "epoch 300: val loss=0.1908, val recon=0.0427, val feature=0.0473, val kl=1.0085\n",
      "Recon R2 : 0.9571707034246414, Feature R2 : 0.42820138489845394\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 327/432\n",
      "beta=0.1, noise_std=0.001, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.1645, recon=0.0322, feature=0.0296, kl=1.0268\n",
      "epoch 300: val loss=0.1850, val recon=0.0386, val feature=0.0454, val kl=1.0107\n",
      "Recon R2 : 0.9613820375560678, Feature R2 : 0.430191568166884\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 328/432\n",
      "beta=0.1, noise_std=0.001, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.2891, recon=0.0800, feature=0.0792, kl=1.2988\n",
      "epoch 300: val loss=0.2911, val recon=0.0715, val feature=0.0913, val kl=1.2828\n",
      "Recon R2 : 0.9282839032889076, Feature R2 : 0.3844163323953766\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 329/432\n",
      "beta=0.1, noise_std=0.001, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.2881, recon=0.0782, feature=0.0796, kl=1.3041\n",
      "epoch 300: val loss=0.2930, val recon=0.0705, val feature=0.0921, val kl=1.3034\n",
      "Recon R2 : 0.9294516095200671, Feature R2 : 0.3838239604100789\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 330/432\n",
      "beta=0.1, noise_std=0.001, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.2942, recon=0.0783, feature=0.0829, kl=1.3300\n",
      "epoch 300: val loss=0.2841, val recon=0.0653, val feature=0.0886, val kl=1.3016\n",
      "Recon R2 : 0.9344959565503164, Feature R2 : 0.3874172352774336\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 331/432\n",
      "beta=0.1, noise_std=0.001, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.1113, recon=0.0221, feature=0.0203, kl=0.6886\n",
      "epoch 300: val loss=0.1471, val recon=0.0342, val feature=0.0447, val kl=0.6828\n",
      "Recon R2 : 0.9659858092746947, Feature R2 : 0.4310676862639569\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 332/432\n",
      "beta=0.1, noise_std=0.001, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.1107, recon=0.0224, feature=0.0204, kl=0.6783\n",
      "epoch 300: val loss=0.1414, val recon=0.0303, val feature=0.0415, val kl=0.6961\n",
      "Recon R2 : 0.9697353000025736, Feature R2 : 0.43405516096254965\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 333/432\n",
      "beta=0.1, noise_std=0.001, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.1136, recon=0.0232, feature=0.0206, kl=0.6974\n",
      "epoch 300: val loss=0.1527, val recon=0.0375, val feature=0.0449, val kl=0.7026\n",
      "Recon R2 : 0.9625284860338279, Feature R2 : 0.4305050139917896\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 334/432\n",
      "beta=0.1, noise_std=0.001, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.2451, recon=0.0676, feature=0.0716, kl=1.0590\n",
      "epoch 300: val loss=0.2540, val recon=0.0638, val feature=0.0858, val kl=1.0443\n",
      "Recon R2 : 0.9365418136367969, Feature R2 : 0.39005904175626155\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 335/432\n",
      "beta=0.1, noise_std=0.001, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.2385, recon=0.0647, feature=0.0719, kl=1.0188\n",
      "epoch 300: val loss=0.2468, val recon=0.0565, val feature=0.0851, val kl=1.0519\n",
      "Recon R2 : 0.9435055334130471, Feature R2 : 0.39091827197940976\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 336/432\n",
      "beta=0.1, noise_std=0.001, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.2418, recon=0.0681, feature=0.0690, kl=1.0478\n",
      "epoch 300: val loss=0.2460, val recon=0.0569, val feature=0.0832, val kl=1.0587\n",
      "Recon R2 : 0.9430791292472935, Feature R2 : 0.3924704089738186\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 337/432\n",
      "beta=0.1, noise_std=0.01, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2023\n",
      "Early stopping at epoch 245\n",
      "epoch 245: loss=0.0560, recon=0.1672, feature=0.0986, kl=0.2943\n",
      "epoch 245: val loss=0.0579, val recon=0.1786, val feature=0.1122, val kl=0.2881\n",
      "Recon R2 : 0.8218107348062377, Feature R2 : 0.36210601988563385\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 338/432\n",
      "beta=0.1, noise_std=0.01, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.0559, recon=0.1668, feature=0.1075, kl=0.2851\n",
      "epoch 300: val loss=0.0573, val recon=0.1820, val feature=0.1148, val kl=0.2758\n",
      "Recon R2 : 0.8164933566257379, Feature R2 : 0.3592259544035833\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 339/432\n",
      "beta=0.1, noise_std=0.01, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.0575, recon=0.1666, feature=0.1032, kl=0.3052\n",
      "epoch 300: val loss=0.0552, val recon=0.1568, val feature=0.0980, val kl=0.2971\n",
      "Recon R2 : 0.8432581111258546, Feature R2 : 0.3765423830246078\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 340/432\n",
      "beta=0.1, noise_std=0.01, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.0831, recon=0.3587, feature=0.1860, kl=0.2860\n",
      "epoch 300: val loss=0.0722, val recon=0.2791, val feature=0.1606, val kl=0.2824\n",
      "Recon R2 : 0.7232477328866171, Feature R2 : 0.313601557523507\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 341/432\n",
      "beta=0.1, noise_std=0.01, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.0831, recon=0.3539, feature=0.1827, kl=0.2941\n",
      "epoch 300: val loss=0.0715, val recon=0.2653, val feature=0.1599, val kl=0.2894\n",
      "Recon R2 : 0.7369027529587374, Feature R2 : 0.31442796639950227\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 342/432\n",
      "beta=0.1, noise_std=0.01, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.0877, recon=0.3792, feature=0.2028, kl=0.2944\n",
      "epoch 300: val loss=0.0737, val recon=0.2884, val feature=0.1677, val kl=0.2813\n",
      "Recon R2 : 0.7149709954841237, Feature R2 : 0.3064081548994661\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 343/432\n",
      "beta=0.1, noise_std=0.01, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.0363, recon=0.0960, feature=0.0553, kl=0.2120\n",
      "epoch 300: val loss=0.0423, val recon=0.1371, val feature=0.0801, val kl=0.2057\n",
      "Recon R2 : 0.8630598569635394, Feature R2 : 0.39435446559400034\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 344/432\n",
      "beta=0.1, noise_std=0.01, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.0372, recon=0.1024, feature=0.0662, kl=0.2032\n",
      "epoch 300: val loss=0.0414, val recon=0.1256, val feature=0.0834, val kl=0.2047\n",
      "Recon R2 : 0.8746202740586031, Feature R2 : 0.3913033905765541\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 345/432\n",
      "beta=0.1, noise_std=0.01, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.0384, recon=0.1085, feature=0.0681, kl=0.2076\n",
      "epoch 300: val loss=0.0422, val recon=0.1298, val feature=0.0873, val kl=0.2050\n",
      "Recon R2 : 0.8702603815040428, Feature R2 : 0.3874548257955651\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 346/432\n",
      "beta=0.1, noise_std=0.01, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.0676, recon=0.2592, feature=0.1567, kl=0.2600\n",
      "epoch 300: val loss=0.0572, val recon=0.1796, val feature=0.1356, val kl=0.2571\n",
      "Recon R2 : 0.8218414150516646, Feature R2 : 0.33932189847952476\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 347/432\n",
      "beta=0.1, noise_std=0.01, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.0652, recon=0.2546, feature=0.1540, kl=0.2429\n",
      "epoch 300: val loss=0.0566, val recon=0.1784, val feature=0.1368, val kl=0.2507\n",
      "Recon R2 : 0.8228324918413031, Feature R2 : 0.3383093180766769\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 348/432\n",
      "beta=0.1, noise_std=0.01, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.0689, recon=0.2752, feature=0.1610, kl=0.2531\n",
      "epoch 300: val loss=0.0575, val recon=0.1843, val feature=0.1363, val kl=0.2540\n",
      "Recon R2 : 0.8166511148049187, Feature R2 : 0.3384686550006163\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 349/432\n",
      "beta=0.1, noise_std=0.01, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.0962, recon=0.1167, feature=0.0320, kl=0.5259\n",
      "epoch 300: val loss=0.1156, val recon=0.1629, val feature=0.0471, val kl=0.5216\n",
      "Recon R2 : 0.8365020612230814, Feature R2 : 0.42820203311312555\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 350/432\n",
      "beta=0.1, noise_std=0.01, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.0947, recon=0.1127, feature=0.0308, kl=0.5265\n",
      "epoch 300: val loss=0.1170, val recon=0.1678, val feature=0.0475, val kl=0.5278\n",
      "Recon R2 : 0.8315653897947726, Feature R2 : 0.4284242539437933\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 351/432\n",
      "beta=0.1, noise_std=0.01, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.0981, recon=0.1117, feature=0.0324, kl=0.5452\n",
      "epoch 300: val loss=0.1190, val recon=0.1553, val feature=0.0498, val kl=0.5363\n",
      "Recon R2 : 0.8448250589702988, Feature R2 : 0.42580831748132775\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 352/432\n",
      "beta=0.1, noise_std=0.01, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.1833, recon=0.3012, feature=0.0888, kl=0.6439\n",
      "epoch 300: val loss=0.1809, val recon=0.2595, val feature=0.0918, val kl=0.6318\n",
      "Recon R2 : 0.7401451598731205, Feature R2 : 0.3841386108193702\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 353/432\n",
      "beta=0.1, noise_std=0.01, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.1793, recon=0.2975, feature=0.0864, kl=0.6314\n",
      "epoch 300: val loss=0.1825, val recon=0.2605, val feature=0.0937, val kl=0.6275\n",
      "Recon R2 : 0.7392431360607669, Feature R2 : 0.38265894538500383\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 354/432\n",
      "beta=0.1, noise_std=0.01, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.1910, recon=0.3114, feature=0.0929, kl=0.6687\n",
      "epoch 300: val loss=0.1794, val recon=0.2661, val feature=0.0883, val kl=0.6442\n",
      "Recon R2 : 0.7334529690959506, Feature R2 : 0.38751769808476993\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 355/432\n",
      "beta=0.1, noise_std=0.01, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.0645, recon=0.0700, feature=0.0213, kl=0.3617\n",
      "epoch 300: val loss=0.0920, val recon=0.1268, val feature=0.0438, val kl=0.3547\n",
      "Recon R2 : 0.872337747601397, Feature R2 : 0.4316407801977031\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 356/432\n",
      "beta=0.1, noise_std=0.01, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.0652, recon=0.0726, feature=0.0228, kl=0.3515\n",
      "epoch 300: val loss=0.0906, val recon=0.1254, val feature=0.0425, val kl=0.3563\n",
      "Recon R2 : 0.8739058070932648, Feature R2 : 0.4331275754464186\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 357/432\n",
      "beta=0.1, noise_std=0.01, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.0681, recon=0.0780, feature=0.0232, kl=0.3713\n",
      "epoch 300: val loss=0.0909, val recon=0.1216, val feature=0.0418, val kl=0.3699\n",
      "Recon R2 : 0.878233046731978, Feature R2 : 0.43378225505319384\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 358/432\n",
      "beta=0.1, noise_std=0.01, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.1566, recon=0.2688, feature=0.0769, kl=0.5290\n",
      "epoch 300: val loss=0.1619, val recon=0.2413, val feature=0.0863, val kl=0.5148\n",
      "Recon R2 : 0.758781769732402, Feature R2 : 0.3897245195714665\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 359/432\n",
      "beta=0.1, noise_std=0.01, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.1579, recon=0.2497, feature=0.0822, kl=0.5074\n",
      "epoch 300: val loss=0.1640, val recon=0.2270, val feature=0.0891, val kl=0.5215\n",
      "Recon R2 : 0.7731994281103808, Feature R2 : 0.38717635311692633\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 360/432\n",
      "beta=0.1, noise_std=0.01, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.1563, recon=0.2701, feature=0.0786, kl=0.5070\n",
      "epoch 300: val loss=0.1599, val recon=0.2355, val feature=0.0851, val kl=0.5125\n",
      "Recon R2 : 0.764409266410085, Feature R2 : 0.39104810099833903\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 361/432\n",
      "beta=0.1, noise_std=0.01, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.1240, recon=0.0373, feature=0.0529, kl=0.8139\n",
      "epoch 300: val loss=0.1358, val recon=0.0481, val feature=0.0802, val kl=0.7971\n",
      "Recon R2 : 0.9521384134942582, Feature R2 : 0.3951076993438272\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 362/432\n",
      "beta=0.1, noise_std=0.01, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.1246, recon=0.0370, feature=0.0499, kl=0.8264\n",
      "epoch 300: val loss=0.1297, val recon=0.0394, val feature=0.0729, val kl=0.8308\n",
      "Recon R2 : 0.9608880850879036, Feature R2 : 0.4022738387285731\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 363/432\n",
      "beta=0.1, noise_std=0.01, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.1249, recon=0.0373, feature=0.0568, kl=0.8191\n",
      "epoch 300: val loss=0.1294, val recon=0.0408, val feature=0.0790, val kl=0.8073\n",
      "Recon R2 : 0.9594740444150027, Feature R2 : 0.39600959517428913\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 364/432\n",
      "beta=0.1, noise_std=0.01, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.2078, recon=0.0869, feature=0.1267, kl=1.0823\n",
      "epoch 300: val loss=0.1922, val recon=0.0715, val feature=0.1366, val kl=1.0710\n",
      "Recon R2 : 0.929282484228446, Feature R2 : 0.33934317592619534\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 365/432\n",
      "beta=0.1, noise_std=0.01, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.2021, recon=0.0824, feature=0.1231, kl=1.0747\n",
      "epoch 300: val loss=0.1864, val recon=0.0668, val feature=0.1233, val kl=1.0728\n",
      "Recon R2 : 0.9335551400761652, Feature R2 : 0.35232888366625315\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 366/432\n",
      "beta=0.1, noise_std=0.01, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.2116, recon=0.0887, feature=0.1275, kl=1.1013\n",
      "epoch 300: val loss=0.1868, val recon=0.0666, val feature=0.1271, val kl=1.0756\n",
      "Recon R2 : 0.9341743123610693, Feature R2 : 0.3488851068727786\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 367/432\n",
      "beta=0.1, noise_std=0.01, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.0839, recon=0.0250, feature=0.0375, kl=0.5522\n",
      "epoch 300: val loss=0.0905, val recon=0.0294, val feature=0.0609, val kl=0.5497\n",
      "Recon R2 : 0.9705252209996977, Feature R2 : 0.4144814804716999\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 368/432\n",
      "beta=0.1, noise_std=0.01, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.0830, recon=0.0249, feature=0.0395, kl=0.5421\n",
      "epoch 300: val loss=0.0904, val recon=0.0282, val feature=0.0607, val kl=0.5615\n",
      "Recon R2 : 0.9718210200590414, Feature R2 : 0.4147686089051541\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 369/432\n",
      "beta=0.1, noise_std=0.01, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.0852, recon=0.0256, feature=0.0375, kl=0.5581\n",
      "epoch 300: val loss=0.0995, val recon=0.0363, val feature=0.0690, val kl=0.5627\n",
      "Recon R2 : 0.9636121827344512, Feature R2 : 0.4063308526608228\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 370/432\n",
      "beta=0.1, noise_std=0.01, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.1698, recon=0.0734, feature=0.1152, kl=0.8490\n",
      "epoch 300: val loss=0.1563, val recon=0.0592, val feature=0.1231, val kl=0.8482\n",
      "Recon R2 : 0.9412871331992789, Feature R2 : 0.35268610673440925\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 371/432\n",
      "beta=0.1, noise_std=0.01, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.1659, recon=0.0730, feature=0.1084, kl=0.8207\n",
      "epoch 300: val loss=0.1473, val recon=0.0501, val feature=0.1169, val kl=0.8550\n",
      "Recon R2 : 0.9504149203202068, Feature R2 : 0.35874831162873716\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 372/432\n",
      "beta=0.1, noise_std=0.01, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.1703, recon=0.0741, feature=0.1123, kl=0.8503\n",
      "epoch 300: val loss=0.1513, val recon=0.0533, val feature=0.1187, val kl=0.8616\n",
      "Recon R2 : 0.9471425761631946, Feature R2 : 0.3567644099839108\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 373/432\n",
      "beta=0.1, noise_std=0.01, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.1609, recon=0.0330, feature=0.0261, kl=1.0192\n",
      "epoch 300: val loss=0.1880, val recon=0.0398, val feature=0.0471, val kl=1.0113\n",
      "Recon R2 : 0.9602650111052148, Feature R2 : 0.42854120337261425\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 374/432\n",
      "beta=0.1, noise_std=0.01, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.1596, recon=0.0331, feature=0.0267, kl=0.9981\n",
      "epoch 300: val loss=0.1908, val recon=0.0427, val feature=0.0473, val kl=1.0085\n",
      "Recon R2 : 0.9571707034246414, Feature R2 : 0.42820138489845394\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 375/432\n",
      "beta=0.1, noise_std=0.01, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.1645, recon=0.0322, feature=0.0296, kl=1.0268\n",
      "epoch 300: val loss=0.1850, val recon=0.0386, val feature=0.0454, val kl=1.0107\n",
      "Recon R2 : 0.9613820375560678, Feature R2 : 0.430191568166884\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 376/432\n",
      "beta=0.1, noise_std=0.01, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.2891, recon=0.0800, feature=0.0792, kl=1.2988\n",
      "epoch 300: val loss=0.2911, val recon=0.0715, val feature=0.0913, val kl=1.2828\n",
      "Recon R2 : 0.9282839032889076, Feature R2 : 0.3844163323953766\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 377/432\n",
      "beta=0.1, noise_std=0.01, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.2881, recon=0.0782, feature=0.0796, kl=1.3041\n",
      "epoch 300: val loss=0.2930, val recon=0.0705, val feature=0.0921, val kl=1.3034\n",
      "Recon R2 : 0.9294516095200671, Feature R2 : 0.3838239604100789\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 378/432\n",
      "beta=0.1, noise_std=0.01, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.2942, recon=0.0783, feature=0.0829, kl=1.3300\n",
      "epoch 300: val loss=0.2841, val recon=0.0653, val feature=0.0886, val kl=1.3016\n",
      "Recon R2 : 0.9344959565503164, Feature R2 : 0.3874172352774336\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 379/432\n",
      "beta=0.1, noise_std=0.01, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.1113, recon=0.0221, feature=0.0203, kl=0.6886\n",
      "epoch 300: val loss=0.1471, val recon=0.0342, val feature=0.0447, val kl=0.6828\n",
      "Recon R2 : 0.9659858092746947, Feature R2 : 0.4310676862639569\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 380/432\n",
      "beta=0.1, noise_std=0.01, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.1107, recon=0.0224, feature=0.0204, kl=0.6783\n",
      "epoch 300: val loss=0.1414, val recon=0.0303, val feature=0.0415, val kl=0.6961\n",
      "Recon R2 : 0.9697353000025736, Feature R2 : 0.43405516096254965\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 381/432\n",
      "beta=0.1, noise_std=0.01, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.1136, recon=0.0232, feature=0.0206, kl=0.6974\n",
      "epoch 300: val loss=0.1527, val recon=0.0375, val feature=0.0449, val kl=0.7026\n",
      "Recon R2 : 0.9625284860338279, Feature R2 : 0.4305050139917896\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 382/432\n",
      "beta=0.1, noise_std=0.01, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.2451, recon=0.0676, feature=0.0716, kl=1.0590\n",
      "epoch 300: val loss=0.2540, val recon=0.0638, val feature=0.0858, val kl=1.0443\n",
      "Recon R2 : 0.9365418136367969, Feature R2 : 0.39005904175626155\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 383/432\n",
      "beta=0.1, noise_std=0.01, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.2385, recon=0.0647, feature=0.0719, kl=1.0188\n",
      "epoch 300: val loss=0.2468, val recon=0.0565, val feature=0.0851, val kl=1.0519\n",
      "Recon R2 : 0.9435055334130471, Feature R2 : 0.39091827197940976\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 384/432\n",
      "beta=0.1, noise_std=0.01, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.2418, recon=0.0681, feature=0.0690, kl=1.0478\n",
      "epoch 300: val loss=0.2460, val recon=0.0569, val feature=0.0832, val kl=1.0587\n",
      "Recon R2 : 0.9430791292472935, Feature R2 : 0.3924704089738186\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 385/432\n",
      "beta=0.1, noise_std=0.1, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2023\n",
      "Early stopping at epoch 245\n",
      "epoch 245: loss=0.0560, recon=0.1672, feature=0.0986, kl=0.2943\n",
      "epoch 245: val loss=0.0579, val recon=0.1786, val feature=0.1122, val kl=0.2881\n",
      "Recon R2 : 0.8218107348062377, Feature R2 : 0.36210601988563385\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 386/432\n",
      "beta=0.1, noise_std=0.1, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.0559, recon=0.1668, feature=0.1075, kl=0.2851\n",
      "epoch 300: val loss=0.0573, val recon=0.1820, val feature=0.1148, val kl=0.2758\n",
      "Recon R2 : 0.8164933566257379, Feature R2 : 0.3592259544035833\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 387/432\n",
      "beta=0.1, noise_std=0.1, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.0575, recon=0.1666, feature=0.1032, kl=0.3052\n",
      "epoch 300: val loss=0.0552, val recon=0.1568, val feature=0.0980, val kl=0.2971\n",
      "Recon R2 : 0.8432581111258546, Feature R2 : 0.3765423830246078\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 388/432\n",
      "beta=0.1, noise_std=0.1, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.0831, recon=0.3587, feature=0.1860, kl=0.2860\n",
      "epoch 300: val loss=0.0722, val recon=0.2791, val feature=0.1606, val kl=0.2824\n",
      "Recon R2 : 0.7232477328866171, Feature R2 : 0.313601557523507\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 389/432\n",
      "beta=0.1, noise_std=0.1, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.0831, recon=0.3539, feature=0.1827, kl=0.2941\n",
      "epoch 300: val loss=0.0715, val recon=0.2653, val feature=0.1599, val kl=0.2894\n",
      "Recon R2 : 0.7369027529587374, Feature R2 : 0.31442796639950227\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 390/432\n",
      "beta=0.1, noise_std=0.1, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.0877, recon=0.3792, feature=0.2028, kl=0.2944\n",
      "epoch 300: val loss=0.0737, val recon=0.2884, val feature=0.1677, val kl=0.2813\n",
      "Recon R2 : 0.7149709954841237, Feature R2 : 0.3064081548994661\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 391/432\n",
      "beta=0.1, noise_std=0.1, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.0363, recon=0.0960, feature=0.0553, kl=0.2120\n",
      "epoch 300: val loss=0.0423, val recon=0.1371, val feature=0.0801, val kl=0.2057\n",
      "Recon R2 : 0.8630598569635394, Feature R2 : 0.39435446559400034\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 392/432\n",
      "beta=0.1, noise_std=0.1, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.0372, recon=0.1024, feature=0.0662, kl=0.2032\n",
      "epoch 300: val loss=0.0414, val recon=0.1256, val feature=0.0834, val kl=0.2047\n",
      "Recon R2 : 0.8746202740586031, Feature R2 : 0.3913033905765541\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 393/432\n",
      "beta=0.1, noise_std=0.1, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.0384, recon=0.1085, feature=0.0681, kl=0.2076\n",
      "epoch 300: val loss=0.0422, val recon=0.1298, val feature=0.0873, val kl=0.2050\n",
      "Recon R2 : 0.8702603815040428, Feature R2 : 0.3874548257955651\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 394/432\n",
      "beta=0.1, noise_std=0.1, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.0676, recon=0.2592, feature=0.1567, kl=0.2600\n",
      "epoch 300: val loss=0.0572, val recon=0.1796, val feature=0.1356, val kl=0.2571\n",
      "Recon R2 : 0.8218414150516646, Feature R2 : 0.33932189847952476\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 395/432\n",
      "beta=0.1, noise_std=0.1, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.0652, recon=0.2546, feature=0.1540, kl=0.2429\n",
      "epoch 300: val loss=0.0566, val recon=0.1784, val feature=0.1368, val kl=0.2507\n",
      "Recon R2 : 0.8228324918413031, Feature R2 : 0.3383093180766769\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 396/432\n",
      "beta=0.1, noise_std=0.1, alpha_recon=0.1, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.0689, recon=0.2752, feature=0.1610, kl=0.2531\n",
      "epoch 300: val loss=0.0575, val recon=0.1843, val feature=0.1363, val kl=0.2540\n",
      "Recon R2 : 0.8166511148049187, Feature R2 : 0.3384686550006163\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 397/432\n",
      "beta=0.1, noise_std=0.1, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.0962, recon=0.1167, feature=0.0320, kl=0.5259\n",
      "epoch 300: val loss=0.1156, val recon=0.1629, val feature=0.0471, val kl=0.5216\n",
      "Recon R2 : 0.8365020612230814, Feature R2 : 0.42820203311312555\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 398/432\n",
      "beta=0.1, noise_std=0.1, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.0947, recon=0.1127, feature=0.0308, kl=0.5265\n",
      "epoch 300: val loss=0.1170, val recon=0.1678, val feature=0.0475, val kl=0.5278\n",
      "Recon R2 : 0.8315653897947726, Feature R2 : 0.4284242539437933\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 399/432\n",
      "beta=0.1, noise_std=0.1, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.0981, recon=0.1117, feature=0.0324, kl=0.5452\n",
      "epoch 300: val loss=0.1190, val recon=0.1553, val feature=0.0498, val kl=0.5363\n",
      "Recon R2 : 0.8448250589702988, Feature R2 : 0.42580831748132775\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 400/432\n",
      "beta=0.1, noise_std=0.1, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.1833, recon=0.3012, feature=0.0888, kl=0.6439\n",
      "epoch 300: val loss=0.1809, val recon=0.2595, val feature=0.0918, val kl=0.6318\n",
      "Recon R2 : 0.7401451598731205, Feature R2 : 0.3841386108193702\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 401/432\n",
      "beta=0.1, noise_std=0.1, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.1793, recon=0.2975, feature=0.0864, kl=0.6314\n",
      "epoch 300: val loss=0.1825, val recon=0.2605, val feature=0.0937, val kl=0.6275\n",
      "Recon R2 : 0.7392431360607669, Feature R2 : 0.38265894538500383\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 402/432\n",
      "beta=0.1, noise_std=0.1, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.1910, recon=0.3114, feature=0.0929, kl=0.6687\n",
      "epoch 300: val loss=0.1794, val recon=0.2661, val feature=0.0883, val kl=0.6442\n",
      "Recon R2 : 0.7334529690959506, Feature R2 : 0.38751769808476993\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 403/432\n",
      "beta=0.1, noise_std=0.1, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.0645, recon=0.0700, feature=0.0213, kl=0.3617\n",
      "epoch 300: val loss=0.0920, val recon=0.1268, val feature=0.0438, val kl=0.3547\n",
      "Recon R2 : 0.872337747601397, Feature R2 : 0.4316407801977031\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 404/432\n",
      "beta=0.1, noise_std=0.1, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.0652, recon=0.0726, feature=0.0228, kl=0.3515\n",
      "epoch 300: val loss=0.0906, val recon=0.1254, val feature=0.0425, val kl=0.3563\n",
      "Recon R2 : 0.8739058070932648, Feature R2 : 0.4331275754464186\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 405/432\n",
      "beta=0.1, noise_std=0.1, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.0681, recon=0.0780, feature=0.0232, kl=0.3713\n",
      "epoch 300: val loss=0.0909, val recon=0.1216, val feature=0.0418, val kl=0.3699\n",
      "Recon R2 : 0.878233046731978, Feature R2 : 0.43378225505319384\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 406/432\n",
      "beta=0.1, noise_std=0.1, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.1566, recon=0.2688, feature=0.0769, kl=0.5290\n",
      "epoch 300: val loss=0.1619, val recon=0.2413, val feature=0.0863, val kl=0.5148\n",
      "Recon R2 : 0.758781769732402, Feature R2 : 0.3897245195714665\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 407/432\n",
      "beta=0.1, noise_std=0.1, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.1579, recon=0.2497, feature=0.0822, kl=0.5074\n",
      "epoch 300: val loss=0.1640, val recon=0.2270, val feature=0.0891, val kl=0.5215\n",
      "Recon R2 : 0.7731994281103808, Feature R2 : 0.38717635311692633\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 408/432\n",
      "beta=0.1, noise_std=0.1, alpha_recon=0.1, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.1563, recon=0.2701, feature=0.0786, kl=0.5070\n",
      "epoch 300: val loss=0.1599, val recon=0.2355, val feature=0.0851, val kl=0.5125\n",
      "Recon R2 : 0.764409266410085, Feature R2 : 0.39104810099833903\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 409/432\n",
      "beta=0.1, noise_std=0.1, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.1240, recon=0.0373, feature=0.0529, kl=0.8139\n",
      "epoch 300: val loss=0.1358, val recon=0.0481, val feature=0.0802, val kl=0.7971\n",
      "Recon R2 : 0.9521384134942582, Feature R2 : 0.3951076993438272\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 410/432\n",
      "beta=0.1, noise_std=0.1, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.1246, recon=0.0370, feature=0.0499, kl=0.8264\n",
      "epoch 300: val loss=0.1297, val recon=0.0394, val feature=0.0729, val kl=0.8308\n",
      "Recon R2 : 0.9608880850879036, Feature R2 : 0.4022738387285731\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 411/432\n",
      "beta=0.1, noise_std=0.1, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.1249, recon=0.0373, feature=0.0568, kl=0.8191\n",
      "epoch 300: val loss=0.1294, val recon=0.0408, val feature=0.0790, val kl=0.8073\n",
      "Recon R2 : 0.9594740444150027, Feature R2 : 0.39600959517428913\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 412/432\n",
      "beta=0.1, noise_std=0.1, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.2078, recon=0.0869, feature=0.1267, kl=1.0823\n",
      "epoch 300: val loss=0.1922, val recon=0.0715, val feature=0.1366, val kl=1.0710\n",
      "Recon R2 : 0.929282484228446, Feature R2 : 0.33934317592619534\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 413/432\n",
      "beta=0.1, noise_std=0.1, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.2021, recon=0.0824, feature=0.1231, kl=1.0747\n",
      "epoch 300: val loss=0.1864, val recon=0.0668, val feature=0.1233, val kl=1.0728\n",
      "Recon R2 : 0.9335551400761652, Feature R2 : 0.35232888366625315\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 414/432\n",
      "beta=0.1, noise_std=0.1, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.2116, recon=0.0887, feature=0.1275, kl=1.1013\n",
      "epoch 300: val loss=0.1868, val recon=0.0666, val feature=0.1271, val kl=1.0756\n",
      "Recon R2 : 0.9341743123610693, Feature R2 : 0.3488851068727786\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 415/432\n",
      "beta=0.1, noise_std=0.1, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.0839, recon=0.0250, feature=0.0375, kl=0.5522\n",
      "epoch 300: val loss=0.0905, val recon=0.0294, val feature=0.0609, val kl=0.5497\n",
      "Recon R2 : 0.9705252209996977, Feature R2 : 0.4144814804716999\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 416/432\n",
      "beta=0.1, noise_std=0.1, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.0830, recon=0.0249, feature=0.0395, kl=0.5421\n",
      "epoch 300: val loss=0.0904, val recon=0.0282, val feature=0.0607, val kl=0.5615\n",
      "Recon R2 : 0.9718210200590414, Feature R2 : 0.4147686089051541\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 417/432\n",
      "beta=0.1, noise_std=0.1, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.0852, recon=0.0256, feature=0.0375, kl=0.5581\n",
      "epoch 300: val loss=0.0995, val recon=0.0363, val feature=0.0690, val kl=0.5627\n",
      "Recon R2 : 0.9636121827344512, Feature R2 : 0.4063308526608228\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 418/432\n",
      "beta=0.1, noise_std=0.1, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.1698, recon=0.0734, feature=0.1152, kl=0.8490\n",
      "epoch 300: val loss=0.1563, val recon=0.0592, val feature=0.1231, val kl=0.8482\n",
      "Recon R2 : 0.9412871331992789, Feature R2 : 0.35268610673440925\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 419/432\n",
      "beta=0.1, noise_std=0.1, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.1659, recon=0.0730, feature=0.1084, kl=0.8207\n",
      "epoch 300: val loss=0.1473, val recon=0.0501, val feature=0.1169, val kl=0.8550\n",
      "Recon R2 : 0.9504149203202068, Feature R2 : 0.35874831162873716\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 420/432\n",
      "beta=0.1, noise_std=0.1, alpha_recon=1.0, alpha_feature=0.1,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.1703, recon=0.0741, feature=0.1123, kl=0.8503\n",
      "epoch 300: val loss=0.1513, val recon=0.0533, val feature=0.1187, val kl=0.8616\n",
      "Recon R2 : 0.9471425761631946, Feature R2 : 0.3567644099839108\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 421/432\n",
      "beta=0.1, noise_std=0.1, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.1609, recon=0.0330, feature=0.0261, kl=1.0192\n",
      "epoch 300: val loss=0.1880, val recon=0.0398, val feature=0.0471, val kl=1.0113\n",
      "Recon R2 : 0.9602650111052148, Feature R2 : 0.42854120337261425\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 422/432\n",
      "beta=0.1, noise_std=0.1, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.1596, recon=0.0331, feature=0.0267, kl=0.9981\n",
      "epoch 300: val loss=0.1908, val recon=0.0427, val feature=0.0473, val kl=1.0085\n",
      "Recon R2 : 0.9571707034246414, Feature R2 : 0.42820138489845394\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 423/432\n",
      "beta=0.1, noise_std=0.1, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.1645, recon=0.0322, feature=0.0296, kl=1.0268\n",
      "epoch 300: val loss=0.1850, val recon=0.0386, val feature=0.0454, val kl=1.0107\n",
      "Recon R2 : 0.9613820375560678, Feature R2 : 0.430191568166884\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 424/432\n",
      "beta=0.1, noise_std=0.1, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.2891, recon=0.0800, feature=0.0792, kl=1.2988\n",
      "epoch 300: val loss=0.2911, val recon=0.0715, val feature=0.0913, val kl=1.2828\n",
      "Recon R2 : 0.9282839032889076, Feature R2 : 0.3844163323953766\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 425/432\n",
      "beta=0.1, noise_std=0.1, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.2881, recon=0.0782, feature=0.0796, kl=1.3041\n",
      "epoch 300: val loss=0.2930, val recon=0.0705, val feature=0.0921, val kl=1.3034\n",
      "Recon R2 : 0.9294516095200671, Feature R2 : 0.3838239604100789\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 426/432\n",
      "beta=0.1, noise_std=0.1, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=32, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.2942, recon=0.0783, feature=0.0829, kl=1.3300\n",
      "epoch 300: val loss=0.2841, val recon=0.0653, val feature=0.0886, val kl=1.3016\n",
      "Recon R2 : 0.9344959565503164, Feature R2 : 0.3874172352774336\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 427/432\n",
      "beta=0.1, noise_std=0.1, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2023\n",
      "epoch 300: loss=0.1113, recon=0.0221, feature=0.0203, kl=0.6886\n",
      "epoch 300: val loss=0.1471, val recon=0.0342, val feature=0.0447, val kl=0.6828\n",
      "Recon R2 : 0.9659858092746947, Feature R2 : 0.4310676862639569\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 428/432\n",
      "beta=0.1, noise_std=0.1, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2024\n",
      "epoch 300: loss=0.1107, recon=0.0224, feature=0.0204, kl=0.6783\n",
      "epoch 300: val loss=0.1414, val recon=0.0303, val feature=0.0415, val kl=0.6961\n",
      "Recon R2 : 0.9697353000025736, Feature R2 : 0.43405516096254965\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 429/432\n",
      "beta=0.1, noise_std=0.1, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.1136, recon=0.0232, feature=0.0206, kl=0.6974\n",
      "epoch 300: val loss=0.1527, val recon=0.0375, val feature=0.0449, val kl=0.7026\n",
      "Recon R2 : 0.9625284860338279, Feature R2 : 0.4305050139917896\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 430/432\n",
      "beta=0.1, noise_std=0.1, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2023\n",
      "epoch 300: loss=0.2451, recon=0.0676, feature=0.0716, kl=1.0590\n",
      "epoch 300: val loss=0.2540, val recon=0.0638, val feature=0.0858, val kl=1.0443\n",
      "Recon R2 : 0.9365418136367969, Feature R2 : 0.39005904175626155\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 431/432\n",
      "beta=0.1, noise_std=0.1, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2024\n",
      "epoch 300: loss=0.2385, recon=0.0647, feature=0.0719, kl=1.0188\n",
      "epoch 300: val loss=0.2468, val recon=0.0565, val feature=0.0851, val kl=1.0519\n",
      "Recon R2 : 0.9435055334130471, Feature R2 : 0.39091827197940976\n",
      "Next experiment..\n",
      "\n",
      "=============================================\n",
      "Experiment 432/432\n",
      "beta=0.1, noise_std=0.1, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.0001, seed=2025\n",
      "epoch 300: loss=0.2418, recon=0.0681, feature=0.0690, kl=1.0478\n",
      "epoch 300: val loss=0.2460, val recon=0.0569, val feature=0.0832, val kl=1.0587\n",
      "Recon R2 : 0.9430791292472935, Feature R2 : 0.3924704089738186\n",
      "Next experiment..\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "import itertools\n",
    "import torch\n",
    "import pandas as pd\n",
    "# 예시 세팅\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val, feature_train, feature_val = train_test_split(\n",
    "    input_data_scaled, cost, feature_scaled,  test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = FeatureDataset(X_train, feature_train)\n",
    "val_dataset   = FeatureDataset(X_val,   feature_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=512, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "input_dim = X_train.shape[-1]\n",
    "latent_dim = 64\n",
    "hidden_dim = 256\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "hyperparameter = {\n",
    "    'beta': [0.001, 0.01, 0.1],\n",
    "    'alpha_recon': [0.1],\n",
    "    'alpha_feature': [1.0],\n",
    "    'latent_dim': [32, 64],\n",
    "    'lr': [1e-3, 1e-4],\n",
    "\n",
    "    'seed': [2023, 2024, 2025],\n",
    "}\n",
    "\n",
    "cnt = 0\n",
    "epochs = 300\n",
    "\n",
    "# 시드 여러 번 시도해서 평균, 표준편차 계산\n",
    "results = []\n",
    "\n",
    "for vals in itertools.product(*hyperparameter.values()):\n",
    "    (beta, noise_std, alpha_recon, alpha_feature, latent_dim, lr, seed) = vals\n",
    "    cnt += 1\n",
    "    print(\"=============================================\")\n",
    "    print(f\"Experiment {cnt}/{len(list(itertools.product(*hyperparameter.values())))}\")\n",
    "    print(f\"beta={beta}, alpha_recon={alpha_recon}, alpha_feature={alpha_feature},\\nepochs={epochs}, latent_dim={latent_dim}, hidden_dim={hidden_dim}, lr={lr}, seed={seed}\")\n",
    "\n",
    "    seed_everything(seed)\n",
    "\n",
    "    vae = VAE_feature_head(input_dim=input_dim, feature_dim=feature_train.shape[-1], latent_dim=latent_dim, hidden_dim=hidden_dim).to(device)\n",
    "    optimizer = torch.optim.Adam(vae.parameters(), lr=lr)\n",
    "\n",
    "    # early stopping\n",
    "    best_val_loss = float('inf')\n",
    "    patience = 30\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        vae.train()\n",
    "        for x_batch, feature_batch in train_loader:\n",
    "            x_batch = x_batch.to(device)  # (N, D)\n",
    "            feature_batch = feature_batch.to(device)\n",
    "\n",
    "            x_recon, mu, logvar, z, feature_pred = vae(x_batch, use_mean=False)\n",
    "\n",
    "            loss, recon_loss, kl, feature_loss = vae_feature_loss(x_recon, x_batch, mu, logvar, feature_pred, feature_batch, alpha_recon=alpha_recon, alpha_feature=alpha_feature, beta=beta)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        vae.eval()\n",
    "        for x_batch, feature_batch in val_loader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            feature_batch = feature_batch.to(device)\n",
    "            x_recon, mu, logvar, z, feature_pred = vae(x_batch, use_mean=True)\n",
    "            val_loss, val_recon_loss, val_kl, val_feature_loss = vae_feature_loss(x_recon, x_batch, mu, logvar, feature_pred, feature_batch, alpha_recon=alpha_recon, alpha_feature=alpha_feature, beta=beta)\n",
    "            val_recon_r2 = r2_score(x_batch.detach().cpu().numpy(), x_recon.detach().cpu().numpy())\n",
    "            val_feature_r2 = r2_score(feature_batch.detach().cpu().numpy(), feature_pred.detach().cpu().numpy())\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss.item()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            \n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch}\")\n",
    "                break\n",
    "    print(f\"epoch {epoch}: loss={loss.item():.4f}, recon={recon_loss.item():.4f}, feature={feature_loss.item():.4f}, kl={kl.item():.4f}\")\n",
    "    print(f\"epoch {epoch}: val loss={val_loss.item():.4f}, val recon={val_recon_loss.item():.4f}, val feature={val_feature_loss.item():.4f}, val kl={val_kl.item():.4f}\")\n",
    "\n",
    "    print(f\"Recon R2 : {val_recon_r2}, Feature R2 : {val_feature_r2}\")\n",
    "    \n",
    "    results.append({\n",
    "        \"beta\": beta,\n",
    "        \"alpha_recon\": alpha_recon,\n",
    "        \"alpha_feature\": alpha_feature,\n",
    "        \"latent_dim\": latent_dim,\n",
    "        \"hidden_dim\": hidden_dim,\n",
    "        \"lr\": lr,\n",
    "        \"seed\": seed,\n",
    "        \"best_val_loss\": best_val_loss,\n",
    "        \"final_val_recon_r2\": val_recon_r2,\n",
    "        \"final_val_feature_r2\": val_feature_r2,\n",
    "    })\n",
    "    print(\"Next experiment..\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "ebf18a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.drop(columns=['noise_std'])\n",
    "# 시드를 하나로 묶어서 평균, 표준편차 계산\n",
    "grouped = results_df.groupby(['beta', 'alpha_recon', 'alpha_feature', 'latent_dim', 'hidden_dim', 'lr']).agg(\n",
    "    mean_val_loss = ('best_val_loss', 'mean'),\n",
    "    std_val_loss = ('best_val_loss', 'std'),\n",
    "    mean_recon_r2 = ('final_val_recon_r2', 'mean'),\n",
    "    std_recon_r2 = ('final_val_recon_r2', 'std'),\n",
    "    mean_feature_r2 = ('final_val_feature_r2', 'mean'),\n",
    "    std_feature_r2 = ('final_val_feature_r2', 'std'),\n",
    "    \n",
    ").reset_index()\n",
    "\n",
    "grouped = grouped.round({\n",
    "    'mean_val_loss': 4,\n",
    "    'std_val_loss': 4,\n",
    "    'mean_recon_r2': 4,\n",
    "    'std_recon_r2': 4,\n",
    "    'mean_feature_r2': 4,\n",
    "    'std_feature_r2': 4,\n",
    "})\n",
    "\n",
    "grouped.to_csv(\"vae_feature_head_hyperparameter_search_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5eff19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================\n",
      "Experiment 1/1\n",
      "beta=0.01, alpha_recon=1.0, alpha_feature=1.0,\n",
      "epochs=300, latent_dim=64, hidden_dim=256, lr=0.001, seed=2025\n",
      "epoch 300: loss=0.0440, recon=0.0086, feature=0.0121, kl=2.3310\n",
      "epoch 300: val loss=0.0877, val recon=0.0211, val feature=0.0434, val kl=2.3236\n",
      "Recon R2 : 0.978883535645712, Feature R2 : 0.4322361224188036\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "import itertools\n",
    "import torch\n",
    "import pandas as pd\n",
    "# 예시 세팅\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val, feature_train, feature_val = train_test_split(\n",
    "    input_data_scaled, cost, feature_scaled,  test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = FeatureDataset(X_train, feature_train)\n",
    "val_dataset   = FeatureDataset(X_val,   feature_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=512, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "input_dim = X_train.shape[-1]\n",
    "latent_dim = 64\n",
    "hidden_dim = 256\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "hyperparameter = {\n",
    "    'beta': [0.01],\n",
    "    'alpha_recon': [0.1],\n",
    "    'alpha_feature': [1.0],\n",
    "    'latent_dim': [64],\n",
    "    'lr': [1e-3],\n",
    "}\n",
    "\n",
    "cnt = 0\n",
    "epochs = 300\n",
    "\n",
    "\n",
    "for vals in itertools.product(*hyperparameter.values()):\n",
    "    (beta, alpha_recon, alpha_feature, latent_dim, lr) = vals\n",
    "    cnt += 1\n",
    "    print(\"=============================================\")\n",
    "    print(f\"Experiment {cnt}/{len(list(itertools.product(*hyperparameter.values())))}\")\n",
    "    print(f\"beta={beta}, alpha_recon={alpha_recon}, alpha_feature={alpha_feature},\\nepochs={epochs}, latent_dim={latent_dim}, hidden_dim={hidden_dim}, lr={lr}, seed={seed}\")\n",
    "\n",
    "    seed_everything(42)\n",
    "\n",
    "    vae = VAE_feature_head(input_dim=input_dim, latent_dim=latent_dim, hidden_dim=hidden_dim).to(device)\n",
    "    optimizer = torch.optim.Adam(vae.parameters(), lr=lr)\n",
    "\n",
    "    # early stopping\n",
    "    best_val_loss = float('inf')\n",
    "    patience = 30\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        vae.train()\n",
    "        for x_batch, feature_batch in train_loader:\n",
    "            x_batch = x_batch.to(device)  # (N, D)\n",
    "            feature_batch = feature_batch.to(device)\n",
    "\n",
    "            x_recon, mu, logvar, z, feature_pred = vae(x_batch, use_mean=False)\n",
    "\n",
    "            loss, recon_loss, kl, feature_loss = vae_feature_loss(x_recon, x_batch, mu, logvar, feature_pred, feature_batch, alpha_recon=alpha_recon, alpha_feature=alpha_feature, beta=beta)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        vae.eval()\n",
    "        for x_batch, feature_batch in val_loader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            feature_batch = feature_batch.to(device)\n",
    "            x_recon, mu, logvar, z, feature_pred = vae(x_batch, use_mean=True)\n",
    "            val_loss, val_recon_loss, val_kl, val_feature_loss = vae_feature_loss(x_recon, x_batch, mu, logvar, feature_pred, feature_batch, alpha_recon=alpha_recon, alpha_feature=alpha_feature, beta=beta)\n",
    "            val_recon_r2 = r2_score(x_batch.detach().cpu().numpy(), x_recon.detach().cpu().numpy())\n",
    "            val_feature_r2 = r2_score(feature_batch.detach().cpu().numpy(), feature_pred.detach().cpu().numpy())\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss.item()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            \n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch}\")\n",
    "                break\n",
    "    print(f\"epoch {epoch}: loss={loss.item():.4f}, recon={recon_loss.item():.4f}, feature={feature_loss.item():.4f}, kl={kl.item():.4f}\")\n",
    "    print(f\"epoch {epoch}: val loss={val_loss.item():.4f}, val recon={val_recon_loss.item():.4f}, val feature={val_feature_loss.item():.4f}, val kl={val_kl.item():.4f}\")\n",
    "\n",
    "    print(f\"Recon R2 : {val_recon_r2}, Feature R2 : {val_feature_r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a018748",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAECostPredictor(nn.Module):\n",
    "    \"\"\"\n",
    "    VAE 기반 Cost Regression 모델\n",
    "    \n",
    "    구조:\n",
    "    - input → segment_encoder → segment_sum → VAE encoder → z → cost_predictor → cost\n",
    "    \n",
    "    특징:\n",
    "    - Pretrained VAE encoder를 finetune (작은 learning rate)\n",
    "    - Cost predictor는 더 큰 learning rate로 학습\n",
    "    - 전체 forward 경로가 완전히 미분 가능 (detach, stop_grad 없음)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim=256, latent_dim=64, \n",
    "                 predictor_hidden=256, predictor_layers=2, dropout=0.1, use_feature=True):\n",
    "        super(VAECostPredictor, self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.fc_mu = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(hidden_dim, latent_dim)\n",
    "        \n",
    "        # ========== Cost Predictor (새로 학습) ==========\n",
    "        predictor_modules = []\n",
    "        current_dim = latent_dim\n",
    "        for i in range(predictor_layers):\n",
    "            predictor_modules.extend([\n",
    "                nn.Linear(current_dim, predictor_hidden),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout) if i < predictor_layers - 1 else nn.Identity(),\n",
    "            ])\n",
    "            current_dim = predictor_hidden\n",
    "        predictor_modules.append(nn.Linear(predictor_hidden, 1))\n",
    "        \n",
    "        self.cost_predictor = nn.Sequential(*predictor_modules)\n",
    "\n",
    "        self.use_feature = use_feature\n",
    "        self.feature_predictor = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, features.shape[-1]),  # features.shape[1]는 feature 차원\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def encode(self, input_data):\n",
    "        \"\"\"\n",
    "        Full encoding path: features → z\n",
    "        완전히 미분 가능\n",
    "        \"\"\"\n",
    "                \n",
    "        # VAE Encoder\n",
    "        h = self.encoder(input_data)\n",
    "        \n",
    "        mean = self.fc_mu(h)\n",
    "        logvar = self.fc_logvar(h)\n",
    "        \n",
    "        return mean, logvar, input_data\n",
    "    \n",
    "    def reparameterize(self, mean, logvar):\n",
    "        \"\"\"Reparameterization trick - 미분 가능\"\"\"\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mean + eps * std\n",
    "    \n",
    "    def predict_cost(self, z):\n",
    "        \"\"\"z → cost prediction - 완전히 미분 가능\"\"\"\n",
    "        return self.cost_predictor(z).squeeze(-1)\n",
    "    \n",
    "    def predict_feature(self, z):\n",
    "        return self.feature_predictor(z)\n",
    "    \n",
    "    def forward(self, input_data, use_mean=True):\n",
    "        \"\"\"\n",
    "        Forward pass: input → z → cost\n",
    "        \n",
    "        Args:\n",
    "            use_mean: True면 reparameterize 대신 mean 사용 (inference용)\n",
    "        \n",
    "        Returns:\n",
    "            cost_pred: 예측된 cost\n",
    "            mean: latent mean\n",
    "            logvar: latent log-variance\n",
    "            z: sampled/mean latent vector\n",
    "        \"\"\"\n",
    "        mean, logvar, input_data = self.encode(input_data)\n",
    "        \n",
    "        if use_mean:\n",
    "            z = mean  # Inference시 deterministic\n",
    "        else:\n",
    "            z = self.reparameterize(mean, logvar)  # Training시 stochastic\n",
    "        \n",
    "        cost_pred = self.predict_cost(z)\n",
    "        \n",
    "        return cost_pred, mean, logvar, z\n",
    "    \n",
    "    def get_encoder_params(self):\n",
    "        \"\"\"Encoder 파라미터 (작은 lr)\"\"\"\n",
    "        encoder_params = []\n",
    "        encoder_params.extend(self.encoder.parameters())\n",
    "        encoder_params.extend(self.fc_mu.parameters())\n",
    "        encoder_params.extend(self.fc_logvar.parameters())\n",
    "        return encoder_params\n",
    "    \n",
    "    def get_cost_predictor_params(self):\n",
    "        \"\"\"Predictor 파라미터 (큰 lr)\"\"\"\n",
    "        return self.cost_predictor.parameters()\n",
    "    \n",
    "    def get_feature_predictor_params(self):\n",
    "        \"\"\"Feature Predictor 파라미터\"\"\"\n",
    "        return self.feature_predictor.parameters()\n",
    "\n",
    "    def load_pretrained_encoder(self, checkpoint):\n",
    "        \"\"\"Pretrained VAE encoder 가중치 로드\"\"\"\n",
    "        \n",
    "\n",
    "        vae_state = checkpoint\n",
    "        \n",
    "        # 매칭되는 키만 로드\n",
    "        encoder_keys = ['encoder', 'fc_mu', 'fc_logvar', 'feature_predictor', ']']\n",
    "        own_state = self.state_dict()\n",
    "        \n",
    "        loaded_keys = []\n",
    "        for name, param in vae_state.items():\n",
    "            if any(name.startswith(k) for k in encoder_keys):\n",
    "                if name in own_state and own_state[name].shape == param.shape:\n",
    "                    own_state[name].copy_(param)\n",
    "                    loaded_keys.append(name)\n",
    "        \n",
    "        # print(f\"Loaded {len(loaded_keys)} parameters from pretrained VAE\")\n",
    "        # return loaded_keys\n",
    "\n",
    "def pair_accuracy(cost_pred, labels):\n",
    "    \"\"\"\n",
    "    cost_pred, labels: (B,) 텐서\n",
    "    \"\"\"\n",
    "    n_samples = min(1000, len(cost_pred))\n",
    "    sample_indices = np.random.choice(len(cost_pred), n_samples, replace=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for i in range(n_samples):\n",
    "            for j in range(i + 1, n_samples):\n",
    "                idx_i = sample_indices[i]\n",
    "                idx_j = sample_indices[j]\n",
    "                pred_diff = cost_pred[idx_i] - cost_pred[idx_j]\n",
    "                true_diff = labels[idx_i] - labels[idx_j]\n",
    "                if (pred_diff * true_diff) > 0:\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "        accuracy = correct / total if total > 0 else 0.0\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "f655fc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_loss_fn(cost_pred, cost_true, loss_type='mse'):\n",
    "    \"\"\"\n",
    "    기본 회귀 손실 (MSE 또는 MAE)\n",
    "    \"\"\"\n",
    "    if loss_type == 'mse':\n",
    "        return F.mse_loss(cost_pred, cost_true)\n",
    "    else:  # mae\n",
    "        return F.l1_loss(cost_pred, cost_true)\n",
    "\n",
    "\n",
    "def pair_loss_fn(cost_pred, cost_true, margin=0.1):\n",
    "    \"\"\"\n",
    "    Pairwise ranking loss: 실제 cost 순서를 예측이 유지하도록.\n",
    "    cost_true[i] < cost_true[j] 이면 cost_pred[i] < cost_pred[j] + margin\n",
    "    \"\"\"\n",
    "    batch_size = cost_pred.size(0)\n",
    "    if batch_size < 2:\n",
    "        return torch.tensor(0.0, device=cost_pred.device)\n",
    "    \n",
    "    # 모든 쌍에 대해 ranking loss 계산\n",
    "    idx = torch.arange(batch_size, device=cost_pred.device)\n",
    "    i_idx, j_idx = torch.meshgrid(idx, idx, indexing='ij')\n",
    "    mask = i_idx < j_idx  # upper triangular only\n",
    "    \n",
    "    pred_i = cost_pred[i_idx[mask]]\n",
    "    pred_j = cost_pred[j_idx[mask]]\n",
    "    true_i = cost_true[i_idx[mask]]\n",
    "    true_j = cost_true[j_idx[mask]]\n",
    "    \n",
    "    # label: 1 if true_i < true_j, -1 otherwise\n",
    "    labels = torch.sign(true_j - true_i).float()\n",
    "    \n",
    "    # Margin ranking loss\n",
    "    loss = F.margin_ranking_loss(pred_j.view(-1), pred_i.view(-1), labels.view(-1), margin=margin)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def smooth_loss_fn(model, z, noise_std=0.1):\n",
    "    \"\"\"\n",
    "    Smoothness loss: z에 작은 노이즈를 더했을 때 예측이 크게 변하지 않도록.\n",
    "    \"\"\"\n",
    "    z_noisy = z + noise_std * torch.randn_like(z)\n",
    "    \n",
    "    cost_original = model.predict_cost(z)\n",
    "    cost_noisy = model.predict_cost(z_noisy)\n",
    "    \n",
    "    smooth_loss = F.mse_loss(cost_original, cost_noisy)\n",
    "    return smooth_loss\n",
    "\n",
    "\n",
    "def kld_loss_fn(mean, logvar):\n",
    "    \"\"\"\n",
    "    KL Divergence: q(z|x) || N(0, I)\n",
    "    \"\"\"\n",
    "    kld = -0.5 * torch.mean(1 + logvar - mean.pow(2) - logvar.exp())\n",
    "    return kld\n",
    "\n",
    "def feature_loss_fn(use_feature, feature_pred, feature_true, coef=0.1):\n",
    "    \"\"\"\n",
    "    Feature 예측 손실 (MSE)\n",
    "    \"\"\"\n",
    "    if not use_feature:\n",
    "        return torch.tensor(0.0, device=feature_pred.device)\n",
    "    return F.mse_loss(feature_pred, feature_true) * coef\n",
    "\n",
    "\n",
    "def compute_total_loss(model, cost_pred, mean, logvar, z, labels, feature, config, return_components=True):\n",
    "    \"\"\"\n",
    "    Total loss 계산 (Segment 기반 데이터용).\n",
    "    total_loss = reg_loss + λ_pair * pair_loss + γ * smooth_loss + β * kld_loss\n",
    "    \"\"\"\n",
    "    \n",
    "    # Individual losses\n",
    "    reg = reg_loss_fn(cost_pred, labels, loss_type=config.get('loss_type', 'mse'))\n",
    "    pair = pair_loss_fn(cost_pred.view(-1), labels.view(-1), margin=config.get('margin', 0.1))\n",
    "    smooth = smooth_loss_fn(model, z, noise_std=config.get('noise_std', 0.1))\n",
    "    kld = kld_loss_fn(mean, logvar)\n",
    "    feature_loss = feature_loss_fn(model.use_feature, model.predict_feature(z), feature, coef=config.get('alpha', 0.1))\n",
    "    \n",
    "    # Weighted sum\n",
    "    total = config['lambda_reg'] * reg + config['lambda_pair'] * pair + config['gamma'] * smooth + config['beta'] * kld + feature_loss\n",
    "    \n",
    "    if return_components:\n",
    "        return total, {\n",
    "            'reg_loss': reg.item(),\n",
    "            'pair_loss': pair.item(),\n",
    "            'smooth_loss': smooth.item(),\n",
    "            'kld_loss': kld.item(),\n",
    "            'feature_loss': feature_loss.item(),\n",
    "        }\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "8f4b2fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = np.log(json_diffs[\"diff_values\"]+1e-8)\n",
    "costs = -np.log(json_diffs[\"cost\"])\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "input_data_scaled = scaler.fit_transform(input_data)\n",
    "features_scaled = scaler.fit_transform(features_mean)\n",
    "\n",
    "# X_train_reg, X_val_reg, y_train_reg, y_val_reg = train_test_split(\n",
    "#     input_data_scaled, costs, test_size=0.2, random_state=42\n",
    "# )\n",
    "\n",
    "X_train_reg, X_val_reg, y_train_reg, y_val_reg, feature_train, feature_val = train_test_split(\n",
    "    input_data_scaled, costs, features_scaled,  test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "train_dataset = FeatureRegressionDataset(X_train_reg, y_train_reg, feature_train)\n",
    "val_dataset   = FeatureRegressionDataset(X_val_reg,   y_val_reg, feature_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=False)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=256, shuffle=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "09013e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train mean: 6.333581531911031, std: 1.3555901482101775\n"
     ]
    }
   ],
   "source": [
    "input_data = np.log(json_diffs[\"diff_values\"]+1e-8)\n",
    "costs = -np.log(json_diffs[\"cost\"])\n",
    "\n",
    "\n",
    "train_size = 64\n",
    "\n",
    "np.random.seed(42)\n",
    "random_indices = np.random.permutation(len(input_data))\n",
    "# random_indices = np.arange(len(input_data))\n",
    "\n",
    "scaler = StandardScaler()\n",
    "input_data_scaled = scaler.fit_transform(input_data)\n",
    "features_scaled = scaler.fit_transform(features_mean)\n",
    "costs_scaled = (costs - costs.mean()) / (costs.std() + 1e-8)\n",
    "\n",
    "X_train = input_data_scaled[random_indices[:train_size]]\n",
    "X_val = input_data_scaled[random_indices[train_size:]]\n",
    "y_train = costs[random_indices[:train_size]]\n",
    "y_val = costs[random_indices[train_size:]]\n",
    "\n",
    "train_dataset = FeatureRegressionDataset(X_train, y_train, features_scaled[random_indices[:train_size]])\n",
    "val_dataset   = FeatureRegressionDataset(X_val,   y_val, features_scaled[random_indices[train_size:]])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=False)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=512, shuffle=False)\n",
    "\n",
    "y_mean = y_train.mean()\n",
    "y_std = y_train.std() + 1e-8  # 0 나누기 방지용 작은 값 추가\n",
    "print(f\"y_train mean: {y_mean}, std: {y_std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "029508f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================\n",
      "Experiment 1/4\n",
      "lambda_reg=0.01, lambda_pair=2.0, margin_scale=0.3, gamma=0.01, beta=0.01, noise_std=0.01, alpha=0.0001,\n",
      "encoder_lr=5e-05, feature_predictor_lr=0.0001, cost_predictor_lr=0.01, seed=True, use_feature=2023\n",
      "Train loss epoch 1000 : reg= 0.7724 rank= 0.0187 kl= 0.7057\n",
      "Val loss epoch 1000: reg= 1.9787 rank= 0.4563 kl= 0.5683\n",
      "Regression R2 : 0.2944, Rank R2 : 0.7516\n",
      "=============================================\n",
      "Experiment 2/4\n",
      "lambda_reg=0.01, lambda_pair=2.0, margin_scale=0.3, gamma=0.01, beta=0.01, noise_std=0.01, alpha=0.0001,\n",
      "encoder_lr=5e-05, feature_predictor_lr=0.0001, cost_predictor_lr=0.01, seed=True, use_feature=2024\n",
      "Train loss epoch 1000 : reg= 0.7724 rank= 0.0187 kl= 0.7057\n",
      "Val loss epoch 1000: reg= 1.9787 rank= 0.4563 kl= 0.5683\n",
      "Regression R2 : 0.2944, Rank R2 : 0.7541\n",
      "=============================================\n",
      "Experiment 3/4\n",
      "lambda_reg=0.01, lambda_pair=2.0, margin_scale=0.3, gamma=0.01, beta=0.01, noise_std=0.01, alpha=0.0001,\n",
      "encoder_lr=5e-05, feature_predictor_lr=0.01, cost_predictor_lr=0.01, seed=True, use_feature=2023\n",
      "Train loss epoch 1000 : reg= 0.8402 rank= 0.0193 kl= 0.7124\n",
      "Val loss epoch 1000: reg= 2.0076 rank= 0.4603 kl= 0.5734\n",
      "Regression R2 : 0.3127, Rank R2 : 0.7521\n",
      "=============================================\n",
      "Experiment 4/4\n",
      "lambda_reg=0.01, lambda_pair=2.0, margin_scale=0.3, gamma=0.01, beta=0.01, noise_std=0.01, alpha=0.0001,\n",
      "encoder_lr=5e-05, feature_predictor_lr=0.01, cost_predictor_lr=0.01, seed=True, use_feature=2024\n",
      "Train loss epoch 1000 : reg= 0.8402 rank= 0.0193 kl= 0.7124\n",
      "Val loss epoch 1000: reg= 2.0076 rank= 0.4603 kl= 0.5734\n",
      "Regression R2 : 0.3127, Rank R2 : 0.7561\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "input_dim = X_train.shape[-1]\n",
    "latent_dim = 64\n",
    "hidden_dim = 256\n",
    "\n",
    "\n",
    "hyperparameter = {\n",
    "    # 'lambda_reg' : [0.01, 0.1],\n",
    "    # 'lambda_pair': [2.0, 3.0],\n",
    "    # 'margin_scale': [0.3],\n",
    "    # 'gamma': [0.01, 0.1],\n",
    "    # 'beta': [0.01, 0.1],\n",
    "    # 'noise_std': [0.001, 0.01],\n",
    "    # 'alpha': [1e-4, 1e-3],\n",
    "\n",
    "    # 'encoder_lr': [5e-5],\n",
    "    # 'feature_predictor_lr': [1e-4, 1e-2],\n",
    "    # 'cost_predictor_lr': [1e-2],\n",
    "    # 'seed': [True, False],\n",
    "    # 'use_feature': [2023, 2024],\n",
    "\n",
    "\n",
    "    'lambda_reg' : [0.01],\n",
    "    'lambda_pair': [2.0],\n",
    "    'margin_scale': [0.3],\n",
    "    'gamma': [0.01],\n",
    "    'beta': [0.01],\n",
    "    'noise_std': [0.01],\n",
    "    'alpha': [1e-4],\n",
    "    'encoder_lr': [5e-5],\n",
    "    'feature_predictor_lr': [1e-4, 1e-2],\n",
    "    'cost_predictor_lr': [1e-2],\n",
    "    'use_feature': [True],\n",
    "    'seed': [2023, 2024],\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "all_reg_results = []\n",
    "cnt = 0\n",
    "\n",
    "for vals in itertools.product(*hyperparameter.values()):\n",
    "    \n",
    "    \n",
    "    (lambda_reg, lambda_pair, margin_scale, gamma, beta, noise_std, alpha,\n",
    "     encoder_lr, feature_predictor_lr, cost_predictor_lr, seed, use_feature) = vals\n",
    "    \n",
    "    cnt += 1\n",
    "    print(\"=============================================\")\n",
    "    print(f\"Experiment {cnt}/{len(list(itertools.product(*hyperparameter.values())))}\")\n",
    "    print(f\"lambda_reg={lambda_reg}, lambda_pair={lambda_pair}, margin_scale={margin_scale}, gamma={gamma}, beta={beta}, noise_std={noise_std}, alpha={alpha},\\nencoder_lr={encoder_lr}, feature_predictor_lr={feature_predictor_lr}, cost_predictor_lr={cost_predictor_lr}, seed={seed}, use_feature={use_feature}\")\n",
    "\n",
    "    config = {\n",
    "                'encoder_lr': encoder_lr,\n",
    "                'feature_predictor_lr': feature_predictor_lr,\n",
    "                'cost_predictor_lr': cost_predictor_lr,\n",
    "                'lambda_reg' : lambda_reg,\n",
    "                'lambda_pair': lambda_pair,\n",
    "                'gamma': gamma,\n",
    "                'beta': beta,\n",
    "                'margin': margin_scale * y_std,\n",
    "                'noise_std': noise_std,\n",
    "                'alpha': alpha,\n",
    "                'loss_type': 'mse'\n",
    "            }\n",
    "\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    vae_cost_model = VAECostPredictor(input_dim=input_dim, \n",
    "                                    latent_dim=latent_dim, \n",
    "                                    hidden_dim=hidden_dim, \n",
    "                                    predictor_layers=2,\n",
    "                                    dropout=0.1, use_feature=use_feature).to(device)\n",
    "    # vae_cost_model.load_pretrained_encoder(vae.state_dict())\n",
    "\n",
    "\n",
    "    optimizer = torch.optim.AdamW([\n",
    "            {'params': vae_cost_model.get_encoder_params(), 'lr': config['encoder_lr']},\n",
    "            {'params': vae_cost_model.get_feature_predictor_params(), 'lr': config['feature_predictor_lr']},\n",
    "            {'params': vae_cost_model.get_cost_predictor_params(), 'lr': config['cost_predictor_lr']}\n",
    "        ], weight_decay=1e-5)\n",
    "\n",
    "\n",
    "    epochs = 1000\n",
    "    best_val_loss = float('inf')\n",
    "    patience = 30\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        vae_cost_model.train()\n",
    "        for x_batch, labels, features in train_loader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            labels = labels.to(device).squeeze(-1)\n",
    "            features = features.to(device)\n",
    "            \n",
    "        \n",
    "            cost_pred, mean, logvar, z = vae_cost_model(x_batch, use_mean=False)\n",
    "\n",
    "            train_loss, train_components = compute_total_loss(vae_cost_model, \n",
    "                                                    cost_pred, mean, logvar, z, labels, features, config)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(vae_cost_model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "        \n",
    "\n",
    "        if epoch % epochs == 0:\n",
    "            vae_cost_model.eval()\n",
    "            all_preds = []\n",
    "            all_labels = []\n",
    "            for x_batch, labels, features in val_loader:\n",
    "                x_batch = x_batch.to(device)\n",
    "                labels = labels.to(device).squeeze(-1)\n",
    "                features = features.to(device)\n",
    "\n",
    "                cost_pred, mean, logvar, z = vae_cost_model(x_batch, use_mean=True)\n",
    "\n",
    "                val_loss, val_components = compute_total_loss(vae_cost_model, cost_pred, mean, logvar, z, labels, features, config)\n",
    "            val_reg_r2 = r2_score(cost_pred.detach().cpu().numpy(), labels.detach().cpu().numpy())\n",
    "                \n",
    "            print(f\"Train loss epoch {epoch} : reg={train_components['reg_loss']: .4f} rank={train_components['pair_loss']: .4f} kl={train_components['kld_loss']: .4f}\")\n",
    "            print(f\"Val loss epoch {epoch}: reg={val_components['reg_loss']: .4f} rank={val_components['pair_loss']: .4f} kl={val_components['kld_loss']: .4f}\")\n",
    "            \n",
    "            print(f\"Regression R2 : {val_reg_r2:.4f}, \", end='')\n",
    "        \n",
    "        # rank r2 계산\n",
    "        if epoch == epochs:\n",
    "            all_preds = []\n",
    "            all_labels = []\n",
    "            for x_batch, labels, features in val_loader:\n",
    "                x_batch = x_batch.to(device)\n",
    "                labels = labels.to(device).squeeze(-1)\n",
    "                features = features.to(device)\n",
    "                cost_pred, mean, logvar, z = vae_cost_model(x_batch, use_mean=True)\n",
    "                all_preds.append(cost_pred.detach().cpu().numpy())\n",
    "                all_labels.append(labels.detach().cpu().numpy())\n",
    "            all_preds = np.concatenate(all_preds, axis=0)\n",
    "            all_labels = np.concatenate(all_labels, axis=0)\n",
    "            val_rank_r2 = pair_accuracy(all_preds, all_labels)\n",
    "            print(f\"Rank R2 : {val_rank_r2:.4f}\")\n",
    "    all_reg_results.append({\n",
    "        \"lambda_reg\": lambda_reg,\n",
    "        \"lambda_pair\": lambda_pair,\n",
    "        \"margin_scale\": margin_scale,\n",
    "        \"gamma\": gamma,\n",
    "        \"beta\": beta,\n",
    "        \"noise_std\": noise_std,\n",
    "        \"alpha\": alpha,\n",
    "        \"encoder_lr\": encoder_lr,\n",
    "        \"feature_predictor_lr\": feature_predictor_lr,\n",
    "        \"cost_predictor_lr\": cost_predictor_lr,\n",
    "        \"use_feature\": use_feature,\n",
    "        \"seed\": seed,\n",
    "        \"reg_r2\": val_reg_r2,\n",
    "        \"rank_r2\": val_rank_r2,\n",
    "    })\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "9f8dd7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reg_results_df = pd.DataFrame(all_reg_results)\n",
    "# seed랑 use_feature 이름 바뀌어서 다시 맞추기\n",
    "reg_results_df = reg_results_df.rename(columns={\"use_feature\": \"seed\", \"seed\":\"use_feature\"})\n",
    "\n",
    "\n",
    "# 시드를 하나로 묶어서 평균, 표준편차 계산\n",
    "grouped = reg_results_df.groupby(['lambda_reg', 'lambda_pair', 'margin_scale', 'gamma', 'beta', 'noise_std', 'alpha', 'encoder_lr', 'feature_predictor_lr', 'cost_predictor_lr', 'use_feature']).agg(\n",
    "    mean_reg_r2 = ('reg_r2', 'mean'),\n",
    "    std_reg_r2 = ('reg_r2', 'std'),\n",
    "    mean_rank_r2 = ('rank_r2', 'mean'),\n",
    "    std_rank_r2 = ('rank_r2', 'std'),\n",
    ").reset_index()\n",
    "\n",
    "grouped = grouped.round({\n",
    "    'mean_reg_r2': 4,\n",
    "    'std_reg_r2': 4,\n",
    "    'mean_rank_r2': 4,\n",
    "    'std_rank_r2': 4,\n",
    "})\n",
    "\n",
    "grouped.to_csv(\"vae_feature_guided_reg_featlr2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2160648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric: val_reg_r2\n",
      "  Seed 2000: Mean=0.5778, Std=0.0018\n",
      "  Seed 2001: Mean=0.5438, Std=0.0209\n",
      "  Seed 2002: Mean=0.5528, Std=0.0101\n",
      "  Seed 2003: Mean=0.5714, Std=0.0043\n",
      "  Seed 2004: Mean=0.5623, Std=0.0007\n",
      "  Seed 2005: Mean=0.5557, Std=0.0066\n",
      "  Seed 2006: Mean=0.5637, Std=0.0160\n",
      "  Seed 2007: Mean=0.5394, Std=0.0026\n",
      "  Seed 2008: Mean=0.5278, Std=0.0007\n",
      "  Seed 2009: Mean=0.5703, Std=0.0074\n",
      "Overall: Mean=0.5565, Std=0.0178\n",
      "Metric: val_rank_r2\n",
      "  Seed 2000: Mean=0.8089, Std=0.0006\n",
      "  Seed 2001: Mean=0.8063, Std=0.0007\n",
      "  Seed 2002: Mean=0.8098, Std=0.0012\n",
      "  Seed 2003: Mean=0.8076, Std=0.0008\n",
      "  Seed 2004: Mean=0.8029, Std=0.0108\n",
      "  Seed 2005: Mean=0.8068, Std=0.0026\n",
      "  Seed 2006: Mean=0.8109, Std=0.0020\n",
      "  Seed 2007: Mean=0.8092, Std=0.0065\n",
      "  Seed 2008: Mean=0.7971, Std=0.0036\n",
      "  Seed 2009: Mean=0.8064, Std=0.0029\n",
      "Overall: Mean=0.8066, Std=0.0058\n"
     ]
    }
   ],
   "source": [
    "for metric in [\"val_reg_r2\", \"val_rank_r2\"]:\n",
    "    print(f\"Metric: {metric}\")\n",
    "    all_values = []\n",
    "    for seed in hyperparameter['seed']:\n",
    "        values = history[seed][metric]\n",
    "        all_values.extend(values)\n",
    "        mean_val = np.mean(values)\n",
    "        std_val = np.std(values)\n",
    "    \n",
    "    overall_mean = np.mean(all_values)\n",
    "    overall_std = np.std(all_values)\n",
    "    print(f\"Overall: Mean={overall_mean:.4f}, Std={overall_std:.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20951b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# true, pred cost 시각화\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(all_labels, all_preds, alpha=0.3, s=10)\n",
    "plt.xlabel(\"True Cost\")\n",
    "plt.ylabel(\"Predicted Cost\")\n",
    "plt.title(\"True vs Predicted Cost\")\n",
    "plt.plot([all_labels.min(), all_labels.max()], [all_labels.min(), all_labels.max()], 'r--')  # y=x 선\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "ccde4079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "모델 파라미터 수:\n",
      "   Encoder: 172,928\n",
      "   Feature Predictor: 124,580\n",
      "   Cost Predictor: 82,689\n",
      "   Total: 380,197\n"
     ]
    }
   ],
   "source": [
    "enc_params = sum(p.numel() for p in vae_cost_model.get_encoder_params())\n",
    "feature_params = sum(p.numel() for p in vae_cost_model.get_feature_predictor_params())\n",
    "cost_params = sum(p.numel() for p in vae_cost_model.get_cost_predictor_params())\n",
    "print(f\"\\n모델 파라미터 수:\")\n",
    "print(f\"   Encoder: {enc_params:,}\")\n",
    "print(f\"   Feature Predictor: {feature_params:,}\")\n",
    "print(f\"   Cost Predictor: {cost_params:,}\")\n",
    "print(f\"   Total: {enc_params + feature_params + cost_params:,}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
