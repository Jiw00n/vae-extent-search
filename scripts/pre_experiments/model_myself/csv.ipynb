{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "523b0023",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import time\n",
    "\n",
    "project_root = \"/root/work/tenset\"\n",
    "os.environ[\"TVM_HOME\"] = f\"{project_root}\"\n",
    "os.environ[\"TVM_LIBRARY_PATH\"] = f\"{project_root}/build\"\n",
    "if f\"{project_root}/python\" not in sys.path:\n",
    "    sys.path.insert(0, f\"{project_root}/python\")\n",
    "    \n",
    "\n",
    "sys.path = [p for p in sys.path if not p.startswith(f\"{project_root}/build\")]\n",
    "sys.path.append(f\"{project_root}/build\")\n",
    "os.environ[\"LD_LIBRARY_PATH\"] = f\"{project_root}/build:\" + os.environ.get(\"LD_LIBRARY_PATH\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00951bb",
   "metadata": {},
   "source": [
    "1. Total 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea4db949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>measure_size</th>\n",
       "      <th>scratch</th>\n",
       "      <th>encoder_freeze</th>\n",
       "      <th>encoder_lr</th>\n",
       "      <th>cost_predictor_lr</th>\n",
       "      <th>weights</th>\n",
       "      <th>uncertainty_topk</th>\n",
       "      <th>grad_num</th>\n",
       "      <th>rand_num</th>\n",
       "      <th>phase</th>\n",
       "      <th>used_time</th>\n",
       "      <th>train_size</th>\n",
       "      <th>val_reg_r2</th>\n",
       "      <th>val_rank_r2</th>\n",
       "      <th>sampling_seed</th>\n",
       "      <th>rank_warmup_epochs</th>\n",
       "      <th>top-1</th>\n",
       "      <th>T_mc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>(0.4, 0.3, 0.3)</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.44</td>\n",
       "      <td>64</td>\n",
       "      <td>[0.8153]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>(0.4, 0.3, 0.3)</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.44</td>\n",
       "      <td>64</td>\n",
       "      <td>[0.713]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>2001</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>(0.4, 0.3, 0.3)</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.41</td>\n",
       "      <td>64</td>\n",
       "      <td>[0.7737]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>2002</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>(0.4, 0.3, 0.3)</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11.19</td>\n",
       "      <td>192</td>\n",
       "      <td>[0.7897, 0.7438, 0.8066]</td>\n",
       "      <td>[None, None, None]</td>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>(0.4, 0.3, 0.3)</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10.98</td>\n",
       "      <td>192</td>\n",
       "      <td>[0.7887, 0.8399, 0.8845]</td>\n",
       "      <td>[None, None, None]</td>\n",
       "      <td>2004</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>48</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>(0.4, 0.3, 0.3)</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.10</td>\n",
       "      <td>32</td>\n",
       "      <td>[0.6055]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>2015</td>\n",
       "      <td>500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>48</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>(0.4, 0.3, 0.3)</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6.39</td>\n",
       "      <td>80</td>\n",
       "      <td>[0.512, 0.3426]</td>\n",
       "      <td>[None, None]</td>\n",
       "      <td>2016</td>\n",
       "      <td>500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>48</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>(0.4, 0.3, 0.3)</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.10</td>\n",
       "      <td>32</td>\n",
       "      <td>[0.4985]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>2017</td>\n",
       "      <td>500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8000</th>\n",
       "      <td>48</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>(0.4, 0.3, 0.3)</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9.81</td>\n",
       "      <td>128</td>\n",
       "      <td>[0.4944, 0.4233, 0.3679]</td>\n",
       "      <td>[None, None, None]</td>\n",
       "      <td>2018</td>\n",
       "      <td>500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8001</th>\n",
       "      <td>48</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>(0.4, 0.3, 0.3)</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6.38</td>\n",
       "      <td>80</td>\n",
       "      <td>[0.4926, 0.5142]</td>\n",
       "      <td>[None, None]</td>\n",
       "      <td>2019</td>\n",
       "      <td>500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8002 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      measure_size  scratch  encoder_freeze  encoder_lr  cost_predictor_lr  \\\n",
       "0               64    False           False     0.00010            0.01000   \n",
       "1               64    False           False     0.00010            0.01000   \n",
       "2               64    False           False     0.00010            0.01000   \n",
       "3               64    False           False     0.00010            0.01000   \n",
       "4               64    False           False     0.00010            0.01000   \n",
       "...            ...      ...             ...         ...                ...   \n",
       "7997            48    False           False     0.00001            0.00001   \n",
       "7998            48    False           False     0.00001            0.00001   \n",
       "7999            48    False           False     0.00001            0.00001   \n",
       "8000            48    False           False     0.00001            0.00001   \n",
       "8001            48    False           False     0.00001            0.00001   \n",
       "\n",
       "              weights  uncertainty_topk  grad_num  rand_num  phase  used_time  \\\n",
       "0     (0.4, 0.3, 0.3)                64         4         0      1       3.44   \n",
       "1     (0.4, 0.3, 0.3)                64         4         0      1       3.44   \n",
       "2     (0.4, 0.3, 0.3)                64         4         0      1       3.41   \n",
       "3     (0.4, 0.3, 0.3)                64         4         0      3      11.19   \n",
       "4     (0.4, 0.3, 0.3)                64         4         0      3      10.98   \n",
       "...               ...               ...       ...       ...    ...        ...   \n",
       "7997  (0.4, 0.3, 0.3)                64         4         0      1       3.10   \n",
       "7998  (0.4, 0.3, 0.3)                64         4         0      2       6.39   \n",
       "7999  (0.4, 0.3, 0.3)                64         4         0      1       3.10   \n",
       "8000  (0.4, 0.3, 0.3)                64         4         0      3       9.81   \n",
       "8001  (0.4, 0.3, 0.3)                64         4         0      2       6.38   \n",
       "\n",
       "      train_size                val_reg_r2         val_rank_r2  sampling_seed  \\\n",
       "0             64                  [0.8153]              [None]           2000   \n",
       "1             64                   [0.713]              [None]           2001   \n",
       "2             64                  [0.7737]              [None]           2002   \n",
       "3            192  [0.7897, 0.7438, 0.8066]  [None, None, None]           2003   \n",
       "4            192  [0.7887, 0.8399, 0.8845]  [None, None, None]           2004   \n",
       "...          ...                       ...                 ...            ...   \n",
       "7997          32                  [0.6055]              [None]           2015   \n",
       "7998          80           [0.512, 0.3426]        [None, None]           2016   \n",
       "7999          32                  [0.4985]              [None]           2017   \n",
       "8000         128  [0.4944, 0.4233, 0.3679]  [None, None, None]           2018   \n",
       "8001          80          [0.4926, 0.5142]        [None, None]           2019   \n",
       "\n",
       "      rank_warmup_epochs  top-1  T_mc  \n",
       "0                      0    NaN   NaN  \n",
       "1                      0    NaN   NaN  \n",
       "2                      0    NaN   NaN  \n",
       "3                      0    NaN   NaN  \n",
       "4                      0    NaN   NaN  \n",
       "...                  ...    ...   ...  \n",
       "7997                 500    0.0   NaN  \n",
       "7998                 500    1.0   NaN  \n",
       "7999                 500    0.0   NaN  \n",
       "8000                 500    0.0   NaN  \n",
       "8001                 500    1.0   NaN  \n",
       "\n",
       "[8002 rows x 18 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "csv_dir = glob(\n",
    "    \"/root/work/tenset/scripts/pre_experiments/model_myself/result/\"\n",
    "    \"([[]0c9a5ba46ffc5e1a9e5641018527117f,4,7,7,160,1,1,160,960,1,1,1,960,4,7,7,960[]],cuda).json/**/*.csv\", recursive=True\n",
    ")\n",
    "\n",
    "csvs = []\n",
    "for csv in csv_dir:\n",
    "    if \"avg\" in csv or \"total\" in csv or \"sampling\" in csv or \"prev\" in csv:\n",
    "       continue\n",
    "    csvs.append(csv) \n",
    "\n",
    "dfs = []\n",
    "for p in csvs:\n",
    "    sub_df = pd.read_csv(p)\n",
    "\n",
    "    if \"rank_warmup_epochs\" not in sub_df.columns:\n",
    "        sub_df[\"rank_warmup_epochs\"] = 0\n",
    "    if \"measure_size\" not in sub_df.columns:\n",
    "        sub_df[\"measure_size\"] = 64\n",
    "    if \"scratch\" not in sub_df.columns:\n",
    "        sub_df[\"scratch\"] = False\n",
    "    if \"encoder_freeze\" not in sub_df.columns:\n",
    "        sub_df[\"encoder_freeze\"] = False\n",
    "    \n",
    "    dfs.append(sub_df)\n",
    "\n",
    "    \n",
    "df_total = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# measure_size 컬럼을 맨 앞으로 이동\n",
    "cols = df_total.columns.tolist()\n",
    "df_total = df_total[[\"measure_size\"] + [c for c in cols if c != \"measure_size\"]]\n",
    "\n",
    "df_total.to_csv(\"/root/work/tenset/scripts/pre_experiments/model_myself/result/([0c9a5ba46ffc5e1a9e5641018527117f,4,7,7,160,1,1,160,960,1,1,1,960,4,7,7,960],cuda).json/vae_extent_total.csv\", index=True)\n",
    "df_total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf001ff9",
   "metadata": {},
   "source": [
    "2. Total avg 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47315380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>measure_size</th>\n",
       "      <th>scratch</th>\n",
       "      <th>encoder_freeze</th>\n",
       "      <th>encoder_lr</th>\n",
       "      <th>cost_predictor_lr</th>\n",
       "      <th>rank_warmup_epochs</th>\n",
       "      <th>weights</th>\n",
       "      <th>uncertainty_topk</th>\n",
       "      <th>grad_num</th>\n",
       "      <th>rand_num</th>\n",
       "      <th>phase</th>\n",
       "      <th>train_size</th>\n",
       "      <th>used_time</th>\n",
       "      <th>val_reg_r2</th>\n",
       "      <th>seed_n</th>\n",
       "      <th>sampling_seed</th>\n",
       "      <th>top-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>100</td>\n",
       "      <td>(0.4, 0.3, 0.3)</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6.75</td>\n",
       "      <td>216.0</td>\n",
       "      <td>44.547500</td>\n",
       "      <td>[0.4545]</td>\n",
       "      <td>20</td>\n",
       "      <td>[2000, 2001, 2002, 2003, 2004, 2005, 2006, 200...</td>\n",
       "      <td>0.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>100</td>\n",
       "      <td>(0.4, 0.3, 0.3)</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5.80</td>\n",
       "      <td>185.6</td>\n",
       "      <td>31.561500</td>\n",
       "      <td>[0.4545]</td>\n",
       "      <td>20</td>\n",
       "      <td>[2000, 2001, 2002, 2003, 2004, 2005, 2006, 200...</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>100</td>\n",
       "      <td>(0.4, 0.3, 0.3)</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>128.0</td>\n",
       "      <td>17.559444</td>\n",
       "      <td>[0.3615, 0.1561, 0.1386, 0.1755, 0.2463, 0.257...</td>\n",
       "      <td>18</td>\n",
       "      <td>[2002, 2003, 2004, 2005, 2006, 2007, 2008, 200...</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>100</td>\n",
       "      <td>(0.4, 0.3, 0.3)</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4.55</td>\n",
       "      <td>145.6</td>\n",
       "      <td>23.844500</td>\n",
       "      <td>[0.4545]</td>\n",
       "      <td>20</td>\n",
       "      <td>[2000, 2001, 2002, 2003, 2004, 2005, 2006, 200...</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>200</td>\n",
       "      <td>(0.4, 0.3, 0.3)</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5.50</td>\n",
       "      <td>176.0</td>\n",
       "      <td>29.047500</td>\n",
       "      <td>[0.4735]</td>\n",
       "      <td>20</td>\n",
       "      <td>[2000, 2001, 2002, 2003, 2004, 2005, 2006, 200...</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>300</td>\n",
       "      <td>(0.4, 0.3, 0.3)</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.40</td>\n",
       "      <td>89.6</td>\n",
       "      <td>5.079500</td>\n",
       "      <td>[0.71]</td>\n",
       "      <td>20</td>\n",
       "      <td>[2000, 2001, 2002, 2003, 2004, 2005, 2006, 200...</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>400</td>\n",
       "      <td>(0.4, 0.3, 0.3)</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.45</td>\n",
       "      <td>92.8</td>\n",
       "      <td>5.442500</td>\n",
       "      <td>[0.7098]</td>\n",
       "      <td>20</td>\n",
       "      <td>[2000, 2001, 2002, 2003, 2004, 2005, 2006, 200...</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>500</td>\n",
       "      <td>(0.4, 0.3, 0.3)</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.55</td>\n",
       "      <td>99.2</td>\n",
       "      <td>5.723000</td>\n",
       "      <td>[0.7091]</td>\n",
       "      <td>20</td>\n",
       "      <td>[2000, 2001, 2002, 2003, 2004, 2005, 2006, 200...</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.4, 0.3, 0.3)</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>102.4</td>\n",
       "      <td>5.653000</td>\n",
       "      <td>[0.7838]</td>\n",
       "      <td>20</td>\n",
       "      <td>[2000, 2001, 2002, 2003, 2004, 2005, 2006, 200...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0</td>\n",
       "      <td>(0.4, 0.3, 0.3)</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2.05</td>\n",
       "      <td>131.2</td>\n",
       "      <td>7.462500</td>\n",
       "      <td>[0.8153]</td>\n",
       "      <td>20</td>\n",
       "      <td>[2000, 2001, 2002, 2003, 2004, 2005, 2006, 200...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>396 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     measure_size  scratch  encoder_freeze  encoder_lr  cost_predictor_lr  \\\n",
       "0              32    False           False     0.00001            0.00001   \n",
       "1              32    False           False     0.00001            0.00001   \n",
       "2              32    False           False     0.00001            0.00001   \n",
       "3              32    False           False     0.00001            0.00001   \n",
       "4              32    False           False     0.00001            0.00001   \n",
       "..            ...      ...             ...         ...                ...   \n",
       "391            64    False           False     0.00010            0.00010   \n",
       "392            64    False           False     0.00010            0.00010   \n",
       "393            64    False           False     0.00010            0.00010   \n",
       "394            64    False           False     0.00010            0.00100   \n",
       "395            64    False           False     0.00010            0.01000   \n",
       "\n",
       "     rank_warmup_epochs          weights  uncertainty_topk  grad_num  \\\n",
       "0                   100  (0.4, 0.3, 0.3)                 0         2   \n",
       "1                   100  (0.4, 0.3, 0.3)                 0         4   \n",
       "2                   100  (0.4, 0.3, 0.3)                64         2   \n",
       "3                   100  (0.4, 0.3, 0.3)                64         4   \n",
       "4                   200  (0.4, 0.3, 0.3)                 0         2   \n",
       "..                  ...              ...               ...       ...   \n",
       "391                 300  (0.4, 0.3, 0.3)                64         4   \n",
       "392                 400  (0.4, 0.3, 0.3)                64         4   \n",
       "393                 500  (0.4, 0.3, 0.3)                64         4   \n",
       "394                   0  (0.4, 0.3, 0.3)                64         4   \n",
       "395                   0  (0.4, 0.3, 0.3)                64         4   \n",
       "\n",
       "     rand_num  phase  train_size  used_time  \\\n",
       "0           0   6.75       216.0  44.547500   \n",
       "1           0   5.80       185.6  31.561500   \n",
       "2           0   4.00       128.0  17.559444   \n",
       "3           0   4.55       145.6  23.844500   \n",
       "4           0   5.50       176.0  29.047500   \n",
       "..        ...    ...         ...        ...   \n",
       "391         0   1.40        89.6   5.079500   \n",
       "392         0   1.45        92.8   5.442500   \n",
       "393         0   1.55        99.2   5.723000   \n",
       "394         0   1.60       102.4   5.653000   \n",
       "395         0   2.05       131.2   7.462500   \n",
       "\n",
       "                                            val_reg_r2  seed_n  \\\n",
       "0                                             [0.4545]      20   \n",
       "1                                             [0.4545]      20   \n",
       "2    [0.3615, 0.1561, 0.1386, 0.1755, 0.2463, 0.257...      18   \n",
       "3                                             [0.4545]      20   \n",
       "4                                             [0.4735]      20   \n",
       "..                                                 ...     ...   \n",
       "391                                             [0.71]      20   \n",
       "392                                           [0.7098]      20   \n",
       "393                                           [0.7091]      20   \n",
       "394                                           [0.7838]      20   \n",
       "395                                           [0.8153]      20   \n",
       "\n",
       "                                         sampling_seed     top-1  \n",
       "0    [2000, 2001, 2002, 2003, 2004, 2005, 2006, 200...  0.150000  \n",
       "1    [2000, 2001, 2002, 2003, 2004, 2005, 2006, 200...  0.200000  \n",
       "2    [2002, 2003, 2004, 2005, 2006, 2007, 2008, 200...  0.166667  \n",
       "3    [2000, 2001, 2002, 2003, 2004, 2005, 2006, 200...  0.250000  \n",
       "4    [2000, 2001, 2002, 2003, 2004, 2005, 2006, 200...  0.250000  \n",
       "..                                                 ...       ...  \n",
       "391  [2000, 2001, 2002, 2003, 2004, 2005, 2006, 200...  0.250000  \n",
       "392  [2000, 2001, 2002, 2003, 2004, 2005, 2006, 200...  0.250000  \n",
       "393  [2000, 2001, 2002, 2003, 2004, 2005, 2006, 200...  0.300000  \n",
       "394  [2000, 2001, 2002, 2003, 2004, 2005, 2006, 200...       NaN  \n",
       "395  [2000, 2001, 2002, 2003, 2004, 2005, 2006, 200...       NaN  \n",
       "\n",
       "[396 rows x 17 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_kwargs = {\n",
    "    \"phase\": (\"phase\", \"mean\"),\n",
    "    \"train_size\": (\"train_size\", \"mean\"),\n",
    "    \"used_time\": (\"used_time\", \"mean\"),\n",
    "    \"val_reg_r2\": (\"val_reg_r2\", \"first\"),\n",
    "    \"seed_n\": (\"sampling_seed\", \"nunique\"),\n",
    "    \"sampling_seed\": (\"sampling_seed\", list),\n",
    "}\n",
    "\n",
    "topk_col = f\"top-1\"\n",
    "if topk_col in df_total.columns:\n",
    "    agg_kwargs[topk_col] = (topk_col, \"mean\")\n",
    "\n",
    "group_cols = [\n",
    "    \"measure_size\",\n",
    "    \"scratch\",\n",
    "    \"encoder_freeze\",\n",
    "    \"encoder_lr\",\n",
    "    \"cost_predictor_lr\",\n",
    "    \"rank_warmup_epochs\",\n",
    "    \"weights\",\n",
    "    \"uncertainty_topk\",\n",
    "    \"grad_num\",\n",
    "    \"rand_num\",\n",
    "]\n",
    "\n",
    "df_total_avg = (\n",
    "    df_total\n",
    "    .groupby(group_cols, as_index=False)\n",
    "    .agg(**agg_kwargs)\n",
    ")\n",
    "df_total_avg.to_csv(\"/root/work/tenset/scripts/pre_experiments/model_myself/result/([0c9a5ba46ffc5e1a9e5641018527117f,4,7,7,160,1,1,160,960,1,1,1,960,4,7,7,960],cuda).json/vae_extent_total_avg.csv\", index=True)\n",
    "df_total_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e47caa1",
   "metadata": {},
   "source": [
    "선택 파일 Avg 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab6cb7c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "save_avg_csv() missing 1 required positional argument: 'top_k'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 35\u001b[0m\n\u001b[1;32m     31\u001b[0m     df_avg\u001b[38;5;241m.\u001b[39mto_csv(filename\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_avg.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m), index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     32\u001b[0m     df_avg\n\u001b[0;32m---> 35\u001b[0m \u001b[43msave_avg_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/root/work/tenset/scripts/pre_experiments/model_myself/result/([0c9a5ba46ffc5e1a9e5641018527117f,4,7,7,160,1,1,160,960,1,1,1,960,4,7,7,960],cuda).json/vae_extent_1221_1646.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: save_avg_csv() missing 1 required positional argument: 'top_k'"
     ]
    }
   ],
   "source": [
    "def save_avg_csv(filename, top_k):\n",
    "    df_results = pd.read_csv(filename)\n",
    "    group_cols = [\n",
    "        \"measure_size\",\n",
    "        \"scratch\",\n",
    "        \"encoder_freeze\",\n",
    "        \"encoder_lr\",\n",
    "        \"cost_predictor_lr\",\n",
    "        \"rank_warmup_epochs\",\n",
    "        \"weights\",\n",
    "        \"uncertainty_topk\",\n",
    "        \"grad_num\",\n",
    "        \"rand_num\",\n",
    "    ]\n",
    "\n",
    "    df_avg = (\n",
    "        df_results\n",
    "        .groupby(group_cols, as_index=False)\n",
    "        .agg(\n",
    "            phase=(\"phase\", \"mean\"),\n",
    "            train_size=(\"train_size\", \"mean\"),\n",
    "            used_time=(\"used_time\", \"mean\"),\n",
    "            **{f\"top-{top_k}\": (f\"top-{top_k}\", \"mean\")},\n",
    "            val_reg_r2=(\"val_reg_r2\", \"first\"),\n",
    "            val_rank_r2=(\"val_rank_r2\", \"first\"),\n",
    "            seed_n=(\"sampling_seed\", \"nunique\"),\n",
    "            sampling_seed=(\"sampling_seed\", list),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    df_avg.to_csv(filename.replace(\".csv\", \"_avg.csv\"), index=False)\n",
    "    df_avg\n",
    "\n",
    "\n",
    "save_avg_csv(\"/root/work/tenset/scripts/pre_experiments/model_myself/result/([0c9a5ba46ffc5e1a9e5641018527117f,4,7,7,160,1,1,160,960,1,1,1,960,4,7,7,960],cuda).json/vae_extent_1221_1646.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76b8331",
   "metadata": {},
   "source": [
    "두 csv 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352c8346",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# CSV 파일 읽기\n",
    "csv1 = pd.read_csv('/root/work/tenset/scripts/pre_experiments/model_myself/result/([0c9a5ba46ffc5e1a9e5641018527117f,4,7,7,160,1,1,160,960,1,1,1,960,4,7,7,960],cuda).json/hyper/vae_extent_1220_2013.csv')\n",
    "csv2 = pd.read_csv('/root/work/tenset/scripts/pre_experiments/model_myself/result/([0c9a5ba46ffc5e1a9e5641018527117f,4,7,7,160,1,1,160,960,1,1,1,960,4,7,7,960],cuda).json/hyper/vae_extent_1220_2135.csv')\n",
    "\n",
    "# 두 CSV 합치기\n",
    "merged_csv = pd.concat([csv1, csv2])\n",
    "\n",
    "# 합친 CSV 저장\n",
    "merged_csv.to_csv('/root/work/tenset/scripts/pre_experiments/model_myself/result/([0c9a5ba46ffc5e1a9e5641018527117f,4,7,7,160,1,1,160,960,1,1,1,960,4,7,7,960],cuda).json/hyper/vae_extent_hyper_total.csv', index=False)\n",
    "save_avg_csv(merged_csv, '/root/work/tenset/scripts/pre_experiments/model_myself/result/([0c9a5ba46ffc5e1a9e5641018527117f,4,7,7,160,1,1,160,960,1,1,1,960,4,7,7,960],cuda).json/hyper/vae_extent_hyper_total.csv', top_k=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
