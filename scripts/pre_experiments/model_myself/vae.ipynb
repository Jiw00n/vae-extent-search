{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d665df27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "\n",
    "project_root = \"/root/work/tenset\"\n",
    "os.environ[\"TVM_HOME\"] = f\"{project_root}\"\n",
    "os.environ[\"TVM_LIBRARY_PATH\"] = f\"{project_root}/build\"\n",
    "if f\"{project_root}/python\" not in sys.path:\n",
    "    sys.path.insert(0, f\"{project_root}/python\")\n",
    "\n",
    "sys.path = [p for p in sys.path if not p.startswith(f\"{project_root}/build\")]\n",
    "sys.path.append(f\"{project_root}/build\")\n",
    "os.environ[\"LD_LIBRARY_PATH\"] = f\"{project_root}/build:\" + os.environ.get(\"LD_LIBRARY_PATH\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5ebadd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-12 14:55:56.969810: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-12 14:55:57.086154: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-12 14:55:57.674992: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import BertModel\n",
    "import numpy as np\n",
    "\n",
    "class VAE_Transformer(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim, bert_model_name='bert-base-uncased', activation=\"relu\"):\n",
    "        super(VAE_Transformer, self).__init__()\n",
    "\n",
    "        if activation == 'relu':\n",
    "            self.activation = nn.ReLU()\n",
    "        elif activation == 'gelu':\n",
    "            self.activation = nn.GELU()\n",
    "        elif activation == 'tanh':\n",
    "            self.activation = nn.Tanh()\n",
    "        elif activation == 'sigmoid':\n",
    "            self.activation = nn.Sigmoid()\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported activation function: {activation}\")\n",
    "\n",
    "        # Encoder (BERT -> mean, logvar)\n",
    "        self.bert = BertModel.from_pretrained(bert_model_name)\n",
    "        bert_output_dim = self.bert.config.hidden_size\n",
    "        self.fc_mean = nn.Linear(bert_output_dim, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(bert_output_dim, latent_dim)\n",
    "\n",
    "        # Decoder\n",
    "        self.fc_d1 = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.fc_d2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc_d3 = nn.Linear(hidden_dim, input_dim)\n",
    "\n",
    "    def encode(self, input_ids, attention_mask):\n",
    "        # bert\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        # 2. Pooler Output 추출 ([CLS] 토큰에 해당하는 벡터, shape: [batch, hidden_size])\n",
    "        # last_hidden_state[:, 0, :] 와 유사하지만, BERT는 추가적인 dense+tanh 층을 거친 pooler_output을 제공함\n",
    "        h = outputs.pooler_output\n",
    "        return self.fc_mean(h), self.fc_logvar(h)\n",
    "\n",
    "    def reparameterize(self, mean, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mean + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        h = F.relu(self.fc_d1(z))\n",
    "        h = F.relu(self.fc_d2(h))\n",
    "        # [수정] Sigmoid 제거. 선형(linear) 출력을 반환\n",
    "        return self.fc_d3(h)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mean, logvar)\n",
    "        recon_x = self.decode(z)\n",
    "        return recon_x, mean, logvar\n",
    "\n",
    "\n",
    "class AE(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim, activation=\"relu\"):\n",
    "        super(AE, self).__init__()\n",
    "\n",
    "        if activation == 'relu':\n",
    "            self.activation = nn.ReLU()\n",
    "        elif activation == 'gelu':\n",
    "            self.activation = nn.GELU()\n",
    "        elif activation == 'tanh':\n",
    "            self.activation = nn.Tanh()\n",
    "        elif activation == 'sigmoid':\n",
    "            self.activation = nn.Sigmoid()\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported activation function: {activation}\")\n",
    "\n",
    "        # Encoder (동일)\n",
    "        self.fc_e1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc_e2 = nn.Linear(hidden_dim, latent_dim)\n",
    "\n",
    "        # Decoder\n",
    "        self.fc_d1 = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.fc_d2 = nn.Linear(hidden_dim, input_dim)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = self.activation(self.fc_e1(x))\n",
    "        z = self.activation(self.fc_e2(h))\n",
    "        return z\n",
    "\n",
    "    def decode(self, z):\n",
    "        h = self.activation(self.fc_d1(z))\n",
    "        recon_x = self.activation(self.fc_d2(h))\n",
    "        return recon_x\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encode(x)\n",
    "        recon_x = self.decode(z)\n",
    "        return recon_x\n",
    "\n",
    "class regression(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim, activation=\"relu\"):\n",
    "        super(regression, self).__init__()\n",
    "\n",
    "        if activation == 'relu':\n",
    "            self.activation = nn.ReLU()\n",
    "        elif activation == 'gelu':\n",
    "            self.activation = nn.GELU()\n",
    "        elif activation == 'tanh':\n",
    "            self.activation = nn.Tanh()\n",
    "        elif activation == 'sigmoid':\n",
    "            self.activation = nn.Sigmoid()\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported activation function: {activation}\")\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            self.activation,\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            self.activation,\n",
    "            nn.Linear(hidden_dim, latent_dim),\n",
    "            nn.Linear(latent_dim, 1)\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        pred_cost = self.fc(x)\n",
    "        return pred_cost\n",
    "\n",
    "\n",
    "def vae_loss(recon_x, x, mean, logvar):\n",
    "    # [수정] BCE 대신 MSE Loss 사용\n",
    "\n",
    "    MSE = F.mse_loss(recon_x, x, reduction='sum')\n",
    "    # MAE = F.l1_loss(recon_x, x, reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mean.pow(2) - logvar.exp())\n",
    "\n",
    "    beta = 1.0 \n",
    "    return MSE + beta * KLD\n",
    "\n",
    "\n",
    "def ae_loss(recon_x, x):\n",
    "    # [수정] BCE 대신 MSE Loss 사용\n",
    "\n",
    "    MSE = F.mse_loss(recon_x, x, reduction='sum')\n",
    "    # MAE = F.l1_loss(recon_x, x, reduction='sum')\n",
    "    # KLD = -0.5 * torch.sum(1 + logvar - mean.pow(2) - logvar.exp())\n",
    "\n",
    "    beta = 1.0 \n",
    "    # return MSE + beta * KLD\n",
    "    return MSE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca1b65e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tvm import auto_scheduler\n",
    "import sys\n",
    "sys.path.insert(0, \"/root/work/tenset/scripts\")\n",
    "from print_programs import return_program\n",
    "from tvm.auto_scheduler.feature import get_per_store_features_from_file\n",
    "from make_dataset import load_and_register_tasks\n",
    "\n",
    "json_file = \"/root/work/tenset/dataset/measure_records_tenset/k80/([0bcb8746286db050cd088f375c85372d,1,64,64,128,6,6,32,128,1,64,64,32],cuda).json\"\n",
    "\n",
    "load_and_register_tasks()\n",
    "inputs, results = auto_scheduler.RecordReader(json_file).read_lines()\n",
    "raw_features, raw_normalized_throughputs, task_ids, min_latency = get_per_store_features_from_file(json_file, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6880a7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "records = {\n",
    "    \"schedules\": [],\n",
    "    \"cost_mean\": [],\n",
    "    \"feature\" : []\n",
    "}\n",
    "\n",
    "for i in range(len(inputs)):\n",
    "    state, cost = return_program(inputs[i], results[i])\n",
    "    # break\n",
    "    if state is not None:\n",
    "        cost_mean = np.mean([x.value for x in cost])\n",
    "        feature = raw_features[i]\n",
    "        records[\"feature\"].append(feature)\n",
    "        records[\"schedules\"].append(state)\n",
    "        records[\"cost_mean\"].append(cost_mean)\n",
    "\n",
    "features = np.array(records[\"feature\"], dtype=np.float32)\n",
    "costs = np.array(records[\"cost_mean\"], dtype=np.float32)\n",
    "print(\"Features shape:\", features.shape)\n",
    "# dataset = TensorDataset(torch.from_numpy(features), torch.from_numpy(costs))\n",
    "# dataloader = DataLoader(dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450fdc39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Mean: 1.1560, Log Std: 2.0146\n",
      "Training Start...\n",
      "Epoch 10/200, Average Loss: 7.3795\n",
      "Epoch 20/200, Average Loss: 6.5847\n",
      "Epoch 30/200, Average Loss: 6.1705\n",
      "Epoch 40/200, Average Loss: 6.0396\n",
      "Epoch 50/200, Average Loss: 5.8569\n",
      "Epoch 60/200, Average Loss: 5.7841\n",
      "Epoch 70/200, Average Loss: 5.8289\n",
      "Epoch 80/200, Average Loss: 5.7564\n",
      "Epoch 90/200, Average Loss: 5.7171\n",
      "Epoch 100/200, Average Loss: 5.6903\n",
      "Epoch 110/200, Average Loss: 5.6446\n",
      "Epoch 120/200, Average Loss: 5.6297\n",
      "Epoch 130/200, Average Loss: 5.5827\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[94], line 57\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[1;32m     56\u001b[0m     epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (batch, mask) \u001b[38;5;129;01min\u001b[39;00m dataloader: \u001b[38;5;66;03m# 마스크도 함께 받음\u001b[39;00m\n\u001b[1;32m     58\u001b[0m         batch \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     59\u001b[0m         mask \u001b[38;5;241m=\u001b[39m mask\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/work/tenset/.venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/work/tenset/.venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "HIDDEN_DIM = 256\n",
    "LATENT_DIM = 128\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "\n",
    "\n",
    "# (전체 데이터셋 기준)\n",
    "data_mean = data_log_masked.sum() / num_elements\n",
    "data_std = torch.sqrt( (((data_log_masked - data_mean) * masks)**2).sum() / num_elements )\n",
    "\n",
    "print(f\"Log Mean: {data_mean:.4f}, Log Std: {data_std:.4f}\")\n",
    "\n",
    "# (data_mean, data_std는 나중에 복원을 위해 저장)\n",
    "\n",
    "# 표준화 (패딩된 0 영역은 (0-mean)/std가 되지만, 학습 시 손실에서 제외)\n",
    "normalized_data = (data_log - data_mean) / (data_std)\n",
    "\n",
    "# --- 3. DataLoader 준비 (마스크 포함) ---\n",
    "dataset = TensorDataset(normalized_data, masks) # 마스크도 함께 전달\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# --- 4. 모델, 옵티마이저 초기화 (이전과 동일) ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = VAE(input_dim=MAX_SEQ_LENGTH, hidden_dim=HIDDEN_DIM, latent_dim=LATENT_DIM, activation=\"relu\").to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# --- 5. 학습 루프 (마스킹된 손실 계산) ---\n",
    "model.train()\n",
    "print(\"Training Start...\")\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch_loss = 0\n",
    "    for (batch, mask) in dataloader: # 마스크도 함께 받음\n",
    "        batch = batch.to(device)\n",
    "        mask = mask.to(device)\n",
    "        \n",
    "        # Forward\n",
    "        recon_batch, mean, logvar = model(batch * mask) # 입력 시에도 마스킹\n",
    "        # recon_batch = model(batch * mask) # 입력 시에도 마스킹\n",
    "        \n",
    "        # [수정] 손실 계산 시 패딩 영역 제외 (마스크 곱하기)\n",
    "        recon_error = F.mse_loss(recon_batch * mask, batch * mask, reduction='sum')\n",
    "        KLD = -0.5 * torch.sum(1 + logvar - mean.pow(2) - logvar.exp())\n",
    "        loss = recon_error + 0.5*KLD\n",
    "        # loss = ae_loss(recon_batch * mask, batch * mask)\n",
    "        # loss = vae_loss(recon_batch * mask, batch * mask)\n",
    "        \n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    avg_loss = epoch_loss / len(dataset)\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch {epoch+1}/{EPOCHS}, Average Loss: {avg_loss:.4f}')\n",
    "\n",
    "print(\"Training Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db2017e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패딩 (max_len로 길이 맞추기)\n",
    "padded_data = np.ones((len(records[\"feature\"]), max_len), dtype=np.float32)\n",
    "masks = np.zeros_like(padded_data, dtype=np.float32)\n",
    "for i, ext_list in enumerate(records[\"feature\"]):\n",
    "    length = min(len(ext_list), max_len)\n",
    "    padded_data[i, :length] = ext_list[:length]\n",
    "    masks[i, :length] = 1.0 # 실제 데이터가 있는 부분\n",
    "\n",
    "data = torch.from_numpy(padded_data)\n",
    "costs = torch.from_numpy(np.array(records[\"cost_mean\"], dtype=np.float32)).unsqueeze(1)\n",
    "masks = torch.from_numpy(masks)\n",
    "\n",
    "data_log = torch.log(data + 1e-8) * masks   # (N, max_len)\n",
    "\n",
    "normalized_data = torch.zeros_like(data_log)\n",
    "for col_idx in range(data_log.shape[1]):\n",
    "    col = data_log[:, col_idx]\n",
    "\n",
    "    # 실제 값(0이 아닌 값)만 골라서 통계 계산\n",
    "    valid = col != 0\n",
    "    if valid.sum() == 0:\n",
    "        # 이 컬럼은 전부 패딩이므로 그냥 0으로 둠\n",
    "        continue\n",
    "\n",
    "    col_valid = col[valid]\n",
    "    col_mean = col_valid.mean()\n",
    "    col_std = col_valid.std()\n",
    "\n",
    "    # std가 0이면 분모를 1로 해서 폭발 막기\n",
    "    if col_std == 0:\n",
    "        col_std = 1.0\n",
    "\n",
    "    col_norm = (col - col_mean) / col_std\n",
    "    # 패딩 자리(0이었던 곳)는 다시 0으로\n",
    "    col_norm = torch.where(valid, col_norm, torch.tensor(0.0, dtype=col.dtype))\n",
    "    normalized_data[:, col_idx] = col_norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d005037c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3734, 45])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tvm.auto_scheduler.feature import get_per_store_features_from_file\n",
    "from make_dataset import load_and_register_tasks\n",
    "\n",
    "load_and_register_tasks()\n",
    "raw_features, raw_normalized_throughputs, task_ids, min_latency = get_per_store_features_from_file(\"/root/work/tenset/dataset/measure_records/k80/([0c9a5ba46ffc5e1a9e5641018527117f,4,7,7,160,1,1,160,960,1,1,1,960,4,7,7,960],cuda).json\", 10000)\n",
    "\n",
    "\n",
    "raw_features = torch.tensor(raw_features.tolist(), dtype=torch.float32)\n",
    "raw_normalized_throughputs = torch.tensor(raw_normalized_throughputs, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "masks = torch.zeros_like(raw_normalized_throughputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a597d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 2987, Validation size: 747\n",
      "Epoch 10/1000 | Train Loss: 0.0505 | Val Loss: 0.0432\n",
      "Epoch 20/1000 | Train Loss: 0.0479 | Val Loss: 0.0408\n",
      "Epoch 30/1000 | Train Loss: 0.0467 | Val Loss: 0.0397\n",
      "Epoch 40/1000 | Train Loss: 0.0460 | Val Loss: 0.0391\n",
      "Epoch 50/1000 | Train Loss: 0.0455 | Val Loss: 0.0386\n",
      "Epoch 60/1000 | Train Loss: 0.0451 | Val Loss: 0.0383\n",
      "Epoch 70/1000 | Train Loss: 0.0448 | Val Loss: 0.0381\n",
      "Epoch 80/1000 | Train Loss: 0.0446 | Val Loss: 0.0378\n",
      "Epoch 90/1000 | Train Loss: 0.0444 | Val Loss: 0.0377\n",
      "Epoch 100/1000 | Train Loss: 0.0441 | Val Loss: 0.0375\n",
      "Epoch 110/1000 | Train Loss: 0.0439 | Val Loss: 0.0374\n",
      "Epoch 120/1000 | Train Loss: 0.0437 | Val Loss: 0.0372\n",
      "Epoch 130/1000 | Train Loss: 0.0436 | Val Loss: 0.0371\n",
      "Epoch 140/1000 | Train Loss: 0.0434 | Val Loss: 0.0370\n",
      "Epoch 150/1000 | Train Loss: 0.0433 | Val Loss: 0.0369\n",
      "Epoch 160/1000 | Train Loss: 0.0431 | Val Loss: 0.0368\n",
      "Epoch 170/1000 | Train Loss: 0.0429 | Val Loss: 0.0366\n",
      "Epoch 180/1000 | Train Loss: 0.0428 | Val Loss: 0.0365\n",
      "Epoch 190/1000 | Train Loss: 0.0426 | Val Loss: 0.0364\n",
      "Epoch 200/1000 | Train Loss: 0.0426 | Val Loss: 0.0363\n",
      "Epoch 210/1000 | Train Loss: 0.0424 | Val Loss: 0.0363\n",
      "Epoch 220/1000 | Train Loss: 0.0423 | Val Loss: 0.0361\n",
      "Epoch 230/1000 | Train Loss: 0.0421 | Val Loss: 0.0361\n",
      "Epoch 240/1000 | Train Loss: 0.0420 | Val Loss: 0.0361\n",
      "Epoch 250/1000 | Train Loss: 0.0420 | Val Loss: 0.0360\n",
      "Epoch 260/1000 | Train Loss: 0.0419 | Val Loss: 0.0360\n",
      "Epoch 270/1000 | Train Loss: 0.0418 | Val Loss: 0.0359\n",
      "Epoch 280/1000 | Train Loss: 0.0417 | Val Loss: 0.0359\n",
      "Epoch 290/1000 | Train Loss: 0.0416 | Val Loss: 0.0358\n",
      "Epoch 300/1000 | Train Loss: 0.0415 | Val Loss: 0.0358\n",
      "Epoch 310/1000 | Train Loss: 0.0415 | Val Loss: 0.0358\n",
      "Epoch 320/1000 | Train Loss: 0.0414 | Val Loss: 0.0358\n",
      "Epoch 330/1000 | Train Loss: 0.0413 | Val Loss: 0.0357\n",
      "Epoch 340/1000 | Train Loss: 0.0412 | Val Loss: 0.0357\n",
      "Epoch 350/1000 | Train Loss: 0.0412 | Val Loss: 0.0357\n",
      "Epoch 360/1000 | Train Loss: 0.0411 | Val Loss: 0.0357\n",
      "Epoch 370/1000 | Train Loss: 0.0410 | Val Loss: 0.0356\n",
      "Epoch 380/1000 | Train Loss: 0.0410 | Val Loss: 0.0356\n",
      "Epoch 390/1000 | Train Loss: 0.0409 | Val Loss: 0.0356\n",
      "Epoch 400/1000 | Train Loss: 0.0409 | Val Loss: 0.0356\n",
      "Epoch 410/1000 | Train Loss: 0.0408 | Val Loss: 0.0355\n",
      "Epoch 420/1000 | Train Loss: 0.0407 | Val Loss: 0.0355\n",
      "Epoch 430/1000 | Train Loss: 0.0407 | Val Loss: 0.0355\n",
      "Epoch 440/1000 | Train Loss: 0.0406 | Val Loss: 0.0355\n",
      "Epoch 450/1000 | Train Loss: 0.0407 | Val Loss: 0.0355\n",
      "Epoch 460/1000 | Train Loss: 0.0406 | Val Loss: 0.0355\n",
      "Epoch 470/1000 | Train Loss: 0.0405 | Val Loss: 0.0354\n",
      "Epoch 480/1000 | Train Loss: 0.0405 | Val Loss: 0.0354\n",
      "Epoch 490/1000 | Train Loss: 0.0404 | Val Loss: 0.0354\n",
      "Epoch 500/1000 | Train Loss: 0.0404 | Val Loss: 0.0354\n",
      "Epoch 510/1000 | Train Loss: 0.0403 | Val Loss: 0.0354\n",
      "Epoch 520/1000 | Train Loss: 0.0402 | Val Loss: 0.0354\n",
      "Epoch 530/1000 | Train Loss: 0.0402 | Val Loss: 0.0354\n",
      "Epoch 540/1000 | Train Loss: 0.0401 | Val Loss: 0.0354\n",
      "Epoch 550/1000 | Train Loss: 0.0402 | Val Loss: 0.0353\n",
      "Epoch 560/1000 | Train Loss: 0.0401 | Val Loss: 0.0353\n",
      "Epoch 570/1000 | Train Loss: 0.0400 | Val Loss: 0.0353\n",
      "Epoch 580/1000 | Train Loss: 0.0400 | Val Loss: 0.0353\n",
      "Epoch 590/1000 | Train Loss: 0.0399 | Val Loss: 0.0353\n",
      "Epoch 600/1000 | Train Loss: 0.0399 | Val Loss: 0.0353\n",
      "Epoch 610/1000 | Train Loss: 0.0398 | Val Loss: 0.0353\n",
      "Epoch 620/1000 | Train Loss: 0.0398 | Val Loss: 0.0353\n",
      "Epoch 630/1000 | Train Loss: 0.0398 | Val Loss: 0.0352\n",
      "Epoch 640/1000 | Train Loss: 0.0397 | Val Loss: 0.0352\n",
      "Epoch 650/1000 | Train Loss: 0.0397 | Val Loss: 0.0352\n",
      "Epoch 660/1000 | Train Loss: 0.0396 | Val Loss: 0.0352\n",
      "Epoch 670/1000 | Train Loss: 0.0396 | Val Loss: 0.0352\n",
      "Epoch 680/1000 | Train Loss: 0.0396 | Val Loss: 0.0352\n",
      "Epoch 690/1000 | Train Loss: 0.0396 | Val Loss: 0.0352\n",
      "Epoch 700/1000 | Train Loss: 0.0395 | Val Loss: 0.0352\n",
      "Epoch 710/1000 | Train Loss: 0.0395 | Val Loss: 0.0352\n",
      "Epoch 720/1000 | Train Loss: 0.0395 | Val Loss: 0.0352\n",
      "Epoch 730/1000 | Train Loss: 0.0394 | Val Loss: 0.0352\n",
      "Epoch 740/1000 | Train Loss: 0.0394 | Val Loss: 0.0352\n",
      "Epoch 750/1000 | Train Loss: 0.0394 | Val Loss: 0.0352\n",
      "Epoch 760/1000 | Train Loss: 0.0393 | Val Loss: 0.0352\n",
      "Epoch 770/1000 | Train Loss: 0.0393 | Val Loss: 0.0352\n",
      "Epoch 780/1000 | Train Loss: 0.0393 | Val Loss: 0.0351\n",
      "Epoch 790/1000 | Train Loss: 0.0393 | Val Loss: 0.0351\n",
      "Epoch 800/1000 | Train Loss: 0.0392 | Val Loss: 0.0351\n",
      "Epoch 810/1000 | Train Loss: 0.0392 | Val Loss: 0.0352\n",
      "Epoch 820/1000 | Train Loss: 0.0392 | Val Loss: 0.0352\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 45\u001b[0m\n\u001b[1;32m     43\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     44\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 45\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m     train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     47\u001b[0m train_loss \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_dataset)\n",
      "File \u001b[0;32m~/work/tenset/.venv/lib/python3.8/site-packages/torch/optim/optimizer.py:373\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    370\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    371\u001b[0m             )\n\u001b[0;32m--> 373\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    376\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/work/tenset/.venv/lib/python3.8/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/work/tenset/.venv/lib/python3.8/site-packages/torch/optim/adam.py:163\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    152\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    155\u001b[0m         group,\n\u001b[1;32m    156\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    160\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    161\u001b[0m         state_steps)\n\u001b[0;32m--> 163\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/work/tenset/.venv/lib/python3.8/site-packages/torch/optim/adam.py:311\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    309\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 311\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/tenset/.venv/lib/python3.8/site-packages/torch/optim/adam.py:565\u001b[0m, in \u001b[0;36m_multi_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    563\u001b[0m     exp_avg_sq_sqrt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_foreach_sqrt(device_max_exp_avg_sqs)\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 565\u001b[0m     exp_avg_sq_sqrt \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_foreach_sqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice_exp_avg_sqs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m torch\u001b[38;5;241m.\u001b[39m_foreach_div_(exp_avg_sq_sqrt, bias_correction2_sqrt)\n\u001b[1;32m    568\u001b[0m torch\u001b[38;5;241m.\u001b[39m_foreach_add_(exp_avg_sq_sqrt, eps)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# seed 고정\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "HIDDEN_DIM = 256\n",
    "LATENT_DIM = 128\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 1000\n",
    "LEARNING_RATE = 1e-5\n",
    "\n",
    "# --- 3. DataLoader 준비 (마스크 포함) ---\n",
    "from torch.utils.data import random_split, DataLoader, TensorDataset\n",
    "\n",
    "# 전체 데이터셋\n",
    "dataset = TensorDataset(normalized_data, costs)\n",
    "\n",
    "# train : val = 8 : 2 (2960 : 740 정도)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# DataLoader 준비\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"Train size: {len(train_dataset)}, Validation size: {len(val_dataset)}\")\n",
    "\n",
    "# --- 4. 모델, 옵티마이저 초기화 (이전과 동일) ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = regression(input_dim=45, hidden_dim=HIDDEN_DIM, latent_dim=LATENT_DIM, activation=\"relu\").to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# --- 5. 학습 루프 (마스킹된 손실 계산) ---\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        pred = model(x_batch)\n",
    "        loss = F.l1_loss(pred, y_batch, reduction='sum')\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_loss /= len(train_dataset)\n",
    "\n",
    "    # --- Validation ---\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in val_loader:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            pred = model(x_batch)\n",
    "            loss = F.l1_loss(pred, y_batch, reduction='sum')\n",
    "            val_loss += loss.item()\n",
    "    val_loss /= len(val_dataset)\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5dba5595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 vae_model.pth 및 통계 norm_stats.pth 로드 완료.\n",
      "\n",
      "--- 1. 재구성 테스트 ---\n",
      " 원본 데이터: [28, 1, 112, 1, 1, 1, 37, 112, 1, 64, 112, 1, 16, 4, 2, 4, 2, 2, 2, 8, 2, 4]\n",
      " 복원 데이터: [5, 4, 53, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 39, 24, 53, 1, 6]\n",
      "\n",
      "--- 2. 신규 생성 테스트 ---\n",
      "3개의 신규 루프 범위 벡터 생성:\n",
      " Sample 1: [3, 3, 272, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 74, 3, 270, 2, 1, 269, 2, 1]...\n",
      " Sample 2: [11, 4, 10, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 30, 32, 10, 3, 28, 10, 1, 1]...\n",
      " Sample 3: [91, 3, 47, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 48, 47, 1, 7, 46, 2, 1]...\n"
     ]
    }
   ],
   "source": [
    "def preprocess(raw_data, max_len, data_mean, data_std):\n",
    "    \"\"\"원시 리스트를 모델 입력 텐서로 변환\"\"\"\n",
    "    # 1. 패딩\n",
    "    padded = np.zeros(max_len, dtype=np.float32)\n",
    "    length = min(len(raw_data), max_len)\n",
    "    padded[:length] = raw_data[:length]\n",
    "    \n",
    "    # 2. 텐서 변환\n",
    "    tensor_data = torch.from_numpy(padded)\n",
    "    \n",
    "    # 3. 로그 변환 (0이 없다고 가정)\n",
    "    log_data = torch.log(tensor_data + 1e-8) # 0 방지\n",
    "    \n",
    "    # 4. 표준화 (학습 시 사용한 평균, 표준편차 사용)\n",
    "    normalized_data = (log_data - data_mean) / (data_std + 1e-8)\n",
    "    \n",
    "    # 5. 패딩 영역 0으로 마스킹 (중요)\n",
    "    mask = torch.zeros_like(tensor_data)\n",
    "    mask[:length] = 1.0\n",
    "    \n",
    "    return normalized_data.unsqueeze(0), mask.unsqueeze(0) # 배치 차원 추가\n",
    "\n",
    "def postprocess(normalized_tensor, data_mean, data_std):\n",
    "    \"\"\"모델 출력 텐서를 원본 스케일의 extent로 변환\"\"\"\n",
    "    # 1. 역-표준화\n",
    "    log_tensor = (normalized_tensor * (data_std + 1e-8)) + data_mean\n",
    "    \n",
    "    # 2. 역-로그 (exp)\n",
    "    extent_tensor = torch.exp(log_tensor)\n",
    "    \n",
    "    # 3. 정수로 변환 (extent는 정수)\n",
    "    return torch.round(extent_tensor).int()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- 1. 설정 (학습 시와 동일하게) ---\n",
    "MAX_SEQ_LENGTH = 45\n",
    "HIDDEN_DIM = 256\n",
    "LATENT_DIM = 128\n",
    "\n",
    "MODEL_PATH = 'vae_model.pth'        # 학습된 모델 경로\n",
    "STATS_PATH = 'norm_stats.pth'      # 학습 시 저장한 정규화 통계 (mean, std)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- 2. 모델 및 통계 로드 ---\n",
    "# (주의: 학습 시 아래와 같이 저장했다고 가정)\n",
    "# torch.save(model, MODEL_PATH)\n",
    "# torch.save({'mean': data_mean, 'std': data_std}, STATS_PATH)\n",
    "\n",
    "try:\n",
    "    # model = torch.load(MODEL_PATH, map_location=device)\n",
    "    model.eval() # 테스트 모드로 설정\n",
    "\n",
    "    # stats = torch.load(STATS_PATH)\n",
    "    # data_mean = stats['mean'].to(device)\n",
    "    # data_std = stats['std'].to(device)\n",
    "except FileNotFoundError:\n",
    "    print(f\"오류: {MODEL_PATH} 또는 {STATS_PATH} 파일을 찾을 수 없습니다.\")\n",
    "    print(\"테스트 전에 모델과 통계 데이터를 먼저 학습/저장해야 합니다.\")\n",
    "    exit()\n",
    "\n",
    "print(f\"모델 {MODEL_PATH} 및 통계 {STATS_PATH} 로드 완료.\\n\")\n",
    "\n",
    "# --- 3. 테스트 1: 재구성 (Reconstruction) ---\n",
    "print(\"--- 1. 재구성 테스트 ---\")\n",
    "test_sample_raw = [28, 1, 112, 1, 1, 1, 37, 112, 1, 64, 112, 1, 16, 4, 2, 4, 2, 2, 2, 8, 2, 4]\n",
    "\n",
    "# 전처리\n",
    "test_input, mask = preprocess(test_sample_raw, MAX_SEQ_LENGTH, data_mean, data_std)\n",
    "test_input = test_input.to(device)\n",
    "mask = mask.to(device)\n",
    "\n",
    "with torch.no_grad(): # 기울기 계산 비활성화\n",
    "    recon_output, _, _ = model(test_input * mask)\n",
    "\n",
    "# 후처리\n",
    "recon_sample = postprocess(recon_output.squeeze(0), data_mean, data_std)\n",
    "\n",
    "# 원본 길이만큼 잘라서 비교\n",
    "original_len = len(test_sample_raw)\n",
    "\n",
    "print(f\" 원본 데이터: {test_sample_raw}\")\n",
    "print(f\" 복원 데이터: {recon_sample[:original_len].tolist()}\")\n",
    "\n",
    "# (참고: VAE는 손실 압축이므로 원본과 완벽히 같지 않습니다)\n",
    "\n",
    "# --- 4. 테스트 2: 생성 (Generation) ---\n",
    "print(\"\\n--- 2. 신규 생성 테스트 ---\")\n",
    "num_to_generate = 3\n",
    "\n",
    "with torch.no_grad():\n",
    "    # 잠재 공간(N(0,1))에서 무작위 샘플링\n",
    "    z = torch.randn(num_to_generate, LATENT_DIM).to(device)\n",
    "    \n",
    "    # 디코더로 생성\n",
    "    generated_output = model.decode(z)\n",
    "    \n",
    "# 후처리\n",
    "generated_samples = postprocess(generated_output, data_mean, data_std)\n",
    "\n",
    "print(f\"{num_to_generate}개의 신규 루프 범위 벡터 생성:\")\n",
    "for i, sample in enumerate(generated_samples):\n",
    "    # 0이나 음수는 1로 클리핑 (extent는 최소 1)\n",
    "    cleaned_sample = torch.clamp(sample, min=1)\n",
    "    \n",
    "    # (편의상 앞 25개 정도만 출력)\n",
    "    print(f\" Sample {i+1}: {cleaned_sample[:25].tolist()}...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
